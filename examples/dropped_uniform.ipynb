{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.transforms.dropout import UniformStochasticDropout\n",
    "from nflows.transforms.dropout import VariationalStochasticDropout\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works with any size x\n",
    "def p(x, n_probs):\n",
    "    sums = torch.sum(x, axis=1)\n",
    "    probs = torch.cos(torch.ger(sums, torch.arange(1, n_probs+1, dtype=torch.float32)))**2\n",
    "    norm = torch.sum(probs, axis=1)\n",
    "\n",
    "    for i in range(n_probs):\n",
    "        probs[:,i] /= norm\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n, drop_indices):\n",
    "    n_probs = torch.max(drop_indices) + 1\n",
    "    x = torch.rand(n, drop_indices.shape[0])\n",
    "    probs = p(x, n_probs)\n",
    "\n",
    "    # Pick a prob\n",
    "    probs_cumsum = torch.cumsum(probs, axis=1)\n",
    "\n",
    "    # Tensor with bools that are true when r passes the cumprob\n",
    "    larger_than_cumprob = torch.rand(n,1) < probs_cumsum\n",
    "    # Do the arange trick to find first nonzero\n",
    "    # This is the HIGHEST LABEL FROM DROP_INDICES THAT IS KEPT\n",
    "    selected_index = torch.argmax(larger_than_cumprob*torch.arange(n_probs, 0, -1), axis=1)\n",
    "\n",
    "    '''\n",
    "    print(\"The index of the selected probability\")\n",
    "    print(\"This is also the highest label in drop_indices that is kept\")\n",
    "    print(selected_index)\n",
    "    ''' \n",
    "    \n",
    "    # Find the index of the first true\n",
    "    drop_mask = drop_indices > selected_index[:,None]\n",
    "    x[drop_mask] = 0\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indices = torch.tensor([0,0,1,1,1,2,3,3,4])\n",
    "n_data = int(1e6)\n",
    "x_data = generate(n_data, drop_indices).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "base_dist_uniform = BoxUniform(torch.zeros(drop_indices.shape[0]), torch.ones(drop_indices.shape[0]))\n",
    "base_dist_variational = BoxUniform(torch.zeros(drop_indices.shape[0]), torch.ones(drop_indices.shape[0]))\n",
    "\n",
    "transforms_uniform = []\n",
    "transforms_variational = []\n",
    "\n",
    "transforms_uniform.append(UniformStochasticDropout(drop_indices))\n",
    "transforms_variational.append(VariationalStochasticDropout(drop_indices))\n",
    "\n",
    "for _ in range(num_layers):\n",
    "    transforms_uniform.append(RandomPermutation(features=drop_indices.shape[0]))\n",
    "    transforms_uniform.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=drop_indices.shape[0], \n",
    "        hidden_features=50,\n",
    "        num_bins=10,\n",
    "        num_blocks=4,\n",
    "    ))\n",
    "\n",
    "    transforms_variational.append(RandomPermutation(features=drop_indices.shape[0]))\n",
    "    transforms_variational.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=drop_indices.shape[0], \n",
    "        hidden_features=50,\n",
    "        num_bins=10,\n",
    "        num_blocks=4,\n",
    "    ))\n",
    "\n",
    "transform_uniform = CompositeTransform(transforms_uniform)\n",
    "transform_variational = CompositeTransform(transforms_variational)\n",
    "\n",
    "flow_uniform = Flow(transform_uniform, base_dist_uniform).to(device)\n",
    "flow_variational = Flow(transform_variational, base_dist_variational).to(device)\n",
    "\n",
    "optimizer_uniform = optim.Adam(flow_uniform.parameters())\n",
    "optimizer_variational = optim.Adam(flow_variational.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/nflows/nflows/transforms/dropout.py:85: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_dropout_selected = torch.log(F.softmax(self._weights)[probs_dropout_index])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  1 / 1000 loss_uniform =  4.152677059173584  loss_variational =  6.120657920837402\n",
      "epoch =  0 batch =  2 / 1000 loss_uniform =  4.094895124435425  loss_variational =  5.9657301902771\n",
      "epoch =  0 batch =  3 / 1000 loss_uniform =  3.9773677984873452  loss_variational =  5.8011555671691895\n",
      "epoch =  0 batch =  4 / 1000 loss_uniform =  3.885342299938202  loss_variational =  5.615455746650696\n",
      "epoch =  0 batch =  5 / 1000 loss_uniform =  3.818865489959717  loss_variational =  5.487174034118652\n",
      "epoch =  0 batch =  6 / 1000 loss_uniform =  3.7399772802988687  loss_variational =  5.333377122879028\n",
      "epoch =  0 batch =  7 / 1000 loss_uniform =  3.675703832081386  loss_variational =  5.201341833387103\n",
      "epoch =  0 batch =  8 / 1000 loss_uniform =  3.610759735107422  loss_variational =  5.082662045955658\n",
      "epoch =  0 batch =  9 / 1000 loss_uniform =  3.5531297789679632  loss_variational =  4.984467294481066\n",
      "epoch =  0 batch =  10 / 1000 loss_uniform =  3.492845368385315  loss_variational =  4.891951274871826\n",
      "epoch =  0 batch =  11 / 1000 loss_uniform =  3.4463000947778877  loss_variational =  4.809431314468384\n",
      "epoch =  0 batch =  12 / 1000 loss_uniform =  3.3924138148625693  loss_variational =  4.726369122664134\n",
      "epoch =  0 batch =  13 / 1000 loss_uniform =  3.351005499179547  loss_variational =  4.647074717741746\n",
      "epoch =  0 batch =  14 / 1000 loss_uniform =  3.311337811606271  loss_variational =  4.584229673658099\n",
      "epoch =  0 batch =  15 / 1000 loss_uniform =  3.267511987686157  loss_variational =  4.519130595525106\n",
      "epoch =  0 batch =  16 / 1000 loss_uniform =  3.2340549528598785  loss_variational =  4.4595730900764465\n",
      "epoch =  0 batch =  17 / 1000 loss_uniform =  3.1991422316607308  loss_variational =  4.399957334294038\n",
      "epoch =  0 batch =  18 / 1000 loss_uniform =  3.1661249001820884  loss_variational =  4.344481680128309\n",
      "epoch =  0 batch =  19 / 1000 loss_uniform =  3.1327185379831413  loss_variational =  4.292414552287052\n",
      "epoch =  0 batch =  20 / 1000 loss_uniform =  3.1004783272743226  loss_variational =  4.237248206138611\n",
      "epoch =  0 batch =  21 / 1000 loss_uniform =  3.0733319350651334  loss_variational =  4.1966048422313875\n",
      "epoch =  0 batch =  22 / 1000 loss_uniform =  3.052265308120034  loss_variational =  4.1553180109370835\n",
      "epoch =  0 batch =  23 / 1000 loss_uniform =  3.0252438628155254  loss_variational =  4.106765498285708\n",
      "epoch =  0 batch =  24 / 1000 loss_uniform =  2.9960822562376657  loss_variational =  4.065280109643936\n",
      "epoch =  0 batch =  25 / 1000 loss_uniform =  2.9754562187194824  loss_variational =  4.025913410186767\n",
      "epoch =  0 batch =  26 / 1000 loss_uniform =  2.954718965750474  loss_variational =  3.9845139338419986\n",
      "epoch =  0 batch =  27 / 1000 loss_uniform =  2.931553275496871  loss_variational =  3.9427135432208025\n",
      "epoch =  0 batch =  28 / 1000 loss_uniform =  2.9122016515050615  loss_variational =  3.906386307307652\n",
      "epoch =  0 batch =  29 / 1000 loss_uniform =  2.8941450201231858  loss_variational =  3.8728567896218133\n",
      "epoch =  0 batch =  30 / 1000 loss_uniform =  2.877502528826396  loss_variational =  3.8370076020558677\n",
      "epoch =  0 batch =  31 / 1000 loss_uniform =  2.8599177252861763  loss_variational =  3.803781824727212\n",
      "epoch =  0 batch =  32 / 1000 loss_uniform =  2.842222511768341  loss_variational =  3.767388440668583\n",
      "epoch =  0 batch =  33 / 1000 loss_uniform =  2.8237744172414145  loss_variational =  3.734580798582597\n",
      "epoch =  0 batch =  34 / 1000 loss_uniform =  2.8072546580258537  loss_variational =  3.7068151656319115\n",
      "epoch =  0 batch =  35 / 1000 loss_uniform =  2.7908289296286446  loss_variational =  3.67948956489563\n",
      "epoch =  0 batch =  36 / 1000 loss_uniform =  2.7722583611806235  loss_variational =  3.6496893167495728\n",
      "epoch =  0 batch =  37 / 1000 loss_uniform =  2.756238486315753  loss_variational =  3.6209093042322107\n",
      "epoch =  0 batch =  38 / 1000 loss_uniform =  2.741639168638932  loss_variational =  3.597313504470022\n",
      "epoch =  0 batch =  39 / 1000 loss_uniform =  2.7260567775139437  loss_variational =  3.5700995799822683\n",
      "epoch =  0 batch =  40 / 1000 loss_uniform =  2.71120171546936  loss_variational =  3.542441356182098\n",
      "epoch =  0 batch =  41 / 1000 loss_uniform =  2.6958631480612407  loss_variational =  3.5168010432545733\n",
      "epoch =  0 batch =  42 / 1000 loss_uniform =  2.681591573215666  loss_variational =  3.4934719857715426\n",
      "epoch =  0 batch =  43 / 1000 loss_uniform =  2.667360594106275  loss_variational =  3.4698927236157795\n",
      "epoch =  0 batch =  44 / 1000 loss_uniform =  2.65503180027008  loss_variational =  3.447985286062414\n",
      "epoch =  0 batch =  45 / 1000 loss_uniform =  2.6413707362280947  loss_variational =  3.427652703391181\n",
      "epoch =  0 batch =  46 / 1000 loss_uniform =  2.6289575307265567  loss_variational =  3.40588046675143\n",
      "epoch =  0 batch =  47 / 1000 loss_uniform =  2.6151276674676445  loss_variational =  3.384909300093955\n",
      "epoch =  0 batch =  48 / 1000 loss_uniform =  2.6024318064252534  loss_variational =  3.3647745003302894\n",
      "epoch =  0 batch =  49 / 1000 loss_uniform =  2.5909889936447144  loss_variational =  3.3430827296510035\n",
      "epoch =  0 batch =  50 / 1000 loss_uniform =  2.5799413752555846  loss_variational =  3.3222485399246215\n",
      "epoch =  0 batch =  51 / 1000 loss_uniform =  2.5687166919895246  loss_variational =  3.3026000845666026\n",
      "epoch =  0 batch =  52 / 1000 loss_uniform =  2.558327475419411  loss_variational =  3.2842292464696445\n",
      "epoch =  0 batch =  53 / 1000 loss_uniform =  2.5461688356579475  loss_variational =  3.265807426200723\n",
      "epoch =  0 batch =  54 / 1000 loss_uniform =  2.5350411269399853  loss_variational =  3.247511351550067\n",
      "epoch =  0 batch =  55 / 1000 loss_uniform =  2.524374142560092  loss_variational =  3.2305170492692428\n",
      "epoch =  0 batch =  56 / 1000 loss_uniform =  2.51546106168202  loss_variational =  3.214596543993269\n",
      "epoch =  0 batch =  57 / 1000 loss_uniform =  2.506223467358372  loss_variational =  3.1991333459552966\n",
      "epoch =  0 batch =  58 / 1000 loss_uniform =  2.4960005221695734  loss_variational =  3.182034134864807\n",
      "epoch =  0 batch =  59 / 1000 loss_uniform =  2.486849411059234  loss_variational =  3.1671989125720525\n",
      "epoch =  0 batch =  60 / 1000 loss_uniform =  2.4777159492174783  loss_variational =  3.1518898328145344\n",
      "epoch =  0 batch =  61 / 1000 loss_uniform =  2.4692053579893267  loss_variational =  3.136922840212212\n",
      "epoch =  0 batch =  62 / 1000 loss_uniform =  2.4613146993421737  loss_variational =  3.1223087387700237\n",
      "epoch =  0 batch =  63 / 1000 loss_uniform =  2.4528243144353232  loss_variational =  3.1081053113180492\n",
      "epoch =  0 batch =  64 / 1000 loss_uniform =  2.4442375041544437  loss_variational =  3.092949938029051\n",
      "epoch =  0 batch =  65 / 1000 loss_uniform =  2.4358240622740523  loss_variational =  3.0789518319643463\n",
      "epoch =  0 batch =  66 / 1000 loss_uniform =  2.428506768111027  loss_variational =  3.0648376255324394\n",
      "epoch =  0 batch =  67 / 1000 loss_uniform =  2.4207191574039744  loss_variational =  3.0504656087106734\n",
      "epoch =  0 batch =  68 / 1000 loss_uniform =  2.4130929638357723  loss_variational =  3.037373321897843\n",
      "epoch =  0 batch =  69 / 1000 loss_uniform =  2.405635633330414  loss_variational =  3.023875329805457\n",
      "epoch =  0 batch =  70 / 1000 loss_uniform =  2.398946235861097  loss_variational =  3.0114447559629167\n",
      "epoch =  0 batch =  71 / 1000 loss_uniform =  2.3916204966289896  loss_variational =  2.9989109912388763\n",
      "epoch =  0 batch =  72 / 1000 loss_uniform =  2.3843732327222824  loss_variational =  2.9861776298946805\n",
      "epoch =  0 batch =  73 / 1000 loss_uniform =  2.378063673842443  loss_variational =  2.9744557256567967\n",
      "epoch =  0 batch =  74 / 1000 loss_uniform =  2.37187678266216  loss_variational =  2.963385788170067\n",
      "epoch =  0 batch =  75 / 1000 loss_uniform =  2.3652940877278645  loss_variational =  2.952402006785075\n",
      "epoch =  0 batch =  76 / 1000 loss_uniform =  2.3583520258727826  loss_variational =  2.9412423152672615\n",
      "epoch =  0 batch =  77 / 1000 loss_uniform =  2.351525693744808  loss_variational =  2.929900652402407\n",
      "epoch =  0 batch =  78 / 1000 loss_uniform =  2.3451769214410048  loss_variational =  2.9183516777478733\n",
      "epoch =  0 batch =  79 / 1000 loss_uniform =  2.339031297949296  loss_variational =  2.907521341420427\n",
      "epoch =  0 batch =  80 / 1000 loss_uniform =  2.332641410827637  loss_variational =  2.896964731812477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  81 / 1000 loss_uniform =  2.3266981634092923  loss_variational =  2.886233635890631\n",
      "epoch =  0 batch =  82 / 1000 loss_uniform =  2.3210371063976756  loss_variational =  2.8754255902476427\n",
      "epoch =  0 batch =  83 / 1000 loss_uniform =  2.315337341952037  loss_variational =  2.8648890343057105\n",
      "epoch =  0 batch =  84 / 1000 loss_uniform =  2.3096360493273966  loss_variational =  2.8552088127249764\n",
      "epoch =  0 batch =  85 / 1000 loss_uniform =  2.3046014252830958  loss_variational =  2.845240759849548\n",
      "epoch =  0 batch =  86 / 1000 loss_uniform =  2.299064548902734  loss_variational =  2.8354436145272364\n",
      "epoch =  0 batch =  87 / 1000 loss_uniform =  2.2936447310721744  loss_variational =  2.82580261120851\n",
      "epoch =  0 batch =  88 / 1000 loss_uniform =  2.2883881086652935  loss_variational =  2.8162853392687706\n",
      "epoch =  0 batch =  89 / 1000 loss_uniform =  2.2831771735394946  loss_variational =  2.807171682293495\n",
      "epoch =  0 batch =  90 / 1000 loss_uniform =  2.2781233522627096  loss_variational =  2.79838515387641\n",
      "epoch =  0 batch =  91 / 1000 loss_uniform =  2.272854790582762  loss_variational =  2.7898860527918883\n",
      "epoch =  0 batch =  92 / 1000 loss_uniform =  2.2681011894474863  loss_variational =  2.781410774459009\n",
      "epoch =  0 batch =  93 / 1000 loss_uniform =  2.2632310352017804  loss_variational =  2.7720772450970057\n",
      "epoch =  0 batch =  94 / 1000 loss_uniform =  2.258193241788986  loss_variational =  2.7634390947666567\n",
      "epoch =  0 batch =  95 / 1000 loss_uniform =  2.2532944654163565  loss_variational =  2.7548702089410075\n",
      "epoch =  0 batch =  96 / 1000 loss_uniform =  2.2487622238695626  loss_variational =  2.746293075382709\n",
      "epoch =  0 batch =  97 / 1000 loss_uniform =  2.2441088317595814  loss_variational =  2.738327692464454\n",
      "epoch =  0 batch =  98 / 1000 loss_uniform =  2.239662310298609  loss_variational =  2.730181663620228\n",
      "epoch =  0 batch =  99 / 1000 loss_uniform =  2.2357194977577297  loss_variational =  2.721898942282705\n",
      "epoch =  0 batch =  100 / 1000 loss_uniform =  2.2311945497989667  loss_variational =  2.7136867928504937\n",
      "epoch =  0 batch =  101 / 1000 loss_uniform =  2.2267205880420056  loss_variational =  2.7053525719312153\n",
      "epoch =  0 batch =  102 / 1000 loss_uniform =  2.222341108555889  loss_variational =  2.698255066778145\n",
      "epoch =  0 batch =  103 / 1000 loss_uniform =  2.2181553250377632  loss_variational =  2.6910975129858956\n",
      "epoch =  0 batch =  104 / 1000 loss_uniform =  2.21429915726185  loss_variational =  2.6836883540336895\n",
      "epoch =  0 batch =  105 / 1000 loss_uniform =  2.2097879739034756  loss_variational =  2.6766707397642584\n",
      "epoch =  0 batch =  106 / 1000 loss_uniform =  2.2056187357542663  loss_variational =  2.669654412089653\n",
      "epoch =  0 batch =  107 / 1000 loss_uniform =  2.2017680952482146  loss_variational =  2.6619668575090776\n",
      "epoch =  0 batch =  108 / 1000 loss_uniform =  2.1978146345527096  loss_variational =  2.6552831784442614\n",
      "epoch =  0 batch =  109 / 1000 loss_uniform =  2.1936563319022517  loss_variational =  2.648454142273019\n",
      "epoch =  0 batch =  110 / 1000 loss_uniform =  2.189970551837576  loss_variational =  2.6416337695988736\n",
      "epoch =  0 batch =  111 / 1000 loss_uniform =  2.1864294522517453  loss_variational =  2.634765389803293\n",
      "epoch =  0 batch =  112 / 1000 loss_uniform =  2.182790514613903  loss_variational =  2.62833070648568\n",
      "epoch =  0 batch =  113 / 1000 loss_uniform =  2.1788460543725363  loss_variational =  2.6222283724135\n",
      "epoch =  0 batch =  114 / 1000 loss_uniform =  2.175307451632987  loss_variational =  2.6159301661608505\n",
      "epoch =  0 batch =  115 / 1000 loss_uniform =  2.1717770503914897  loss_variational =  2.6094895072605295\n",
      "epoch =  0 batch =  116 / 1000 loss_uniform =  2.1680627629674736  loss_variational =  2.6030799962323283\n",
      "epoch =  0 batch =  117 / 1000 loss_uniform =  2.1644805679973396  loss_variational =  2.596778928724109\n",
      "epoch =  0 batch =  118 / 1000 loss_uniform =  2.1610802391828137  loss_variational =  2.590764853913905\n",
      "epoch =  0 batch =  119 / 1000 loss_uniform =  2.157509313911953  loss_variational =  2.5846833150927755\n",
      "epoch =  0 batch =  120 / 1000 loss_uniform =  2.1539233992497144  loss_variational =  2.5784711192051564\n",
      "epoch =  0 batch =  121 / 1000 loss_uniform =  2.1506046805500016  loss_variational =  2.5724726225718975\n",
      "epoch =  0 batch =  122 / 1000 loss_uniform =  2.1472439726845183  loss_variational =  2.5665992986960484\n",
      "epoch =  0 batch =  123 / 1000 loss_uniform =  2.1438261105762284  loss_variational =  2.5606722540971707\n",
      "epoch =  0 batch =  124 / 1000 loss_uniform =  2.140968625583958  loss_variational =  2.5551715493202205\n",
      "epoch =  0 batch =  125 / 1000 loss_uniform =  2.1378179998397844  loss_variational =  2.5497854070663446\n",
      "epoch =  0 batch =  126 / 1000 loss_uniform =  2.1347229319905496  loss_variational =  2.5444827363604587\n",
      "epoch =  0 batch =  127 / 1000 loss_uniform =  2.1315998815176074  loss_variational =  2.5393321410877494\n",
      "epoch =  0 batch =  128 / 1000 loss_uniform =  2.128534238785507  loss_variational =  2.5340219922363754\n",
      "epoch =  0 batch =  129 / 1000 loss_uniform =  2.125638678092367  loss_variational =  2.528912167216456\n",
      "epoch =  0 batch =  130 / 1000 loss_uniform =  2.1226085011775693  loss_variational =  2.523649554069225\n",
      "epoch =  0 batch =  131 / 1000 loss_uniform =  2.1197158944515797  loss_variational =  2.5181357032470117\n",
      "epoch =  0 batch =  132 / 1000 loss_uniform =  2.1169031533327987  loss_variational =  2.513162746573939\n",
      "epoch =  0 batch =  133 / 1000 loss_uniform =  2.114334064318723  loss_variational =  2.5086192224258763\n",
      "epoch =  0 batch =  134 / 1000 loss_uniform =  2.1113034851515486  loss_variational =  2.5035659635244905\n",
      "epoch =  0 batch =  135 / 1000 loss_uniform =  2.1083824537418523  loss_variational =  2.4985623668741295\n",
      "epoch =  0 batch =  136 / 1000 loss_uniform =  2.105578994926286  loss_variational =  2.4938091793481036\n",
      "epoch =  0 batch =  137 / 1000 loss_uniform =  2.1029592378296136  loss_variational =  2.4889711028467993\n",
      "epoch =  0 batch =  138 / 1000 loss_uniform =  2.1005159141360865  loss_variational =  2.4842513903327603\n",
      "epoch =  0 batch =  139 / 1000 loss_uniform =  2.097963220781561  loss_variational =  2.4798166194408053\n",
      "epoch =  0 batch =  140 / 1000 loss_uniform =  2.095392411095757  loss_variational =  2.474940827063151\n",
      "epoch =  0 batch =  141 / 1000 loss_uniform =  2.092814043058573  loss_variational =  2.470547709059207\n",
      "epoch =  0 batch =  142 / 1000 loss_uniform =  2.0903804151105225  loss_variational =  2.465948137598977\n",
      "epoch =  0 batch =  143 / 1000 loss_uniform =  2.0876922557404005  loss_variational =  2.461428383847216\n",
      "epoch =  0 batch =  144 / 1000 loss_uniform =  2.0852535068988813  loss_variational =  2.4570507076051493\n",
      "epoch =  0 batch =  145 / 1000 loss_uniform =  2.0829516040867784  loss_variational =  2.4526533176159027\n",
      "epoch =  0 batch =  146 / 1000 loss_uniform =  2.0805041855328716  loss_variational =  2.448421340282648\n",
      "epoch =  0 batch =  147 / 1000 loss_uniform =  2.0782185509091344  loss_variational =  2.444161175059622\n",
      "epoch =  0 batch =  148 / 1000 loss_uniform =  2.075856892643749  loss_variational =  2.4399417775708265\n",
      "epoch =  0 batch =  149 / 1000 loss_uniform =  2.0736615721811393  loss_variational =  2.435949695190326\n",
      "epoch =  0 batch =  150 / 1000 loss_uniform =  2.07131616751353  loss_variational =  2.432012260754902\n",
      "epoch =  0 batch =  151 / 1000 loss_uniform =  2.0690556583025606  loss_variational =  2.428029935881001\n",
      "epoch =  0 batch =  152 / 1000 loss_uniform =  2.066836306923315  loss_variational =  2.424094748340154\n",
      "epoch =  0 batch =  153 / 1000 loss_uniform =  2.0648524854697445  loss_variational =  2.4199711957009002\n",
      "epoch =  0 batch =  154 / 1000 loss_uniform =  2.0627255973877854  loss_variational =  2.4160404778146116\n",
      "epoch =  0 batch =  155 / 1000 loss_uniform =  2.0605567409146226  loss_variational =  2.412373587392991\n",
      "epoch =  0 batch =  156 / 1000 loss_uniform =  2.058338502278696  loss_variational =  2.4085922936598454\n",
      "epoch =  0 batch =  157 / 1000 loss_uniform =  2.056102962250923  loss_variational =  2.404882845605254\n",
      "epoch =  0 batch =  158 / 1000 loss_uniform =  2.0538923325417926  loss_variational =  2.4011681600462023\n",
      "epoch =  0 batch =  159 / 1000 loss_uniform =  2.0519470966087203  loss_variational =  2.3975986557186766\n",
      "epoch =  0 batch =  160 / 1000 loss_uniform =  2.0499045886099347  loss_variational =  2.393684806674718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  161 / 1000 loss_uniform =  2.047660806904669  loss_variational =  2.3900273601460893\n",
      "epoch =  0 batch =  162 / 1000 loss_uniform =  2.0456321290981627  loss_variational =  2.3865088283279787\n",
      "epoch =  0 batch =  163 / 1000 loss_uniform =  2.0436333001025617  loss_variational =  2.3829907822462673\n",
      "epoch =  0 batch =  164 / 1000 loss_uniform =  2.041665043045835  loss_variational =  2.3793153094082338\n",
      "epoch =  0 batch =  165 / 1000 loss_uniform =  2.0395518613584116  loss_variational =  2.3756414189483173\n",
      "epoch =  0 batch =  166 / 1000 loss_uniform =  2.0376053797193325  loss_variational =  2.372096761163458\n",
      "epoch =  0 batch =  167 / 1000 loss_uniform =  2.0357514441370252  loss_variational =  2.368721665022615\n",
      "epoch =  0 batch =  168 / 1000 loss_uniform =  2.0339115616821113  loss_variational =  2.3652909000714613\n",
      "epoch =  0 batch =  169 / 1000 loss_uniform =  2.0320138839574966  loss_variational =  2.3620890936202543\n",
      "epoch =  0 batch =  170 / 1000 loss_uniform =  2.030129954394173  loss_variational =  2.3587685956674456\n",
      "epoch =  0 batch =  171 / 1000 loss_uniform =  2.028255185885737  loss_variational =  2.3554944315848987\n",
      "epoch =  0 batch =  172 / 1000 loss_uniform =  2.02657261975976  loss_variational =  2.3520665044008293\n",
      "epoch =  0 batch =  173 / 1000 loss_uniform =  2.0246314843955076  loss_variational =  2.348793055280784\n",
      "epoch =  0 batch =  174 / 1000 loss_uniform =  2.0228917516511067  loss_variational =  2.345816094299842\n",
      "epoch =  0 batch =  175 / 1000 loss_uniform =  2.020945895739964  loss_variational =  2.342767683437892\n",
      "epoch =  0 batch =  176 / 1000 loss_uniform =  2.0190439027818767  loss_variational =  2.339691124179146\n",
      "epoch =  0 batch =  177 / 1000 loss_uniform =  2.0172951046356373  loss_variational =  2.336164760724299\n",
      "epoch =  0 batch =  178 / 1000 loss_uniform =  2.0156082296639344  loss_variational =  2.332957195431998\n",
      "epoch =  0 batch =  179 / 1000 loss_uniform =  2.013844557980585  loss_variational =  2.329871888267261\n",
      "epoch =  0 batch =  180 / 1000 loss_uniform =  2.0121535440285996  loss_variational =  2.326815111107296\n",
      "epoch =  0 batch =  181 / 1000 loss_uniform =  2.0104598373339315  loss_variational =  2.3237008218607187\n",
      "epoch =  0 batch =  182 / 1000 loss_uniform =  2.0087399842974896  loss_variational =  2.3207555183997517\n",
      "epoch =  0 batch =  183 / 1000 loss_uniform =  2.007095589663812  loss_variational =  2.3178153109680757\n",
      "epoch =  0 batch =  184 / 1000 loss_uniform =  2.0055542789075678  loss_variational =  2.3148975346399387\n",
      "epoch =  0 batch =  185 / 1000 loss_uniform =  2.004007171940158  loss_variational =  2.3120800843109954\n",
      "epoch =  0 batch =  186 / 1000 loss_uniform =  2.002196466410031  loss_variational =  2.3091872988208646\n",
      "epoch =  0 batch =  187 / 1000 loss_uniform =  2.000586813146417  loss_variational =  2.306363930039227\n",
      "epoch =  0 batch =  188 / 1000 loss_uniform =  1.9989509449360212  loss_variational =  2.3033591369365123\n",
      "epoch =  0 batch =  189 / 1000 loss_uniform =  1.997351348715484  loss_variational =  2.30049598532379\n",
      "epoch =  0 batch =  190 / 1000 loss_uniform =  1.9957722111752152  loss_variational =  2.2977238002576326\n",
      "epoch =  0 batch =  191 / 1000 loss_uniform =  1.9941989089806036  loss_variational =  2.294957053598933\n",
      "epoch =  0 batch =  192 / 1000 loss_uniform =  1.9925756398588412  loss_variational =  2.2922898170848685\n",
      "epoch =  0 batch =  193 / 1000 loss_uniform =  1.9911199128689538  loss_variational =  2.289655716925705\n",
      "epoch =  0 batch =  194 / 1000 loss_uniform =  1.9895791067290547  loss_variational =  2.286957092506369\n",
      "epoch =  0 batch =  195 / 1000 loss_uniform =  1.9881349410766205  loss_variational =  2.2842606477248357\n",
      "epoch =  0 batch =  196 / 1000 loss_uniform =  1.9865968178729616  loss_variational =  2.2815105008835688\n",
      "epoch =  0 batch =  197 / 1000 loss_uniform =  1.9850079492869106  loss_variational =  2.278833561137242\n",
      "epoch =  0 batch =  198 / 1000 loss_uniform =  1.983565028869744  loss_variational =  2.276163591278923\n",
      "epoch =  0 batch =  199 / 1000 loss_uniform =  1.9821110304875584  loss_variational =  2.273656819933023\n",
      "epoch =  0 batch =  200 / 1000 loss_uniform =  1.980657585859298  loss_variational =  2.271106573343276\n",
      "epoch =  0 batch =  201 / 1000 loss_uniform =  1.9793681671370316  loss_variational =  2.2686659382350403\n",
      "epoch =  0 batch =  202 / 1000 loss_uniform =  1.9778972533669796  loss_variational =  2.266010475630807\n",
      "epoch =  0 batch =  203 / 1000 loss_uniform =  1.9765184718399793  loss_variational =  2.2635486049605116\n",
      "epoch =  0 batch =  204 / 1000 loss_uniform =  1.9751904571757593  loss_variational =  2.2609708367609507\n",
      "epoch =  0 batch =  205 / 1000 loss_uniform =  1.9738794664057284  loss_variational =  2.2585792948560015\n",
      "epoch =  0 batch =  206 / 1000 loss_uniform =  1.9724056865405104  loss_variational =  2.2560810898114174\n",
      "epoch =  0 batch =  207 / 1000 loss_uniform =  1.970989540579238  loss_variational =  2.253762826251523\n",
      "epoch =  0 batch =  208 / 1000 loss_uniform =  1.969689045961086  loss_variational =  2.251608153948417\n",
      "epoch =  0 batch =  209 / 1000 loss_uniform =  1.9682909535449082  loss_variational =  2.2492560604542637\n",
      "epoch =  0 batch =  210 / 1000 loss_uniform =  1.9669160740716112  loss_variational =  2.246976109913417\n",
      "epoch =  0 batch =  211 / 1000 loss_uniform =  1.9655833334719395  loss_variational =  2.244736577097273\n",
      "epoch =  0 batch =  212 / 1000 loss_uniform =  1.964318545921793  loss_variational =  2.2424322355468314\n",
      "epoch =  0 batch =  213 / 1000 loss_uniform =  1.9630190688119802  loss_variational =  2.2402404524350943\n",
      "epoch =  0 batch =  214 / 1000 loss_uniform =  1.961717659624937  loss_variational =  2.237898540831057\n",
      "epoch =  0 batch =  215 / 1000 loss_uniform =  1.96034808935121  loss_variational =  2.235677171862402\n",
      "epoch =  0 batch =  216 / 1000 loss_uniform =  1.9590658727619379  loss_variational =  2.2334330578645063\n",
      "epoch =  0 batch =  217 / 1000 loss_uniform =  1.9577116537753332  loss_variational =  2.2312593328238624\n",
      "epoch =  0 batch =  218 / 1000 loss_uniform =  1.956371813739111  loss_variational =  2.2290425989605955\n",
      "epoch =  0 batch =  219 / 1000 loss_uniform =  1.9551014949197634  loss_variational =  2.226881004359623\n",
      "epoch =  0 batch =  220 / 1000 loss_uniform =  1.9538827516815873  loss_variational =  2.224679825522682\n",
      "epoch =  0 batch =  221 / 1000 loss_uniform =  1.95275776958034  loss_variational =  2.222589717731216\n",
      "epoch =  0 batch =  222 / 1000 loss_uniform =  1.9515329169797462  loss_variational =  2.220515346204911\n",
      "epoch =  0 batch =  223 / 1000 loss_uniform =  1.9503206469018357  loss_variational =  2.218367650369891\n",
      "epoch =  0 batch =  224 / 1000 loss_uniform =  1.9490029247743739  loss_variational =  2.2163813747465597\n",
      "epoch =  0 batch =  225 / 1000 loss_uniform =  1.947929938104417  loss_variational =  2.2142779583401135\n",
      "epoch =  0 batch =  226 / 1000 loss_uniform =  1.9467582011644815  loss_variational =  2.2123465596047107\n",
      "epoch =  0 batch =  227 / 1000 loss_uniform =  1.9455689606687565  loss_variational =  2.210305952290605\n",
      "epoch =  0 batch =  228 / 1000 loss_uniform =  1.9443949785148884  loss_variational =  2.208328152957714\n",
      "epoch =  0 batch =  229 / 1000 loss_uniform =  1.9432601022928557  loss_variational =  2.2062490548629414\n",
      "epoch =  0 batch =  230 / 1000 loss_uniform =  1.9421083294827  loss_variational =  2.2042859077453603\n",
      "epoch =  0 batch =  231 / 1000 loss_uniform =  1.940980034473138  loss_variational =  2.20225306868037\n",
      "epoch =  0 batch =  232 / 1000 loss_uniform =  1.9398589303781242  loss_variational =  2.2003552209714354\n",
      "epoch =  0 batch =  233 / 1000 loss_uniform =  1.9387846658158194  loss_variational =  2.1983653808356345\n",
      "epoch =  0 batch =  234 / 1000 loss_uniform =  1.9377508871575702  loss_variational =  2.19651109082067\n",
      "epoch =  0 batch =  235 / 1000 loss_uniform =  1.9366155375825593  loss_variational =  2.194641166544974\n",
      "epoch =  0 batch =  236 / 1000 loss_uniform =  1.9356012410026482  loss_variational =  2.192768865217596\n",
      "epoch =  0 batch =  237 / 1000 loss_uniform =  1.9345418144378979  loss_variational =  2.1909011577252087\n",
      "epoch =  0 batch =  238 / 1000 loss_uniform =  1.9335516500873722  loss_variational =  2.1890451662680674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  239 / 1000 loss_uniform =  1.9325100068766696  loss_variational =  2.1872250500084456\n",
      "epoch =  0 batch =  240 / 1000 loss_uniform =  1.9314478784799571  loss_variational =  2.185433349510033\n",
      "epoch =  0 batch =  241 / 1000 loss_uniform =  1.9303882572166153  loss_variational =  2.1836693855736753\n",
      "epoch =  0 batch =  242 / 1000 loss_uniform =  1.9292671192776067  loss_variational =  2.1820429154664023\n",
      "epoch =  0 batch =  243 / 1000 loss_uniform =  1.9283219561164757  loss_variational =  2.1802525981463514\n",
      "epoch =  0 batch =  244 / 1000 loss_uniform =  1.9272636531806377  loss_variational =  2.178476048786131\n",
      "epoch =  0 batch =  245 / 1000 loss_uniform =  1.9262617763207879  loss_variational =  2.176736729485647\n",
      "epoch =  0 batch =  246 / 1000 loss_uniform =  1.9252146283785498  loss_variational =  2.1748035797258694\n",
      "epoch =  0 batch =  247 / 1000 loss_uniform =  1.9242078268576244  loss_variational =  2.17288868099089\n",
      "epoch =  0 batch =  248 / 1000 loss_uniform =  1.923202096935241  loss_variational =  2.1713572375236008\n",
      "epoch =  0 batch =  249 / 1000 loss_uniform =  1.9222116858126164  loss_variational =  2.169722220026345\n",
      "epoch =  0 batch =  250 / 1000 loss_uniform =  1.9211648225784297  loss_variational =  2.16799638223648\n",
      "epoch =  0 batch =  251 / 1000 loss_uniform =  1.9201360238025857  loss_variational =  2.1663078482882425\n",
      "epoch =  0 batch =  252 / 1000 loss_uniform =  1.9191392489842  loss_variational =  2.1646159513602172\n",
      "epoch =  0 batch =  253 / 1000 loss_uniform =  1.9181259215584852  loss_variational =  2.1630335028463663\n",
      "epoch =  0 batch =  254 / 1000 loss_uniform =  1.917161096738079  loss_variational =  2.1615263547484322\n",
      "epoch =  0 batch =  255 / 1000 loss_uniform =  1.9162284103094358  loss_variational =  2.159939070308909\n",
      "epoch =  0 batch =  256 / 1000 loss_uniform =  1.915319350548088  loss_variational =  2.1584267406724384\n",
      "epoch =  0 batch =  257 / 1000 loss_uniform =  1.9143271525082417  loss_variational =  2.156776388331609\n",
      "epoch =  0 batch =  258 / 1000 loss_uniform =  1.9134297731310819  loss_variational =  2.1552212515542664\n",
      "epoch =  0 batch =  259 / 1000 loss_uniform =  1.9124902808988413  loss_variational =  2.1535283363924056\n",
      "epoch =  0 batch =  260 / 1000 loss_uniform =  1.911587088841658  loss_variational =  2.1519633261057036\n",
      "epoch =  0 batch =  261 / 1000 loss_uniform =  1.9106000168570152  loss_variational =  2.1504297644699206\n",
      "epoch =  0 batch =  262 / 1000 loss_uniform =  1.909745857915805  loss_variational =  2.148894485171514\n",
      "epoch =  0 batch =  263 / 1000 loss_uniform =  1.9088951285801001  loss_variational =  2.1472356011205744\n",
      "epoch =  0 batch =  264 / 1000 loss_uniform =  1.9080085912437146  loss_variational =  2.145579421610542\n",
      "epoch =  0 batch =  265 / 1000 loss_uniform =  1.9071069312545483  loss_variational =  2.1439547718695864\n",
      "epoch =  0 batch =  266 / 1000 loss_uniform =  1.9061627728598454  loss_variational =  2.14241518965341\n",
      "epoch =  0 batch =  267 / 1000 loss_uniform =  1.9052376934651574  loss_variational =  2.1408653844161862\n",
      "epoch =  0 batch =  268 / 1000 loss_uniform =  1.90437709306603  loss_variational =  2.139292066221805\n",
      "epoch =  0 batch =  269 / 1000 loss_uniform =  1.9035489213510957  loss_variational =  2.137882425439401\n",
      "epoch =  0 batch =  270 / 1000 loss_uniform =  1.9027140723334415  loss_variational =  2.136388923945249\n",
      "epoch =  0 batch =  271 / 1000 loss_uniform =  1.9018873622936512  loss_variational =  2.134981817424956\n",
      "epoch =  0 batch =  272 / 1000 loss_uniform =  1.901060696910409  loss_variational =  2.1335428979466933\n",
      "epoch =  0 batch =  273 / 1000 loss_uniform =  1.9002936248814226  loss_variational =  2.132064534630967\n",
      "epoch =  0 batch =  274 / 1000 loss_uniform =  1.8995340431693692  loss_variational =  2.1306694819979417\n",
      "epoch =  0 batch =  275 / 1000 loss_uniform =  1.8987225528196852  loss_variational =  2.1291257355429902\n",
      "epoch =  0 batch =  276 / 1000 loss_uniform =  1.8979916175206497  loss_variational =  2.127761364846989\n",
      "epoch =  0 batch =  277 / 1000 loss_uniform =  1.8971477927714044  loss_variational =  2.1264937599643465\n",
      "epoch =  0 batch =  278 / 1000 loss_uniform =  1.8963203743207364  loss_variational =  2.125044058552748\n",
      "epoch =  0 batch =  279 / 1000 loss_uniform =  1.8956311488237  loss_variational =  2.1235149910800337\n",
      "epoch =  0 batch =  280 / 1000 loss_uniform =  1.8948167622089382  loss_variational =  2.1220187664031975\n",
      "epoch =  0 batch =  281 / 1000 loss_uniform =  1.8940852914416488  loss_variational =  2.1206220846583403\n",
      "epoch =  0 batch =  282 / 1000 loss_uniform =  1.8933042232871897  loss_variational =  2.11925883538334\n",
      "epoch =  0 batch =  283 / 1000 loss_uniform =  1.8925093635653434  loss_variational =  2.117917480822586\n",
      "epoch =  0 batch =  284 / 1000 loss_uniform =  1.8917247430539463  loss_variational =  2.1164508806148037\n",
      "epoch =  0 batch =  285 / 1000 loss_uniform =  1.8908788078709649  loss_variational =  2.1150813328592393\n",
      "epoch =  0 batch =  286 / 1000 loss_uniform =  1.8901033030523282  loss_variational =  2.1138262927949003\n",
      "epoch =  0 batch =  287 / 1000 loss_uniform =  1.8893194613971773  loss_variational =  2.1124735430973325\n",
      "epoch =  0 batch =  288 / 1000 loss_uniform =  1.8885915631221397  loss_variational =  2.111111962960825\n",
      "epoch =  0 batch =  289 / 1000 loss_uniform =  1.8878488581898298  loss_variational =  2.109827741619624\n",
      "epoch =  0 batch =  290 / 1000 loss_uniform =  1.887137507159134  loss_variational =  2.10859023538129\n",
      "epoch =  0 batch =  291 / 1000 loss_uniform =  1.8864043594635636  loss_variational =  2.107205479005767\n",
      "epoch =  0 batch =  292 / 1000 loss_uniform =  1.8857299603828008  loss_variational =  2.1059584601284698\n",
      "epoch =  0 batch =  293 / 1000 loss_uniform =  1.885036753713067  loss_variational =  2.10480954907453\n",
      "epoch =  0 batch =  294 / 1000 loss_uniform =  1.8843587799137138  loss_variational =  2.10357337257489\n",
      "epoch =  0 batch =  295 / 1000 loss_uniform =  1.8836211640956033  loss_variational =  2.1024105872138064\n",
      "epoch =  0 batch =  296 / 1000 loss_uniform =  1.8828928047740778  loss_variational =  2.1012071065000577\n",
      "epoch =  0 batch =  297 / 1000 loss_uniform =  1.8821292850706308  loss_variational =  2.0999144404022774\n",
      "epoch =  0 batch =  298 / 1000 loss_uniform =  1.8814381188994282  loss_variational =  2.0986908150199266\n",
      "epoch =  0 batch =  299 / 1000 loss_uniform =  1.8807139556144787  loss_variational =  2.097331583699254\n",
      "epoch =  0 batch =  300 / 1000 loss_uniform =  1.8800502125422156  loss_variational =  2.0961160083611796\n",
      "epoch =  0 batch =  301 / 1000 loss_uniform =  1.8793109453397727  loss_variational =  2.094856984987606\n",
      "epoch =  0 batch =  302 / 1000 loss_uniform =  1.8785764006589418  loss_variational =  2.093630217163767\n",
      "epoch =  0 batch =  303 / 1000 loss_uniform =  1.8778945837083818  loss_variational =  2.0924819294768975\n",
      "epoch =  0 batch =  304 / 1000 loss_uniform =  1.8772115378003367  loss_variational =  2.0912466198205935\n",
      "epoch =  0 batch =  305 / 1000 loss_uniform =  1.8765011361387907  loss_variational =  2.0899755872663888\n",
      "epoch =  0 batch =  306 / 1000 loss_uniform =  1.8757988409279216  loss_variational =  2.088790446325064\n",
      "epoch =  0 batch =  307 / 1000 loss_uniform =  1.875154335646365  loss_variational =  2.0875172090841025\n",
      "epoch =  0 batch =  308 / 1000 loss_uniform =  1.874478681908025  loss_variational =  2.0863370965053494\n",
      "epoch =  0 batch =  309 / 1000 loss_uniform =  1.8738616697224981  loss_variational =  2.0850585328722446\n",
      "epoch =  0 batch =  310 / 1000 loss_uniform =  1.8732193719956178  loss_variational =  2.0838912229384126\n",
      "epoch =  0 batch =  311 / 1000 loss_uniform =  1.8725290551446254  loss_variational =  2.0827617760256536\n",
      "epoch =  0 batch =  312 / 1000 loss_uniform =  1.871850843612964  loss_variational =  2.0816303212673217\n",
      "epoch =  0 batch =  313 / 1000 loss_uniform =  1.871171579193383  loss_variational =  2.0805428892659665\n",
      "epoch =  0 batch =  314 / 1000 loss_uniform =  1.8705153013490563  loss_variational =  2.079410382516823\n",
      "epoch =  0 batch =  315 / 1000 loss_uniform =  1.8698621246549814  loss_variational =  2.078263218819147\n",
      "epoch =  0 batch =  316 / 1000 loss_uniform =  1.8692280242714696  loss_variational =  2.0772030662886687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  317 / 1000 loss_uniform =  1.8685860302922097  loss_variational =  2.076131899650163\n",
      "epoch =  0 batch =  318 / 1000 loss_uniform =  1.8679304089186324  loss_variational =  2.0750249954139646\n",
      "epoch =  0 batch =  319 / 1000 loss_uniform =  1.8672990361724897  loss_variational =  2.0738772082851957\n",
      "epoch =  0 batch =  320 / 1000 loss_uniform =  1.8666543878614898  loss_variational =  2.072725166752933\n",
      "epoch =  0 batch =  321 / 1000 loss_uniform =  1.8660089353163292  loss_variational =  2.071570485180411\n",
      "epoch =  0 batch =  322 / 1000 loss_uniform =  1.865405592488946  loss_variational =  2.0704875218201853\n",
      "epoch =  0 batch =  323 / 1000 loss_uniform =  1.8647686294726908  loss_variational =  2.0693698700736536\n",
      "epoch =  0 batch =  324 / 1000 loss_uniform =  1.8641192732769762  loss_variational =  2.0683162823135457\n",
      "epoch =  0 batch =  325 / 1000 loss_uniform =  1.8635186136685882  loss_variational =  2.067366305497975\n",
      "epoch =  0 batch =  326 / 1000 loss_uniform =  1.862933545024848  loss_variational =  2.066205132592674\n",
      "epoch =  0 batch =  327 / 1000 loss_uniform =  1.8622640477043404  loss_variational =  2.065042016703053\n",
      "epoch =  0 batch =  328 / 1000 loss_uniform =  1.8616182887699542  loss_variational =  2.0639250765486445\n",
      "epoch =  0 batch =  329 / 1000 loss_uniform =  1.8610178609024786  loss_variational =  2.0628537936051186\n",
      "epoch =  0 batch =  330 / 1000 loss_uniform =  1.8604007475303879  loss_variational =  2.0618355364510492\n",
      "epoch =  0 batch =  331 / 1000 loss_uniform =  1.8598182795631197  loss_variational =  2.0608216819446237\n",
      "epoch =  0 batch =  332 / 1000 loss_uniform =  1.8592192771204978  loss_variational =  2.0598110071865894\n",
      "epoch =  0 batch =  333 / 1000 loss_uniform =  1.858629517011098  loss_variational =  2.058733116757045\n",
      "epoch =  0 batch =  334 / 1000 loss_uniform =  1.858020018674656  loss_variational =  2.057713002501846\n",
      "epoch =  0 batch =  335 / 1000 loss_uniform =  1.857438605934826  loss_variational =  2.056680831980348\n",
      "epoch =  0 batch =  336 / 1000 loss_uniform =  1.8568588598143483  loss_variational =  2.0556350793866867\n",
      "epoch =  0 batch =  337 / 1000 loss_uniform =  1.8562493805361782  loss_variational =  2.0546136885792974\n",
      "epoch =  0 batch =  338 / 1000 loss_uniform =  1.8556276369376998  loss_variational =  2.0535987985910027\n",
      "epoch =  0 batch =  339 / 1000 loss_uniform =  1.8551032311093487  loss_variational =  2.0526751279830915\n",
      "epoch =  0 batch =  340 / 1000 loss_uniform =  1.8544790786855359  loss_variational =  2.051709148112464\n",
      "epoch =  0 batch =  341 / 1000 loss_uniform =  1.8538928968815507  loss_variational =  2.0507237918216097\n",
      "epoch =  0 batch =  342 / 1000 loss_uniform =  1.8533143467373314  loss_variational =  2.049791476531334\n",
      "epoch =  0 batch =  343 / 1000 loss_uniform =  1.8527380234993578  loss_variational =  2.048785790410054\n",
      "epoch =  0 batch =  344 / 1000 loss_uniform =  1.8520928583172862  loss_variational =  2.0478037893772107\n",
      "epoch =  0 batch =  345 / 1000 loss_uniform =  1.8515126656794891  loss_variational =  2.046859603342801\n",
      "epoch =  0 batch =  346 / 1000 loss_uniform =  1.8509585905626327  loss_variational =  2.045924191530039\n",
      "epoch =  0 batch =  347 / 1000 loss_uniform =  1.8504222710469267  loss_variational =  2.045055264698324\n",
      "epoch =  0 batch =  348 / 1000 loss_uniform =  1.8498271676315654  loss_variational =  2.0441655180920115\n",
      "epoch =  0 batch =  349 / 1000 loss_uniform =  1.8492051468879238  loss_variational =  2.0432418683880025\n",
      "epoch =  0 batch =  350 / 1000 loss_uniform =  1.8486657701219829  loss_variational =  2.0423132198197487\n",
      "epoch =  0 batch =  351 / 1000 loss_uniform =  1.8480937525078098  loss_variational =  2.0414013074673805\n",
      "epoch =  0 batch =  352 / 1000 loss_uniform =  1.8475269400937988  loss_variational =  2.0405484766445365\n",
      "epoch =  0 batch =  353 / 1000 loss_uniform =  1.8469961267017436  loss_variational =  2.039629830517106\n",
      "epoch =  0 batch =  354 / 1000 loss_uniform =  1.8464622416738734  loss_variational =  2.038735422374164\n",
      "epoch =  0 batch =  355 / 1000 loss_uniform =  1.8459149884506008  loss_variational =  2.0378837555227136\n",
      "epoch =  0 batch =  356 / 1000 loss_uniform =  1.8454118143306686  loss_variational =  2.0369426055570656\n",
      "epoch =  0 batch =  357 / 1000 loss_uniform =  1.8448433074630606  loss_variational =  2.035940487845604\n",
      "epoch =  0 batch =  358 / 1000 loss_uniform =  1.8443043035501872  loss_variational =  2.0350737361934583\n",
      "epoch =  0 batch =  359 / 1000 loss_uniform =  1.8437692501418768  loss_variational =  2.034227302479543\n",
      "epoch =  0 batch =  360 / 1000 loss_uniform =  1.843245023488998  loss_variational =  2.033275883396465\n",
      "epoch =  0 batch =  361 / 1000 loss_uniform =  1.8427533092921458  loss_variational =  2.0324743718651836\n",
      "epoch =  0 batch =  362 / 1000 loss_uniform =  1.8422423545168247  loss_variational =  2.03159128499953\n",
      "epoch =  0 batch =  363 / 1000 loss_uniform =  1.8417503344454382  loss_variational =  2.0306898142023835\n",
      "epoch =  0 batch =  364 / 1000 loss_uniform =  1.84120303097662  loss_variational =  2.029887808220726\n",
      "epoch =  0 batch =  365 / 1000 loss_uniform =  1.8406852895266386  loss_variational =  2.0289883567862304\n",
      "epoch =  0 batch =  366 / 1000 loss_uniform =  1.8402010899423897  loss_variational =  2.0281884644200883\n",
      "epoch =  0 batch =  367 / 1000 loss_uniform =  1.8396761557061923  loss_variational =  2.0272868686540892\n",
      "epoch =  0 batch =  368 / 1000 loss_uniform =  1.8391562648441477  loss_variational =  2.026472412373708\n",
      "epoch =  0 batch =  369 / 1000 loss_uniform =  1.838606248703106  loss_variational =  2.025587065110038\n",
      "epoch =  0 batch =  370 / 1000 loss_uniform =  1.838129915095664  loss_variational =  2.0247027777336735\n",
      "epoch =  0 batch =  371 / 1000 loss_uniform =  1.837657570517609  loss_variational =  2.0238640648978095\n",
      "epoch =  0 batch =  372 / 1000 loss_uniform =  1.8371609930069213  loss_variational =  2.0229866334827995\n",
      "epoch =  0 batch =  373 / 1000 loss_uniform =  1.8366866623108888  loss_variational =  2.022079048783146\n",
      "epoch =  0 batch =  374 / 1000 loss_uniform =  1.8361652984338646  loss_variational =  2.021229634947955\n",
      "epoch =  0 batch =  375 / 1000 loss_uniform =  1.8356772692998247  loss_variational =  2.020366231918335\n",
      "epoch =  0 batch =  376 / 1000 loss_uniform =  1.8351994600701835  loss_variational =  2.0195124802437237\n",
      "epoch =  0 batch =  377 / 1000 loss_uniform =  1.8347882728045433  loss_variational =  2.0188182247728506\n",
      "epoch =  0 batch =  378 / 1000 loss_uniform =  1.8342737177061652  loss_variational =  2.017966633751279\n",
      "epoch =  0 batch =  379 / 1000 loss_uniform =  1.833856866667956  loss_variational =  2.0171363907313284\n",
      "epoch =  0 batch =  380 / 1000 loss_uniform =  1.8334163179523064  loss_variational =  2.0163886810603895\n",
      "epoch =  0 batch =  381 / 1000 loss_uniform =  1.8329572396015554  loss_variational =  2.0155312426759817\n",
      "epoch =  0 batch =  382 / 1000 loss_uniform =  1.832443240113283  loss_variational =  2.014683114608545\n",
      "epoch =  0 batch =  383 / 1000 loss_uniform =  1.8320329419626578  loss_variational =  2.0137944479835252\n",
      "epoch =  0 batch =  384 / 1000 loss_uniform =  1.8316273434708512  loss_variational =  2.013044076040387\n",
      "epoch =  0 batch =  385 / 1000 loss_uniform =  1.8311736812839257  loss_variational =  2.0122786178217305\n",
      "epoch =  0 batch =  386 / 1000 loss_uniform =  1.8307556225845847  loss_variational =  2.0115279870329745\n",
      "epoch =  0 batch =  387 / 1000 loss_uniform =  1.8303223645040227  loss_variational =  2.0107253109145846\n",
      "epoch =  0 batch =  388 / 1000 loss_uniform =  1.8298659638031238  loss_variational =  2.010009827380328\n",
      "epoch =  0 batch =  389 / 1000 loss_uniform =  1.8293992976602977  loss_variational =  2.0092462552543777\n",
      "epoch =  0 batch =  390 / 1000 loss_uniform =  1.8289638027166706  loss_variational =  2.008467305317903\n",
      "epoch =  0 batch =  391 / 1000 loss_uniform =  1.8285329302253623  loss_variational =  2.0076816685669256\n",
      "epoch =  0 batch =  392 / 1000 loss_uniform =  1.8280702354956644  loss_variational =  2.00700038184925\n",
      "epoch =  0 batch =  393 / 1000 loss_uniform =  1.8276846190445293  loss_variational =  2.006200936611069\n",
      "epoch =  0 batch =  394 / 1000 loss_uniform =  1.8272193649093509  loss_variational =  2.0054532455913914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  395 / 1000 loss_uniform =  1.8267748561086532  loss_variational =  2.0047204974331434\n",
      "epoch =  0 batch =  396 / 1000 loss_uniform =  1.8263300569972605  loss_variational =  2.0039694167748845\n",
      "epoch =  0 batch =  397 / 1000 loss_uniform =  1.8259011906400433  loss_variational =  2.0032381218686814\n",
      "epoch =  0 batch =  398 / 1000 loss_uniform =  1.8254244075947668  loss_variational =  2.0024736113284702\n",
      "epoch =  0 batch =  399 / 1000 loss_uniform =  1.8249941224741155  loss_variational =  2.001693761438356\n",
      "epoch =  0 batch =  400 / 1000 loss_uniform =  1.8245380419492718  loss_variational =  2.0009630483388907\n",
      "epoch =  0 batch =  401 / 1000 loss_uniform =  1.824127712451906  loss_variational =  2.0002194134671796\n",
      "epoch =  0 batch =  402 / 1000 loss_uniform =  1.823722595006079  loss_variational =  1.9994512585858213\n",
      "epoch =  0 batch =  403 / 1000 loss_uniform =  1.8233171358297833  loss_variational =  1.9986753336549106\n",
      "epoch =  0 batch =  404 / 1000 loss_uniform =  1.8229082571988056  loss_variational =  1.9978850035384155\n",
      "epoch =  0 batch =  405 / 1000 loss_uniform =  1.822465430954356  loss_variational =  1.9971967676539486\n",
      "epoch =  0 batch =  406 / 1000 loss_uniform =  1.8220601648532695  loss_variational =  1.9964060730534827\n",
      "epoch =  0 batch =  407 / 1000 loss_uniform =  1.8216380879685683  loss_variational =  1.9956898185486296\n",
      "epoch =  0 batch =  408 / 1000 loss_uniform =  1.8212210620735203  loss_variational =  1.9949231726281789\n",
      "epoch =  0 batch =  409 / 1000 loss_uniform =  1.8208021913589065  loss_variational =  1.9942064407693734\n",
      "epoch =  0 batch =  410 / 1000 loss_uniform =  1.8203947549912984  loss_variational =  1.9934281200897408\n",
      "epoch =  0 batch =  411 / 1000 loss_uniform =  1.8200126164150932  loss_variational =  1.9926789070857998\n",
      "epoch =  0 batch =  412 / 1000 loss_uniform =  1.8195960044282151  loss_variational =  1.9919763152460455\n",
      "epoch =  0 batch =  413 / 1000 loss_uniform =  1.8191941835112488  loss_variational =  1.9913038107731158\n",
      "epoch =  0 batch =  414 / 1000 loss_uniform =  1.8187960786519992  loss_variational =  1.9905916501358516\n",
      "epoch =  0 batch =  415 / 1000 loss_uniform =  1.8184096594890913  loss_variational =  1.989938298765436\n",
      "epoch =  0 batch =  416 / 1000 loss_uniform =  1.8180113790126944  loss_variational =  1.989234128537087\n",
      "epoch =  0 batch =  417 / 1000 loss_uniform =  1.8175951542614173  loss_variational =  1.988593616931559\n",
      "epoch =  0 batch =  418 / 1000 loss_uniform =  1.8171687619537826  loss_variational =  1.9878980648574651\n",
      "epoch =  0 batch =  419 / 1000 loss_uniform =  1.816788733432287  loss_variational =  1.9871818726273316\n",
      "epoch =  0 batch =  420 / 1000 loss_uniform =  1.8163808748835606  loss_variational =  1.9864686985810602\n",
      "epoch =  0 batch =  421 / 1000 loss_uniform =  1.8159550660579615  loss_variational =  1.9857611508947093\n",
      "epoch =  0 batch =  422 / 1000 loss_uniform =  1.8155763629488468  loss_variational =  1.9851525564329324\n",
      "epoch =  0 batch =  423 / 1000 loss_uniform =  1.8151764021415797  loss_variational =  1.984467955063985\n",
      "epoch =  0 batch =  424 / 1000 loss_uniform =  1.8147770323843324  loss_variational =  1.983846450470529\n",
      "epoch =  0 batch =  425 / 1000 loss_uniform =  1.8143440111945655  loss_variational =  1.9832062768936163\n",
      "epoch =  0 batch =  426 / 1000 loss_uniform =  1.8139569767763914  loss_variational =  1.9825634438666944\n",
      "epoch =  0 batch =  427 / 1000 loss_uniform =  1.8135761812643365  loss_variational =  1.9819181300437987\n",
      "epoch =  0 batch =  428 / 1000 loss_uniform =  1.8131549784513274  loss_variational =  1.981217856997642\n",
      "epoch =  0 batch =  429 / 1000 loss_uniform =  1.812791368900201  loss_variational =  1.9805850415796673\n",
      "epoch =  0 batch =  430 / 1000 loss_uniform =  1.812412507866704  loss_variational =  1.9798467649969949\n",
      "epoch =  0 batch =  431 / 1000 loss_uniform =  1.8120412480803485  loss_variational =  1.9791829104766496\n",
      "epoch =  0 batch =  432 / 1000 loss_uniform =  1.8116880718756603  loss_variational =  1.9784975112588323\n",
      "epoch =  0 batch =  433 / 1000 loss_uniform =  1.8113223234445335  loss_variational =  1.9778835696381185\n",
      "epoch =  0 batch =  434 / 1000 loss_uniform =  1.8109601549289192  loss_variational =  1.9771866073256819\n",
      "epoch =  0 batch =  435 / 1000 loss_uniform =  1.8105838504330862  loss_variational =  1.9766355829677367\n",
      "epoch =  0 batch =  436 / 1000 loss_uniform =  1.810204057791911  loss_variational =  1.9759740711898983\n",
      "epoch =  0 batch =  437 / 1000 loss_uniform =  1.8098632762852194  loss_variational =  1.97532277849228\n",
      "epoch =  0 batch =  438 / 1000 loss_uniform =  1.8095007566012202  loss_variational =  1.9746630951149828\n",
      "epoch =  0 batch =  439 / 1000 loss_uniform =  1.8091191455280589  loss_variational =  1.9740543756506714\n",
      "epoch =  0 batch =  440 / 1000 loss_uniform =  1.8087770651687272  loss_variational =  1.9734269513325262\n",
      "epoch =  0 batch =  441 / 1000 loss_uniform =  1.808423160695705  loss_variational =  1.9728055959926447\n",
      "epoch =  0 batch =  442 / 1000 loss_uniform =  1.808089226079742  loss_variational =  1.9721757510668556\n",
      "epoch =  0 batch =  443 / 1000 loss_uniform =  1.8077485391840706  loss_variational =  1.9715480344290124\n",
      "epoch =  0 batch =  444 / 1000 loss_uniform =  1.8074142044191959  loss_variational =  1.970957796584379\n",
      "epoch =  0 batch =  445 / 1000 loss_uniform =  1.8070658319451833  loss_variational =  1.970345045475478\n",
      "epoch =  0 batch =  446 / 1000 loss_uniform =  1.8067082388518634  loss_variational =  1.9697684656344192\n",
      "epoch =  0 batch =  447 / 1000 loss_uniform =  1.8063570602361518  loss_variational =  1.9691223186134497\n",
      "epoch =  0 batch =  448 / 1000 loss_uniform =  1.8059660057936393  loss_variational =  1.9685143277581254\n",
      "epoch =  0 batch =  449 / 1000 loss_uniform =  1.8056220116222355  loss_variational =  1.9678965952985807\n",
      "epoch =  0 batch =  450 / 1000 loss_uniform =  1.8052776180373296  loss_variational =  1.9673010473781167\n",
      "epoch =  0 batch =  451 / 1000 loss_uniform =  1.8049386554705327  loss_variational =  1.966712754475833\n",
      "epoch =  0 batch =  452 / 1000 loss_uniform =  1.804593058550252  loss_variational =  1.9660695158274832\n",
      "epoch =  0 batch =  453 / 1000 loss_uniform =  1.8042559963188423  loss_variational =  1.9655609120333173\n",
      "epoch =  0 batch =  454 / 1000 loss_uniform =  1.803910354685678  loss_variational =  1.9649609201280036\n",
      "epoch =  0 batch =  455 / 1000 loss_uniform =  1.8035550722709066  loss_variational =  1.9643492020093483\n",
      "epoch =  0 batch =  456 / 1000 loss_uniform =  1.8032177772961162  loss_variational =  1.963816589953607\n",
      "epoch =  0 batch =  457 / 1000 loss_uniform =  1.8028842688128512  loss_variational =  1.9632200654799885\n",
      "epoch =  0 batch =  458 / 1000 loss_uniform =  1.8025257863332087  loss_variational =  1.9626624264050785\n",
      "epoch =  0 batch =  459 / 1000 loss_uniform =  1.802185951494703  loss_variational =  1.9620902216252682\n",
      "epoch =  0 batch =  460 / 1000 loss_uniform =  1.801834159830342  loss_variational =  1.961527706229169\n",
      "epoch =  0 batch =  461 / 1000 loss_uniform =  1.8015087853284821  loss_variational =  1.960994627367132\n",
      "epoch =  0 batch =  462 / 1000 loss_uniform =  1.8011986729386562  loss_variational =  1.960422146629978\n",
      "epoch =  0 batch =  463 / 1000 loss_uniform =  1.8008927845800409  loss_variational =  1.9598587689595401\n",
      "epoch =  0 batch =  464 / 1000 loss_uniform =  1.8005557471308213  loss_variational =  1.9593670697047798\n",
      "epoch =  0 batch =  465 / 1000 loss_uniform =  1.8001831572542906  loss_variational =  1.9587410808891383\n",
      "epoch =  0 batch =  466 / 1000 loss_uniform =  1.7998828312358117  loss_variational =  1.9582283072205577\n",
      "epoch =  0 batch =  467 / 1000 loss_uniform =  1.7995549284671561  loss_variational =  1.9576377860994365\n",
      "epoch =  0 batch =  468 / 1000 loss_uniform =  1.7992034465329259  loss_variational =  1.9570454417640333\n",
      "epoch =  0 batch =  469 / 1000 loss_uniform =  1.7988480060085303  loss_variational =  1.9565074995382512\n",
      "epoch =  0 batch =  470 / 1000 loss_uniform =  1.7985254736656835  loss_variational =  1.955934257963871\n",
      "epoch =  0 batch =  471 / 1000 loss_uniform =  1.7981646913884803  loss_variational =  1.9553603371743695\n",
      "epoch =  0 batch =  472 / 1000 loss_uniform =  1.797829355476266  loss_variational =  1.9548054082413857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  473 / 1000 loss_uniform =  1.7975454753851536  loss_variational =  1.954235821647322\n",
      "epoch =  0 batch =  474 / 1000 loss_uniform =  1.7972292301524035  loss_variational =  1.9537267164338998\n",
      "epoch =  0 batch =  475 / 1000 loss_uniform =  1.796922266859757  loss_variational =  1.9531482829545679\n",
      "epoch =  0 batch =  476 / 1000 loss_uniform =  1.7965903314722684  loss_variational =  1.9525916075506136\n",
      "epoch =  0 batch =  477 / 1000 loss_uniform =  1.7963081763225528  loss_variational =  1.952057540041846\n",
      "epoch =  0 batch =  478 / 1000 loss_uniform =  1.7960029760663976  loss_variational =  1.9515471790126182\n",
      "epoch =  0 batch =  479 / 1000 loss_uniform =  1.7957285754615924  loss_variational =  1.9510152235409417\n",
      "epoch =  0 batch =  480 / 1000 loss_uniform =  1.7953951266904669  loss_variational =  1.9504346753160164\n",
      "epoch =  0 batch =  481 / 1000 loss_uniform =  1.7950584142470805  loss_variational =  1.9499273124207086\n",
      "epoch =  0 batch =  482 / 1000 loss_uniform =  1.79478390335542  loss_variational =  1.9493973176014379\n",
      "epoch =  0 batch =  483 / 1000 loss_uniform =  1.794481006715115  loss_variational =  1.948931565442688\n",
      "epoch =  0 batch =  484 / 1000 loss_uniform =  1.7941762260661636  loss_variational =  1.948399943753708\n",
      "epoch =  0 batch =  485 / 1000 loss_uniform =  1.7938912885705218  loss_variational =  1.947875310465233\n",
      "epoch =  0 batch =  486 / 1000 loss_uniform =  1.7935579860651931  loss_variational =  1.947394327862273\n",
      "epoch =  0 batch =  487 / 1000 loss_uniform =  1.7932492452970028  loss_variational =  1.9468458908049726\n",
      "epoch =  0 batch =  488 / 1000 loss_uniform =  1.792976005155532  loss_variational =  1.9463087882174825\n",
      "epoch =  0 batch =  489 / 1000 loss_uniform =  1.7926781596825407  loss_variational =  1.9458037224771547\n",
      "epoch =  0 batch =  490 / 1000 loss_uniform =  1.7923946244376043  loss_variational =  1.945195769047251\n",
      "epoch =  0 batch =  491 / 1000 loss_uniform =  1.7920773803823589  loss_variational =  1.9446130289322494\n",
      "epoch =  0 batch =  492 / 1000 loss_uniform =  1.7917922672217452  loss_variational =  1.9440879293573585\n",
      "epoch =  0 batch =  493 / 1000 loss_uniform =  1.7914766232817456  loss_variational =  1.9435496983131584\n",
      "epoch =  0 batch =  494 / 1000 loss_uniform =  1.7911705524332608  loss_variational =  1.943035501941496\n",
      "epoch =  0 batch =  495 / 1000 loss_uniform =  1.7908732903124103  loss_variational =  1.9425831431090235\n",
      "epoch =  0 batch =  496 / 1000 loss_uniform =  1.790576372175447  loss_variational =  1.9421225555481454\n",
      "epoch =  0 batch =  497 / 1000 loss_uniform =  1.7902930526426377  loss_variational =  1.9416517501385884\n",
      "epoch =  0 batch =  498 / 1000 loss_uniform =  1.790019045871903  loss_variational =  1.9411832407775178\n",
      "epoch =  0 batch =  499 / 1000 loss_uniform =  1.789742301843448  loss_variational =  1.940683351728864\n",
      "epoch =  0 batch =  500 / 1000 loss_uniform =  1.7894367656707761  loss_variational =  1.9401640625000005\n",
      "epoch =  0 batch =  501 / 1000 loss_uniform =  1.789134328712722  loss_variational =  1.9396873170030335\n",
      "epoch =  0 batch =  502 / 1000 loss_uniform =  1.7888578076761554  loss_variational =  1.9391827215236501\n",
      "epoch =  0 batch =  503 / 1000 loss_uniform =  1.7885666196910333  loss_variational =  1.938704945932089\n",
      "epoch =  0 batch =  504 / 1000 loss_uniform =  1.7882608589198852  loss_variational =  1.9382110947654365\n",
      "epoch =  0 batch =  505 / 1000 loss_uniform =  1.7879517748804374  loss_variational =  1.9376999227127232\n",
      "epoch =  0 batch =  506 / 1000 loss_uniform =  1.7876413031057876  loss_variational =  1.937256583112031\n",
      "epoch =  0 batch =  507 / 1000 loss_uniform =  1.7873407475341705  loss_variational =  1.936753811450635\n",
      "epoch =  0 batch =  508 / 1000 loss_uniform =  1.7870580868458183  loss_variational =  1.936278953326969\n",
      "epoch =  0 batch =  509 / 1000 loss_uniform =  1.7868154671899459  loss_variational =  1.9358092949292052\n",
      "epoch =  0 batch =  510 / 1000 loss_uniform =  1.786584389209747  loss_variational =  1.9354097097527752\n",
      "epoch =  0 batch =  511 / 1000 loss_uniform =  1.7863197014056538  loss_variational =  1.9349855002591758\n",
      "epoch =  0 batch =  512 / 1000 loss_uniform =  1.786068827146664  loss_variational =  1.9344807423185562\n",
      "epoch =  0 batch =  513 / 1000 loss_uniform =  1.7857681055050378  loss_variational =  1.9339961585013261\n",
      "epoch =  0 batch =  514 / 1000 loss_uniform =  1.785487951935497  loss_variational =  1.9335403797227588\n",
      "epoch =  0 batch =  515 / 1000 loss_uniform =  1.785242415631859  loss_variational =  1.9330590516618158\n",
      "epoch =  0 batch =  516 / 1000 loss_uniform =  1.784961083831713  loss_variational =  1.9325870585071954\n",
      "epoch =  0 batch =  517 / 1000 loss_uniform =  1.7847066206904396  loss_variational =  1.932096284178286\n",
      "epoch =  0 batch =  518 / 1000 loss_uniform =  1.784423182369659  loss_variational =  1.9316411057494327\n",
      "epoch =  0 batch =  519 / 1000 loss_uniform =  1.7841659573001896  loss_variational =  1.931142644156381\n",
      "epoch =  0 batch =  520 / 1000 loss_uniform =  1.7838808362300578  loss_variational =  1.9306995080067566\n",
      "epoch =  0 batch =  521 / 1000 loss_uniform =  1.7836253983960726  loss_variational =  1.930269935309544\n",
      "epoch =  0 batch =  522 / 1000 loss_uniform =  1.7833578346789567  loss_variational =  1.9298084266341056\n",
      "epoch =  0 batch =  523 / 1000 loss_uniform =  1.7830582342001948  loss_variational =  1.9293377182907634\n",
      "epoch =  0 batch =  524 / 1000 loss_uniform =  1.7827834914658813  loss_variational =  1.9288864454240293\n",
      "epoch =  0 batch =  525 / 1000 loss_uniform =  1.7824679342905678  loss_variational =  1.9284082058497842\n",
      "epoch =  0 batch =  526 / 1000 loss_uniform =  1.7822065412318295  loss_variational =  1.9279383810754063\n",
      "epoch =  0 batch =  527 / 1000 loss_uniform =  1.7819490563937332  loss_variational =  1.9274855634971637\n",
      "epoch =  0 batch =  528 / 1000 loss_uniform =  1.7816884172233665  loss_variational =  1.927032149199284\n",
      "epoch =  0 batch =  529 / 1000 loss_uniform =  1.7814481449938446  loss_variational =  1.9265833766338736\n",
      "epoch =  0 batch =  530 / 1000 loss_uniform =  1.7811862225802435  loss_variational =  1.9261912512329393\n",
      "epoch =  0 batch =  531 / 1000 loss_uniform =  1.7809519774496214  loss_variational =  1.9257629303833415\n",
      "epoch =  0 batch =  532 / 1000 loss_uniform =  1.7806838486427647  loss_variational =  1.9253326300391582\n",
      "epoch =  0 batch =  533 / 1000 loss_uniform =  1.780424182007952  loss_variational =  1.9248821735382085\n",
      "epoch =  0 batch =  534 / 1000 loss_uniform =  1.7801900300640288  loss_variational =  1.924473072482406\n",
      "epoch =  0 batch =  535 / 1000 loss_uniform =  1.7799355217229536  loss_variational =  1.9240288750033516\n",
      "epoch =  0 batch =  536 / 1000 loss_uniform =  1.7796832976946186  loss_variational =  1.9235566725481805\n",
      "epoch =  0 batch =  537 / 1000 loss_uniform =  1.77942898930562  loss_variational =  1.9231467841945773\n",
      "epoch =  0 batch =  538 / 1000 loss_uniform =  1.7791907809480854  loss_variational =  1.922707935912902\n",
      "epoch =  0 batch =  539 / 1000 loss_uniform =  1.7789685887618052  loss_variational =  1.9222594400062636\n",
      "epoch =  0 batch =  540 / 1000 loss_uniform =  1.778733830981784  loss_variational =  1.921803532485609\n",
      "epoch =  0 batch =  541 / 1000 loss_uniform =  1.7784691101521966  loss_variational =  1.921362025239772\n",
      "epoch =  0 batch =  542 / 1000 loss_uniform =  1.7782167205071533  loss_variational =  1.9209360233971997\n",
      "epoch =  0 batch =  543 / 1000 loss_uniform =  1.7779644218378081  loss_variational =  1.9205548113441824\n",
      "epoch =  0 batch =  544 / 1000 loss_uniform =  1.777705858516342  loss_variational =  1.9201465788133008\n",
      "epoch =  0 batch =  545 / 1000 loss_uniform =  1.7774182932092506  loss_variational =  1.919695911713697\n",
      "epoch =  0 batch =  546 / 1000 loss_uniform =  1.7771745542466855  loss_variational =  1.919275780300518\n",
      "epoch =  0 batch =  547 / 1000 loss_uniform =  1.7769297958510009  loss_variational =  1.918852105655008\n",
      "epoch =  0 batch =  548 / 1000 loss_uniform =  1.7766655291954092  loss_variational =  1.9183717924748027\n",
      "epoch =  0 batch =  549 / 1000 loss_uniform =  1.7764141776739786  loss_variational =  1.917945103567155\n",
      "epoch =  0 batch =  550 / 1000 loss_uniform =  1.7761627130074928  loss_variational =  1.917510379010981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  551 / 1000 loss_uniform =  1.775925948918406  loss_variational =  1.9170797730097975\n",
      "epoch =  0 batch =  552 / 1000 loss_uniform =  1.7756817520096675  loss_variational =  1.9166831531818367\n",
      "epoch =  0 batch =  553 / 1000 loss_uniform =  1.7754593986283582  loss_variational =  1.9162508167366874\n",
      "epoch =  0 batch =  554 / 1000 loss_uniform =  1.77520869354909  loss_variational =  1.9158762581511959\n",
      "epoch =  0 batch =  555 / 1000 loss_uniform =  1.7750082540082495  loss_variational =  1.9154879144720134\n",
      "epoch =  0 batch =  556 / 1000 loss_uniform =  1.774779812895136  loss_variational =  1.9150521392873727\n",
      "epoch =  0 batch =  557 / 1000 loss_uniform =  1.774561965700967  loss_variational =  1.9146265827346751\n",
      "epoch =  0 batch =  558 / 1000 loss_uniform =  1.774342632635519  loss_variational =  1.9141931211222034\n",
      "epoch =  0 batch =  559 / 1000 loss_uniform =  1.7741003149523922  loss_variational =  1.9137897092669087\n",
      "epoch =  0 batch =  560 / 1000 loss_uniform =  1.7738796561956396  loss_variational =  1.913394255297525\n",
      "epoch =  0 batch =  561 / 1000 loss_uniform =  1.773644239507256  loss_variational =  1.9129623215041276\n",
      "epoch =  0 batch =  562 / 1000 loss_uniform =  1.7734074019876653  loss_variational =  1.9125629568015132\n",
      "epoch =  0 batch =  563 / 1000 loss_uniform =  1.773187184841975  loss_variational =  1.9121247345770236\n",
      "epoch =  0 batch =  564 / 1000 loss_uniform =  1.7729669048431063  loss_variational =  1.911696163263727\n",
      "epoch =  0 batch =  565 / 1000 loss_uniform =  1.7727424180613145  loss_variational =  1.9112560291205891\n",
      "epoch =  0 batch =  566 / 1000 loss_uniform =  1.7725199477832636  loss_variational =  1.910874731338488\n",
      "epoch =  0 batch =  567 / 1000 loss_uniform =  1.772305939983858  loss_variational =  1.9104402571969146\n",
      "epoch =  0 batch =  568 / 1000 loss_uniform =  1.772057445955947  loss_variational =  1.9100282500747228\n",
      "epoch =  0 batch =  569 / 1000 loss_uniform =  1.7718402830284792  loss_variational =  1.9096159157727854\n",
      "epoch =  0 batch =  570 / 1000 loss_uniform =  1.771635093396169  loss_variational =  1.909218971980246\n",
      "epoch =  0 batch =  571 / 1000 loss_uniform =  1.7714259630744376  loss_variational =  1.9088463269682987\n",
      "epoch =  0 batch =  572 / 1000 loss_uniform =  1.7712319424519163  loss_variational =  1.9084471962251868\n",
      "epoch =  0 batch =  573 / 1000 loss_uniform =  1.7710033565707637  loss_variational =  1.908054439393222\n",
      "epoch =  0 batch =  574 / 1000 loss_uniform =  1.7707684800184553  loss_variational =  1.9076743402132177\n",
      "epoch =  0 batch =  575 / 1000 loss_uniform =  1.7705265250413305  loss_variational =  1.9073159821137142\n",
      "epoch =  0 batch =  576 / 1000 loss_uniform =  1.770292608688274  loss_variational =  1.9069478486975038\n",
      "epoch =  0 batch =  577 / 1000 loss_uniform =  1.770063213087243  loss_variational =  1.9065592483176725\n",
      "epoch =  0 batch =  578 / 1000 loss_uniform =  1.7698512477445758  loss_variational =  1.9062043350048135\n",
      "epoch =  0 batch =  579 / 1000 loss_uniform =  1.769633204208136  loss_variational =  1.90582649571908\n",
      "epoch =  0 batch =  580 / 1000 loss_uniform =  1.769426722567656  loss_variational =  1.9054649609943919\n",
      "epoch =  0 batch =  581 / 1000 loss_uniform =  1.7692367630448063  loss_variational =  1.9050666930958657\n",
      "epoch =  0 batch =  582 / 1000 loss_uniform =  1.7690339805334288  loss_variational =  1.9046815680884008\n",
      "epoch =  0 batch =  583 / 1000 loss_uniform =  1.7688525649327553  loss_variational =  1.9042929435471527\n",
      "epoch =  0 batch =  584 / 1000 loss_uniform =  1.76862612468739  loss_variational =  1.903903742154984\n",
      "epoch =  0 batch =  585 / 1000 loss_uniform =  1.7684043566385896  loss_variational =  1.9035063164865873\n",
      "epoch =  0 batch =  586 / 1000 loss_uniform =  1.7681975303656405  loss_variational =  1.903134613313773\n",
      "epoch =  0 batch =  587 / 1000 loss_uniform =  1.767974744460448  loss_variational =  1.9027251309796132\n",
      "epoch =  0 batch =  588 / 1000 loss_uniform =  1.767756998944444  loss_variational =  1.9023582276438373\n",
      "epoch =  0 batch =  589 / 1000 loss_uniform =  1.7675361904506968  loss_variational =  1.9019388209376962\n",
      "epoch =  0 batch =  590 / 1000 loss_uniform =  1.7673296764745543  loss_variational =  1.9015495114407301\n",
      "epoch =  0 batch =  591 / 1000 loss_uniform =  1.7671107598367675  loss_variational =  1.9011510973654426\n",
      "epoch =  0 batch =  592 / 1000 loss_uniform =  1.7669107565605955  loss_variational =  1.9007716362138056\n",
      "epoch =  0 batch =  593 / 1000 loss_uniform =  1.7666815692216502  loss_variational =  1.9003732727108682\n",
      "epoch =  0 batch =  594 / 1000 loss_uniform =  1.7665042004199936  loss_variational =  1.8999906934873025\n",
      "epoch =  0 batch =  595 / 1000 loss_uniform =  1.7662793454001924  loss_variational =  1.8995959872959045\n",
      "epoch =  0 batch =  596 / 1000 loss_uniform =  1.7660734885490974  loss_variational =  1.899263160540754\n",
      "epoch =  0 batch =  597 / 1000 loss_uniform =  1.7658366140608404  loss_variational =  1.8989098245774085\n",
      "epoch =  0 batch =  598 / 1000 loss_uniform =  1.7656134668002552  loss_variational =  1.8985596927113362\n",
      "epoch =  0 batch =  599 / 1000 loss_uniform =  1.7653915846288097  loss_variational =  1.8982407320321903\n",
      "epoch =  0 batch =  600 / 1000 loss_uniform =  1.7651594229539227  loss_variational =  1.8978626791636153\n",
      "epoch =  0 batch =  601 / 1000 loss_uniform =  1.7649355561483315  loss_variational =  1.89750055921653\n",
      "epoch =  0 batch =  602 / 1000 loss_uniform =  1.7647589975813291  loss_variational =  1.8971354947533723\n",
      "epoch =  0 batch =  603 / 1000 loss_uniform =  1.7645566431839463  loss_variational =  1.8967658220041257\n",
      "epoch =  0 batch =  604 / 1000 loss_uniform =  1.7643408248361365  loss_variational =  1.8964054456215036\n",
      "epoch =  0 batch =  605 / 1000 loss_uniform =  1.7641460420671566  loss_variational =  1.8960498815725662\n",
      "epoch =  0 batch =  606 / 1000 loss_uniform =  1.7639727169531005  loss_variational =  1.8957054032744358\n",
      "epoch =  0 batch =  607 / 1000 loss_uniform =  1.7637835240246234  loss_variational =  1.8953909999652596\n",
      "epoch =  0 batch =  608 / 1000 loss_uniform =  1.763606220679847  loss_variational =  1.895036484457945\n",
      "epoch =  0 batch =  609 / 1000 loss_uniform =  1.7634001140328261  loss_variational =  1.8946785686051322\n",
      "epoch =  0 batch =  610 / 1000 loss_uniform =  1.7632292548163986  loss_variational =  1.8943238698068217\n",
      "epoch =  0 batch =  611 / 1000 loss_uniform =  1.7630293468796867  loss_variational =  1.8939554905930442\n",
      "epoch =  0 batch =  612 / 1000 loss_uniform =  1.7628339176474046  loss_variational =  1.8936466007840402\n",
      "epoch =  0 batch =  613 / 1000 loss_uniform =  1.7626174659168927  loss_variational =  1.8933023735516226\n",
      "epoch =  0 batch =  614 / 1000 loss_uniform =  1.7624422604952255  loss_variational =  1.8929603202723528\n",
      "epoch =  0 batch =  615 / 1000 loss_uniform =  1.762238159218454  loss_variational =  1.8925906047588446\n",
      "epoch =  0 batch =  616 / 1000 loss_uniform =  1.762011444413816  loss_variational =  1.892240952361714\n",
      "epoch =  0 batch =  617 / 1000 loss_uniform =  1.7618216359248224  loss_variational =  1.8918621229004824\n",
      "epoch =  0 batch =  618 / 1000 loss_uniform =  1.7616182260914521  loss_variational =  1.891509145787619\n",
      "epoch =  0 batch =  619 / 1000 loss_uniform =  1.7614216604217374  loss_variational =  1.891152525756972\n",
      "epoch =  0 batch =  620 / 1000 loss_uniform =  1.7612154383813174  loss_variational =  1.8907999557833521\n",
      "epoch =  0 batch =  621 / 1000 loss_uniform =  1.760999358986502  loss_variational =  1.890466798330851\n",
      "epoch =  0 batch =  622 / 1000 loss_uniform =  1.7607955995863267  loss_variational =  1.890159208291597\n",
      "epoch =  0 batch =  623 / 1000 loss_uniform =  1.760616979476536  loss_variational =  1.8897943269000967\n",
      "epoch =  0 batch =  624 / 1000 loss_uniform =  1.7604262431462598  loss_variational =  1.8894128033365962\n",
      "epoch =  0 batch =  625 / 1000 loss_uniform =  1.760214056015014  loss_variational =  1.8890655876159672\n",
      "epoch =  0 batch =  626 / 1000 loss_uniform =  1.7600123244352608  loss_variational =  1.8887725742861108\n",
      "epoch =  0 batch =  627 / 1000 loss_uniform =  1.759823177229654  loss_variational =  1.8884683041291188\n",
      "epoch =  0 batch =  628 / 1000 loss_uniform =  1.759635560641622  loss_variational =  1.8881314744235607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  629 / 1000 loss_uniform =  1.7594542859658142  loss_variational =  1.887785662528252\n",
      "epoch =  0 batch =  630 / 1000 loss_uniform =  1.759268567107972  loss_variational =  1.8874730501856127\n",
      "epoch =  0 batch =  631 / 1000 loss_uniform =  1.7590885168021144  loss_variational =  1.887177166394689\n",
      "epoch =  0 batch =  632 / 1000 loss_uniform =  1.7589032702808132  loss_variational =  1.8868576978580864\n",
      "epoch =  0 batch =  633 / 1000 loss_uniform =  1.758720581942071  loss_variational =  1.8865483445578846\n",
      "epoch =  0 batch =  634 / 1000 loss_uniform =  1.7585227047607344  loss_variational =  1.8862004896819784\n",
      "epoch =  0 batch =  635 / 1000 loss_uniform =  1.7583373805669342  loss_variational =  1.8858699098346743\n",
      "epoch =  0 batch =  636 / 1000 loss_uniform =  1.7581656031638564  loss_variational =  1.8855326693013033\n",
      "epoch =  0 batch =  637 / 1000 loss_uniform =  1.7579610841801994  loss_variational =  1.885204284120018\n",
      "epoch =  0 batch =  638 / 1000 loss_uniform =  1.7577766241698423  loss_variational =  1.8848804291512902\n",
      "epoch =  0 batch =  639 / 1000 loss_uniform =  1.7576067692050719  loss_variational =  1.8845427713483716\n",
      "epoch =  0 batch =  640 / 1000 loss_uniform =  1.7574345061555499  loss_variational =  1.8842151431366805\n",
      "epoch =  0 batch =  641 / 1000 loss_uniform =  1.7572474485254503  loss_variational =  1.8838948154598245\n",
      "epoch =  0 batch =  642 / 1000 loss_uniform =  1.757098408131584  loss_variational =  1.8835693076020836\n",
      "epoch =  0 batch =  643 / 1000 loss_uniform =  1.7569158334939692  loss_variational =  1.8832640329007972\n",
      "epoch =  0 batch =  644 / 1000 loss_uniform =  1.756748193909662  loss_variational =  1.8829682295366847\n",
      "epoch =  0 batch =  645 / 1000 loss_uniform =  1.7565621677295176  loss_variational =  1.8826550450435908\n",
      "epoch =  0 batch =  646 / 1000 loss_uniform =  1.7563583819489723  loss_variational =  1.882309109802955\n",
      "epoch =  0 batch =  647 / 1000 loss_uniform =  1.7561951514558034  loss_variational =  1.8819688930762057\n",
      "epoch =  0 batch =  648 / 1000 loss_uniform =  1.7560004779586078  loss_variational =  1.8816586151535133\n",
      "epoch =  0 batch =  649 / 1000 loss_uniform =  1.755812021910868  loss_variational =  1.8813661123828274\n",
      "epoch =  0 batch =  650 / 1000 loss_uniform =  1.7556169834503754  loss_variational =  1.881029414580419\n",
      "epoch =  0 batch =  651 / 1000 loss_uniform =  1.755434770554807  loss_variational =  1.8806797533357569\n",
      "epoch =  0 batch =  652 / 1000 loss_uniform =  1.7552378916301603  loss_variational =  1.8803442751337418\n",
      "epoch =  0 batch =  653 / 1000 loss_uniform =  1.7550497788930188  loss_variational =  1.8800155683827076\n",
      "epoch =  0 batch =  654 / 1000 loss_uniform =  1.754852612813313  loss_variational =  1.8796991514503412\n",
      "epoch =  0 batch =  655 / 1000 loss_uniform =  1.7546848704796705  loss_variational =  1.8793971321964995\n",
      "epoch =  0 batch =  656 / 1000 loss_uniform =  1.7545165096114315  loss_variational =  1.8791100470031183\n",
      "epoch =  0 batch =  657 / 1000 loss_uniform =  1.7543299277986377  loss_variational =  1.8787804283144995\n",
      "epoch =  0 batch =  658 / 1000 loss_uniform =  1.7541549180416345  loss_variational =  1.8784738907698082\n",
      "epoch =  0 batch =  659 / 1000 loss_uniform =  1.7539759232169392  loss_variational =  1.8781655896596376\n",
      "epoch =  0 batch =  660 / 1000 loss_uniform =  1.7538037587295872  loss_variational =  1.8778651634852095\n",
      "epoch =  0 batch =  661 / 1000 loss_uniform =  1.7536357390537918  loss_variational =  1.8775879815558987\n",
      "epoch =  0 batch =  662 / 1000 loss_uniform =  1.753466112375979  loss_variational =  1.8772534288668563\n",
      "epoch =  0 batch =  663 / 1000 loss_uniform =  1.7532903820860612  loss_variational =  1.8769421323931599\n",
      "epoch =  0 batch =  664 / 1000 loss_uniform =  1.7531101136322473  loss_variational =  1.8766493571091851\n",
      "epoch =  0 batch =  665 / 1000 loss_uniform =  1.7529266624522382  loss_variational =  1.876348511975511\n",
      "epoch =  0 batch =  666 / 1000 loss_uniform =  1.7527899163979304  loss_variational =  1.8760225785387175\n",
      "epoch =  0 batch =  667 / 1000 loss_uniform =  1.7525986790478312  loss_variational =  1.8757215105611527\n",
      "epoch =  0 batch =  668 / 1000 loss_uniform =  1.752441341827015  loss_variational =  1.875449034625185\n",
      "epoch =  0 batch =  669 / 1000 loss_uniform =  1.7522776861005471  loss_variational =  1.8752127917892734\n",
      "epoch =  0 batch =  670 / 1000 loss_uniform =  1.7521354104155917  loss_variational =  1.8749195187839114\n",
      "epoch =  0 batch =  671 / 1000 loss_uniform =  1.7519894943152021  loss_variational =  1.8746406623396898\n",
      "epoch =  0 batch =  672 / 1000 loss_uniform =  1.7518098888297868  loss_variational =  1.8743227647528766\n",
      "epoch =  0 batch =  673 / 1000 loss_uniform =  1.751661274266632  loss_variational =  1.8740468790414255\n",
      "epoch =  0 batch =  674 / 1000 loss_uniform =  1.751492184064508  loss_variational =  1.8737475879114533\n",
      "epoch =  0 batch =  675 / 1000 loss_uniform =  1.7513065693113532  loss_variational =  1.8734655039398762\n",
      "epoch =  0 batch =  676 / 1000 loss_uniform =  1.7511600605129483  loss_variational =  1.873177521680234\n",
      "epoch =  0 batch =  677 / 1000 loss_uniform =  1.7509921348957749  loss_variational =  1.8729131174228395\n",
      "epoch =  0 batch =  678 / 1000 loss_uniform =  1.7508084095333172  loss_variational =  1.8726182326806333\n",
      "epoch =  0 batch =  679 / 1000 loss_uniform =  1.750653664739212  loss_variational =  1.8722961200003423\n",
      "epoch =  0 batch =  680 / 1000 loss_uniform =  1.7505137289271628  loss_variational =  1.8720321199473215\n",
      "epoch =  0 batch =  681 / 1000 loss_uniform =  1.7503883887667657  loss_variational =  1.8717253852345699\n",
      "epoch =  0 batch =  682 / 1000 loss_uniform =  1.7502342764932732  loss_variational =  1.8713886297343416\n",
      "epoch =  0 batch =  683 / 1000 loss_uniform =  1.7500985340702055  loss_variational =  1.8710955212091809\n",
      "epoch =  0 batch =  684 / 1000 loss_uniform =  1.7499762808370305  loss_variational =  1.870821715795506\n",
      "epoch =  0 batch =  685 / 1000 loss_uniform =  1.749827160974488  loss_variational =  1.8705306789300742\n",
      "epoch =  0 batch =  686 / 1000 loss_uniform =  1.7496469375343426  loss_variational =  1.8702380254039268\n",
      "epoch =  0 batch =  687 / 1000 loss_uniform =  1.7494841085250714  loss_variational =  1.8699811015066625\n",
      "epoch =  0 batch =  688 / 1000 loss_uniform =  1.749300986528396  loss_variational =  1.8696860286385517\n",
      "epoch =  0 batch =  689 / 1000 loss_uniform =  1.7491302768793087  loss_variational =  1.8694043917302992\n",
      "epoch =  0 batch =  690 / 1000 loss_uniform =  1.7489820117535793  loss_variational =  1.8691131951152418\n",
      "epoch =  0 batch =  691 / 1000 loss_uniform =  1.7488361728174118  loss_variational =  1.868825833462772\n",
      "epoch =  0 batch =  692 / 1000 loss_uniform =  1.748683298426556  loss_variational =  1.8685316410712427\n",
      "epoch =  0 batch =  693 / 1000 loss_uniform =  1.7485157087939807  loss_variational =  1.8682583157634325\n",
      "epoch =  0 batch =  694 / 1000 loss_uniform =  1.748383389426239  loss_variational =  1.8679697204391967\n",
      "epoch =  0 batch =  695 / 1000 loss_uniform =  1.7482119637427564  loss_variational =  1.8676757882824908\n",
      "epoch =  0 batch =  696 / 1000 loss_uniform =  1.7480445332910817  loss_variational =  1.8673996873970693\n",
      "epoch =  0 batch =  697 / 1000 loss_uniform =  1.7479081942327046  loss_variational =  1.8671453903874164\n",
      "epoch =  0 batch =  698 / 1000 loss_uniform =  1.747752068548284  loss_variational =  1.8668600088545795\n",
      "epoch =  0 batch =  699 / 1000 loss_uniform =  1.7476035842568058  loss_variational =  1.8665659395239729\n",
      "epoch =  0 batch =  700 / 1000 loss_uniform =  1.7474618113040918  loss_variational =  1.866285781519754\n",
      "epoch =  0 batch =  701 / 1000 loss_uniform =  1.7473096401987327  loss_variational =  1.8660246380385594\n",
      "epoch =  0 batch =  702 / 1000 loss_uniform =  1.747147649781316  loss_variational =  1.8657296502012817\n",
      "epoch =  0 batch =  703 / 1000 loss_uniform =  1.7469841662375714  loss_variational =  1.8654667922477128\n",
      "epoch =  0 batch =  704 / 1000 loss_uniform =  1.746836877004666  loss_variational =  1.8651614273813641\n",
      "epoch =  0 batch =  705 / 1000 loss_uniform =  1.7466723846205576  loss_variational =  1.8648693992736496\n",
      "epoch =  0 batch =  706 / 1000 loss_uniform =  1.7465118542946763  loss_variational =  1.86461975030791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  707 / 1000 loss_uniform =  1.7463610845037019  loss_variational =  1.8643335749775891\n",
      "epoch =  0 batch =  708 / 1000 loss_uniform =  1.7461971743295415  loss_variational =  1.8640572654325414\n",
      "epoch =  0 batch =  709 / 1000 loss_uniform =  1.7460591554305442  loss_variational =  1.8638415281123608\n",
      "epoch =  0 batch =  710 / 1000 loss_uniform =  1.745913403638651  loss_variational =  1.8635958904951395\n",
      "epoch =  0 batch =  711 / 1000 loss_uniform =  1.7457557645025126  loss_variational =  1.8632810996051583\n",
      "epoch =  0 batch =  712 / 1000 loss_uniform =  1.745584067668807  loss_variational =  1.863004827767276\n",
      "epoch =  0 batch =  713 / 1000 loss_uniform =  1.7454479546566992  loss_variational =  1.8627414631475743\n",
      "epoch =  0 batch =  714 / 1000 loss_uniform =  1.7453332555060286  loss_variational =  1.8624863766488577\n",
      "epoch =  0 batch =  715 / 1000 loss_uniform =  1.7451878429292793  loss_variational =  1.8622195927413197\n",
      "epoch =  0 batch =  716 / 1000 loss_uniform =  1.7450465631551577  loss_variational =  1.8619925118358445\n",
      "epoch =  0 batch =  717 / 1000 loss_uniform =  1.744908199815736  loss_variational =  1.8617408273941638\n",
      "epoch =  0 batch =  718 / 1000 loss_uniform =  1.7447592805355034  loss_variational =  1.8614828134977721\n",
      "epoch =  0 batch =  719 / 1000 loss_uniform =  1.744613720246581  loss_variational =  1.8612175821760601\n",
      "epoch =  0 batch =  720 / 1000 loss_uniform =  1.7444620610939126  loss_variational =  1.8609596381584805\n",
      "epoch =  0 batch =  721 / 1000 loss_uniform =  1.744323380942483  loss_variational =  1.860695678714906\n",
      "epoch =  0 batch =  722 / 1000 loss_uniform =  1.7441624584620672  loss_variational =  1.8604152012729913\n",
      "epoch =  0 batch =  723 / 1000 loss_uniform =  1.7440165264807626  loss_variational =  1.8601438822752876\n",
      "epoch =  0 batch =  724 / 1000 loss_uniform =  1.7438841440730326  loss_variational =  1.8599034300825217\n",
      "epoch =  0 batch =  725 / 1000 loss_uniform =  1.7437465592088364  loss_variational =  1.8596298369045918\n",
      "epoch =  0 batch =  726 / 1000 loss_uniform =  1.7436002857428932  loss_variational =  1.8593704383563736\n",
      "epoch =  0 batch =  727 / 1000 loss_uniform =  1.7434634109638738  loss_variational =  1.859119658293062\n",
      "epoch =  0 batch =  728 / 1000 loss_uniform =  1.7433054786134545  loss_variational =  1.8588881929824643\n",
      "epoch =  0 batch =  729 / 1000 loss_uniform =  1.7431840613709222  loss_variational =  1.8586161327950752\n",
      "epoch =  0 batch =  730 / 1000 loss_uniform =  1.7430345762265866  loss_variational =  1.8583388661685059\n",
      "epoch =  0 batch =  731 / 1000 loss_uniform =  1.7428792573195633  loss_variational =  1.858100484562312\n",
      "epoch =  0 batch =  732 / 1000 loss_uniform =  1.7427137124408132  loss_variational =  1.8578391226588706\n",
      "epoch =  0 batch =  733 / 1000 loss_uniform =  1.7425456988697645  loss_variational =  1.8575696001924566\n",
      "epoch =  0 batch =  734 / 1000 loss_uniform =  1.7423861322350978  loss_variational =  1.8572892439462836\n",
      "epoch =  0 batch =  735 / 1000 loss_uniform =  1.742248537589092  loss_variational =  1.857017735721303\n",
      "epoch =  0 batch =  736 / 1000 loss_uniform =  1.742093298422253  loss_variational =  1.8567460770516295\n",
      "epoch =  0 batch =  737 / 1000 loss_uniform =  1.7419540618459108  loss_variational =  1.856530177706456\n",
      "epoch =  0 batch =  738 / 1000 loss_uniform =  1.7418120356433107  loss_variational =  1.8562748399853386\n",
      "epoch =  0 batch =  739 / 1000 loss_uniform =  1.741695248548329  loss_variational =  1.8560253646280191\n",
      "epoch =  0 batch =  740 / 1000 loss_uniform =  1.7415457327623618  loss_variational =  1.8557714604042674\n",
      "epoch =  0 batch =  741 / 1000 loss_uniform =  1.7413858572642003  loss_variational =  1.8555133847894298\n",
      "epoch =  0 batch =  742 / 1000 loss_uniform =  1.7412540499733458  loss_variational =  1.8552618074931226\n",
      "epoch =  0 batch =  743 / 1000 loss_uniform =  1.7411006389042885  loss_variational =  1.8550069713977595\n",
      "epoch =  0 batch =  744 / 1000 loss_uniform =  1.7409723175148804  loss_variational =  1.8547812253236773\n",
      "epoch =  0 batch =  745 / 1000 loss_uniform =  1.7408351664575148  loss_variational =  1.854533260300656\n",
      "epoch =  0 batch =  746 / 1000 loss_uniform =  1.7406934194526462  loss_variational =  1.8542932131335181\n",
      "epoch =  0 batch =  747 / 1000 loss_uniform =  1.740554118730935  loss_variational =  1.854061878828639\n",
      "epoch =  0 batch =  748 / 1000 loss_uniform =  1.7404116728407808  loss_variational =  1.8538247738929996\n",
      "epoch =  0 batch =  749 / 1000 loss_uniform =  1.740262345573771  loss_variational =  1.8535662348343631\n",
      "epoch =  0 batch =  750 / 1000 loss_uniform =  1.7401541150410964  loss_variational =  1.8533257204691571\n",
      "epoch =  0 batch =  751 / 1000 loss_uniform =  1.7400474902316823  loss_variational =  1.8530613982407615\n",
      "epoch =  0 batch =  752 / 1000 loss_uniform =  1.7399293956287358  loss_variational =  1.8528166903143237\n",
      "epoch =  0 batch =  753 / 1000 loss_uniform =  1.7398021697681416  loss_variational =  1.8525720481695251\n",
      "epoch =  0 batch =  754 / 1000 loss_uniform =  1.7396626249548606  loss_variational =  1.8523275934416674\n",
      "epoch =  0 batch =  755 / 1000 loss_uniform =  1.739550419359017  loss_variational =  1.8521142541178017\n",
      "epoch =  0 batch =  756 / 1000 loss_uniform =  1.7394240555309108  loss_variational =  1.8518892756845589\n",
      "epoch =  0 batch =  757 / 1000 loss_uniform =  1.739309047928259  loss_variational =  1.8516331889040407\n",
      "epoch =  0 batch =  758 / 1000 loss_uniform =  1.7391703433914985  loss_variational =  1.8513759652983233\n",
      "epoch =  0 batch =  759 / 1000 loss_uniform =  1.7390281825825782  loss_variational =  1.851146486751019\n",
      "epoch =  0 batch =  760 / 1000 loss_uniform =  1.7388977686041274  loss_variational =  1.8509225850042548\n",
      "epoch =  0 batch =  761 / 1000 loss_uniform =  1.7387797874784026  loss_variational =  1.850698281211703\n",
      "epoch =  0 batch =  762 / 1000 loss_uniform =  1.7386259262956028  loss_variational =  1.8504277949570986\n",
      "epoch =  0 batch =  763 / 1000 loss_uniform =  1.738508953960663  loss_variational =  1.850203820012344\n",
      "epoch =  0 batch =  764 / 1000 loss_uniform =  1.738385348419868  loss_variational =  1.8499630463372978\n",
      "epoch =  0 batch =  765 / 1000 loss_uniform =  1.7382492564082919  loss_variational =  1.849750536719179\n",
      "epoch =  0 batch =  766 / 1000 loss_uniform =  1.738116720326575  loss_variational =  1.8495138172381231\n",
      "epoch =  0 batch =  767 / 1000 loss_uniform =  1.7380023283939778  loss_variational =  1.8492718246489805\n",
      "epoch =  0 batch =  768 / 1000 loss_uniform =  1.7378746455845728  loss_variational =  1.849039215128869\n",
      "epoch =  0 batch =  769 / 1000 loss_uniform =  1.7377450352992434  loss_variational =  1.8487949462798856\n",
      "epoch =  0 batch =  770 / 1000 loss_uniform =  1.7376023131531548  loss_variational =  1.8485475880759106\n",
      "epoch =  0 batch =  771 / 1000 loss_uniform =  1.7374848946832337  loss_variational =  1.8482981351253744\n",
      "epoch =  0 batch =  772 / 1000 loss_uniform =  1.7373590914078938  loss_variational =  1.8480420527989385\n",
      "epoch =  0 batch =  773 / 1000 loss_uniform =  1.7372141009314706  loss_variational =  1.847823198831714\n",
      "epoch =  0 batch =  774 / 1000 loss_uniform =  1.7370876230934789  loss_variational =  1.8475992151317058\n",
      "epoch =  0 batch =  775 / 1000 loss_uniform =  1.7369877841395711  loss_variational =  1.8473792120718189\n",
      "epoch =  0 batch =  776 / 1000 loss_uniform =  1.7368614968565315  loss_variational =  1.847135562564909\n",
      "epoch =  0 batch =  777 / 1000 loss_uniform =  1.7367224911158297  loss_variational =  1.8469111101661106\n",
      "epoch =  0 batch =  778 / 1000 loss_uniform =  1.7365905867750657  loss_variational =  1.8466961840431\n",
      "epoch =  0 batch =  779 / 1000 loss_uniform =  1.7364550001048913  loss_variational =  1.8464909756749832\n",
      "epoch =  0 batch =  780 / 1000 loss_uniform =  1.7363224530831356  loss_variational =  1.846262083603786\n",
      "epoch =  0 batch =  781 / 1000 loss_uniform =  1.7361921139166383  loss_variational =  1.8460005446982295\n",
      "epoch =  0 batch =  782 / 1000 loss_uniform =  1.7360335614370257  loss_variational =  1.8457725322459972\n",
      "epoch =  0 batch =  783 / 1000 loss_uniform =  1.7358892210598644  loss_variational =  1.845543304470155\n",
      "epoch =  0 batch =  784 / 1000 loss_uniform =  1.7357326121050478  loss_variational =  1.8453014716506007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  785 / 1000 loss_uniform =  1.7356111843874493  loss_variational =  1.8450539104498118\n",
      "epoch =  0 batch =  786 / 1000 loss_uniform =  1.7354937477876207  loss_variational =  1.8448568012271525\n",
      "epoch =  0 batch =  787 / 1000 loss_uniform =  1.7353755309893786  loss_variational =  1.8446455907639892\n",
      "epoch =  0 batch =  788 / 1000 loss_uniform =  1.735223455780048  loss_variational =  1.844449044181611\n",
      "epoch =  0 batch =  789 / 1000 loss_uniform =  1.7350864745818158  loss_variational =  1.8441955200166307\n",
      "epoch =  0 batch =  790 / 1000 loss_uniform =  1.7349641381939749  loss_variational =  1.843954781037343\n",
      "epoch =  0 batch =  791 / 1000 loss_uniform =  1.7348377211808248  loss_variational =  1.843713035022866\n",
      "epoch =  0 batch =  792 / 1000 loss_uniform =  1.7347061530207137  loss_variational =  1.8434746930695547\n",
      "epoch =  0 batch =  793 / 1000 loss_uniform =  1.7345608324000388  loss_variational =  1.8432463569869613\n",
      "epoch =  0 batch =  794 / 1000 loss_uniform =  1.7344400159057496  loss_variational =  1.8430236442863794\n",
      "epoch =  0 batch =  795 / 1000 loss_uniform =  1.7343235630659182  loss_variational =  1.8428330502420105\n",
      "epoch =  0 batch =  796 / 1000 loss_uniform =  1.7342277678413003  loss_variational =  1.842619167500405\n",
      "epoch =  0 batch =  797 / 1000 loss_uniform =  1.734113970096018  loss_variational =  1.842379129815431\n",
      "epoch =  0 batch =  798 / 1000 loss_uniform =  1.733990717800637  loss_variational =  1.8421713013696792\n",
      "epoch =  0 batch =  799 / 1000 loss_uniform =  1.7338693710382047  loss_variational =  1.8419612562551966\n",
      "epoch =  0 batch =  800 / 1000 loss_uniform =  1.7337410427629942  loss_variational =  1.841731694340706\n",
      "epoch =  0 batch =  801 / 1000 loss_uniform =  1.733619039722447  loss_variational =  1.8415260097656063\n",
      "epoch =  0 batch =  802 / 1000 loss_uniform =  1.7334742015436695  loss_variational =  1.8412893025060546\n",
      "epoch =  0 batch =  803 / 1000 loss_uniform =  1.7333210393470957  loss_variational =  1.8410427315000581\n",
      "epoch =  0 batch =  804 / 1000 loss_uniform =  1.733216318325023  loss_variational =  1.8408408713577995\n",
      "epoch =  0 batch =  805 / 1000 loss_uniform =  1.7330926898103318  loss_variational =  1.8406264964097778\n",
      "epoch =  0 batch =  806 / 1000 loss_uniform =  1.732974385061571  loss_variational =  1.8403872423077343\n",
      "epoch =  0 batch =  807 / 1000 loss_uniform =  1.7328465408847524  loss_variational =  1.8401789427394468\n",
      "epoch =  0 batch =  808 / 1000 loss_uniform =  1.7327157934703443  loss_variational =  1.8399481038645946\n",
      "epoch =  0 batch =  809 / 1000 loss_uniform =  1.7326025763901844  loss_variational =  1.8397449084059125\n",
      "epoch =  0 batch =  810 / 1000 loss_uniform =  1.7324908851105485  loss_variational =  1.839541946811441\n",
      "epoch =  0 batch =  811 / 1000 loss_uniform =  1.7323831749021192  loss_variational =  1.839335244769086\n",
      "epoch =  0 batch =  812 / 1000 loss_uniform =  1.7322626177019669  loss_variational =  1.83914662993013\n",
      "epoch =  0 batch =  813 / 1000 loss_uniform =  1.7321334747370754  loss_variational =  1.8389636175512243\n",
      "epoch =  0 batch =  814 / 1000 loss_uniform =  1.7320312692140767  loss_variational =  1.8387446085709613\n",
      "epoch =  0 batch =  815 / 1000 loss_uniform =  1.7319365894867593  loss_variational =  1.8385568950805198\n",
      "epoch =  0 batch =  816 / 1000 loss_uniform =  1.731819712794294  loss_variational =  1.8383258531490965\n",
      "epoch =  0 batch =  817 / 1000 loss_uniform =  1.7316878635705315  loss_variational =  1.8381048477410982\n",
      "epoch =  0 batch =  818 / 1000 loss_uniform =  1.7315450523476723  loss_variational =  1.837898403770475\n",
      "epoch =  0 batch =  819 / 1000 loss_uniform =  1.7314355616458892  loss_variational =  1.8376797286290973\n",
      "epoch =  0 batch =  820 / 1000 loss_uniform =  1.731338929112364  loss_variational =  1.837461201010681\n",
      "epoch =  0 batch =  821 / 1000 loss_uniform =  1.731238729480413  loss_variational =  1.837251149490022\n",
      "epoch =  0 batch =  822 / 1000 loss_uniform =  1.731116043970242  loss_variational =  1.837070239431377\n",
      "epoch =  0 batch =  823 / 1000 loss_uniform =  1.7309869061408611  loss_variational =  1.8368663169344028\n",
      "epoch =  0 batch =  824 / 1000 loss_uniform =  1.7308556713814869  loss_variational =  1.8366387383741085\n",
      "epoch =  0 batch =  825 / 1000 loss_uniform =  1.7307328322439477  loss_variational =  1.8364280746922352\n",
      "epoch =  0 batch =  826 / 1000 loss_uniform =  1.730605051967768  loss_variational =  1.8362290856335992\n",
      "epoch =  0 batch =  827 / 1000 loss_uniform =  1.7304641103513867  loss_variational =  1.8359886923897226\n",
      "epoch =  0 batch =  828 / 1000 loss_uniform =  1.73036052322618  loss_variational =  1.8357639321382497\n",
      "epoch =  0 batch =  829 / 1000 loss_uniform =  1.7302435702667875  loss_variational =  1.8355516294518486\n",
      "epoch =  0 batch =  830 / 1000 loss_uniform =  1.7301199578377133  loss_variational =  1.83531605048352\n",
      "epoch =  0 batch =  831 / 1000 loss_uniform =  1.729993302899577  loss_variational =  1.835103426312425\n",
      "epoch =  0 batch =  832 / 1000 loss_uniform =  1.7298834758022652  loss_variational =  1.8348817043006422\n",
      "epoch =  0 batch =  833 / 1000 loss_uniform =  1.729768539534038  loss_variational =  1.8346682560830274\n",
      "epoch =  0 batch =  834 / 1000 loss_uniform =  1.7296480788029636  loss_variational =  1.8344664647996571\n",
      "epoch =  0 batch =  835 / 1000 loss_uniform =  1.7295238933163484  loss_variational =  1.834251216642871\n",
      "epoch =  0 batch =  836 / 1000 loss_uniform =  1.7294077519594762  loss_variational =  1.8340639601769062\n",
      "epoch =  0 batch =  837 / 1000 loss_uniform =  1.729284640993553  loss_variational =  1.8338388550666074\n",
      "epoch =  0 batch =  838 / 1000 loss_uniform =  1.729183629190722  loss_variational =  1.8336078572956078\n",
      "epoch =  0 batch =  839 / 1000 loss_uniform =  1.7290671776815871  loss_variational =  1.833378882175123\n",
      "epoch =  0 batch =  840 / 1000 loss_uniform =  1.7289643872351868  loss_variational =  1.8331537690900623\n",
      "epoch =  0 batch =  841 / 1000 loss_uniform =  1.7288511452861965  loss_variational =  1.832939389911475\n",
      "epoch =  0 batch =  842 / 1000 loss_uniform =  1.7287380974253108  loss_variational =  1.8327292284603076\n",
      "epoch =  0 batch =  843 / 1000 loss_uniform =  1.728625975469677  loss_variational =  1.832510569058845\n",
      "epoch =  0 batch =  844 / 1000 loss_uniform =  1.7285058893863618  loss_variational =  1.8323093673911708\n",
      "epoch =  0 batch =  845 / 1000 loss_uniform =  1.7283865227501767  loss_variational =  1.832127102733364\n",
      "epoch =  0 batch =  846 / 1000 loss_uniform =  1.7282593751911852  loss_variational =  1.8319375278256467\n",
      "epoch =  0 batch =  847 / 1000 loss_uniform =  1.7281448511756432  loss_variational =  1.831723782078857\n",
      "epoch =  0 batch =  848 / 1000 loss_uniform =  1.7280337560289305  loss_variational =  1.8315228464187319\n",
      "epoch =  0 batch =  849 / 1000 loss_uniform =  1.7279242619749229  loss_variational =  1.8313200454127805\n",
      "epoch =  0 batch =  850 / 1000 loss_uniform =  1.7278246492498055  loss_variational =  1.8311371226871718\n",
      "epoch =  0 batch =  851 / 1000 loss_uniform =  1.72771878556275  loss_variational =  1.8309418904375108\n",
      "epoch =  0 batch =  852 / 1000 loss_uniform =  1.7276157252665412  loss_variational =  1.8307462590680998\n",
      "epoch =  0 batch =  853 / 1000 loss_uniform =  1.7275019476030797  loss_variational =  1.8305516954323613\n",
      "epoch =  0 batch =  854 / 1000 loss_uniform =  1.7273957179357626  loss_variational =  1.830339156632122\n",
      "epoch =  0 batch =  855 / 1000 loss_uniform =  1.727297933896382  loss_variational =  1.8301309554897556\n",
      "epoch =  0 batch =  856 / 1000 loss_uniform =  1.7271758946024363  loss_variational =  1.8299292686665172\n",
      "epoch =  0 batch =  857 / 1000 loss_uniform =  1.7270601214438914  loss_variational =  1.8297531553299593\n",
      "epoch =  0 batch =  858 / 1000 loss_uniform =  1.7269456097573939  loss_variational =  1.8295658389171523\n",
      "epoch =  0 batch =  859 / 1000 loss_uniform =  1.7268344911901716  loss_variational =  1.8293823238301752\n",
      "epoch =  0 batch =  860 / 1000 loss_uniform =  1.72673192509385  loss_variational =  1.8291949581268225\n",
      "epoch =  0 batch =  861 / 1000 loss_uniform =  1.7266282190706113  loss_variational =  1.828994245340877\n",
      "epoch =  0 batch =  862 / 1000 loss_uniform =  1.7265321407683205  loss_variational =  1.8288110920558676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  863 / 1000 loss_uniform =  1.7264377376019329  loss_variational =  1.8286413962705665\n",
      "epoch =  0 batch =  864 / 1000 loss_uniform =  1.7263399921357627  loss_variational =  1.828468347175254\n",
      "epoch =  0 batch =  865 / 1000 loss_uniform =  1.7262319189964686  loss_variational =  1.82825764259162\n",
      "epoch =  0 batch =  866 / 1000 loss_uniform =  1.726139164411443  loss_variational =  1.8280771556407147\n",
      "epoch =  0 batch =  867 / 1000 loss_uniform =  1.7260359144815793  loss_variational =  1.8278918259421575\n",
      "epoch =  0 batch =  868 / 1000 loss_uniform =  1.725934174615666  loss_variational =  1.82770372920322\n",
      "epoch =  0 batch =  869 / 1000 loss_uniform =  1.725830625198241  loss_variational =  1.827498980029406\n",
      "epoch =  0 batch =  870 / 1000 loss_uniform =  1.7257400512695307  loss_variational =  1.827293953128245\n",
      "epoch =  0 batch =  871 / 1000 loss_uniform =  1.7256383416847023  loss_variational =  1.827111829846379\n",
      "epoch =  0 batch =  872 / 1000 loss_uniform =  1.725522575301861  loss_variational =  1.8269390347627328\n",
      "epoch =  0 batch =  873 / 1000 loss_uniform =  1.725422740255707  loss_variational =  1.8267482896031386\n",
      "epoch =  0 batch =  874 / 1000 loss_uniform =  1.7253176990035464  loss_variational =  1.8265731606112467\n",
      "epoch =  0 batch =  875 / 1000 loss_uniform =  1.72520534147535  loss_variational =  1.826383143288749\n",
      "epoch =  0 batch =  876 / 1000 loss_uniform =  1.7251006008283183  loss_variational =  1.8262124371855228\n",
      "epoch =  0 batch =  877 / 1000 loss_uniform =  1.7249969335075381  loss_variational =  1.8260311915909826\n",
      "epoch =  0 batch =  878 / 1000 loss_uniform =  1.7248984037607835  loss_variational =  1.8258406111211063\n",
      "epoch =  0 batch =  879 / 1000 loss_uniform =  1.7248076218115722  loss_variational =  1.8256603692307545\n",
      "epoch =  0 batch =  880 / 1000 loss_uniform =  1.7247026746923269  loss_variational =  1.8254620212045585\n",
      "epoch =  0 batch =  881 / 1000 loss_uniform =  1.7245900532173646  loss_variational =  1.8252807875902783\n",
      "epoch =  0 batch =  882 / 1000 loss_uniform =  1.7244998727525978  loss_variational =  1.825085574537178\n",
      "epoch =  0 batch =  883 / 1000 loss_uniform =  1.7243726654473945  loss_variational =  1.8248994592092047\n",
      "epoch =  0 batch =  884 / 1000 loss_uniform =  1.7242617414278139  loss_variational =  1.8247161943178913\n",
      "epoch =  0 batch =  885 / 1000 loss_uniform =  1.7241631906584827  loss_variational =  1.8245682279942401\n",
      "epoch =  0 batch =  886 / 1000 loss_uniform =  1.7240643483790528  loss_variational =  1.8244019997039178\n",
      "epoch =  0 batch =  887 / 1000 loss_uniform =  1.7239432388658313  loss_variational =  1.824239796689022\n",
      "epoch =  0 batch =  888 / 1000 loss_uniform =  1.7238283215073846  loss_variational =  1.8240315222793875\n",
      "epoch =  0 batch =  889 / 1000 loss_uniform =  1.7237164022147449  loss_variational =  1.8238382170519494\n",
      "epoch =  0 batch =  890 / 1000 loss_uniform =  1.723624889100535  loss_variational =  1.8236401543188634\n",
      "epoch =  0 batch =  891 / 1000 loss_uniform =  1.7235250058265108  loss_variational =  1.8234521335222909\n",
      "epoch =  0 batch =  892 / 1000 loss_uniform =  1.7234302855393273  loss_variational =  1.8232674645468796\n",
      "epoch =  0 batch =  893 / 1000 loss_uniform =  1.7233239476384397  loss_variational =  1.823109501153064\n",
      "epoch =  0 batch =  894 / 1000 loss_uniform =  1.7232186264906415  loss_variational =  1.8229855224323488\n",
      "epoch =  0 batch =  895 / 1000 loss_uniform =  1.723124263006881  loss_variational =  1.8228184685360789\n",
      "epoch =  0 batch =  896 / 1000 loss_uniform =  1.7230272230559156  loss_variational =  1.8226241688909277\n",
      "epoch =  0 batch =  897 / 1000 loss_uniform =  1.7229130555156078  loss_variational =  1.8224226650984394\n",
      "epoch =  0 batch =  898 / 1000 loss_uniform =  1.722824847246862  loss_variational =  1.8222314006501692\n",
      "epoch =  0 batch =  899 / 1000 loss_uniform =  1.7227340704607084  loss_variational =  1.8220638864165024\n",
      "epoch =  0 batch =  900 / 1000 loss_uniform =  1.722644268141852  loss_variational =  1.8219394539462197\n",
      "epoch =  0 batch =  901 / 1000 loss_uniform =  1.7225535291678098  loss_variational =  1.8217811571241882\n",
      "epoch =  0 batch =  902 / 1000 loss_uniform =  1.7224466753111705  loss_variational =  1.8216383436038068\n",
      "epoch =  0 batch =  903 / 1000 loss_uniform =  1.7223527716639822  loss_variational =  1.8214569576290889\n",
      "epoch =  0 batch =  904 / 1000 loss_uniform =  1.7222446216418674  loss_variational =  1.8212961300020727\n",
      "epoch =  0 batch =  905 / 1000 loss_uniform =  1.7221648212295864  loss_variational =  1.8211327133916362\n",
      "epoch =  0 batch =  906 / 1000 loss_uniform =  1.7220594507968974  loss_variational =  1.8209503125933888\n",
      "epoch =  0 batch =  907 / 1000 loss_uniform =  1.7219474712569496  loss_variational =  1.8207851854679737\n",
      "epoch =  0 batch =  908 / 1000 loss_uniform =  1.7218409487854536  loss_variational =  1.8206154998178528\n",
      "epoch =  0 batch =  909 / 1000 loss_uniform =  1.7217555846055868  loss_variational =  1.8204455223545124\n",
      "epoch =  0 batch =  910 / 1000 loss_uniform =  1.721656829315227  loss_variational =  1.820252390091236\n",
      "epoch =  0 batch =  911 / 1000 loss_uniform =  1.7215594338533249  loss_variational =  1.8200722300783865\n",
      "epoch =  0 batch =  912 / 1000 loss_uniform =  1.7214526961508545  loss_variational =  1.8199026417313964\n",
      "epoch =  0 batch =  913 / 1000 loss_uniform =  1.7213486060908167  loss_variational =  1.8197314787537744\n",
      "epoch =  0 batch =  914 / 1000 loss_uniform =  1.7212483696394985  loss_variational =  1.8195547140661947\n",
      "epoch =  0 batch =  915 / 1000 loss_uniform =  1.7211475907779126  loss_variational =  1.8193927354499944\n",
      "epoch =  0 batch =  916 / 1000 loss_uniform =  1.7210412932535442  loss_variational =  1.8192079987328127\n",
      "epoch =  0 batch =  917 / 1000 loss_uniform =  1.7209482358092174  loss_variational =  1.8190844759686304\n",
      "epoch =  0 batch =  918 / 1000 loss_uniform =  1.7208335863219362  loss_variational =  1.8189179412939451\n",
      "epoch =  0 batch =  919 / 1000 loss_uniform =  1.7207391535755854  loss_variational =  1.8187658941136093\n",
      "epoch =  0 batch =  920 / 1000 loss_uniform =  1.7206572055816645  loss_variational =  1.8186015630545826\n",
      "epoch =  0 batch =  921 / 1000 loss_uniform =  1.7205705742364852  loss_variational =  1.8184495128844902\n",
      "epoch =  0 batch =  922 / 1000 loss_uniform =  1.720467760092265  loss_variational =  1.818278771289776\n",
      "epoch =  0 batch =  923 / 1000 loss_uniform =  1.720365883211402  loss_variational =  1.8181079695826623\n",
      "epoch =  0 batch =  924 / 1000 loss_uniform =  1.7202758970972774  loss_variational =  1.8179140501208122\n",
      "epoch =  0 batch =  925 / 1000 loss_uniform =  1.720182337503175  loss_variational =  1.817763214884578\n",
      "epoch =  0 batch =  926 / 1000 loss_uniform =  1.7200946908275196  loss_variational =  1.8176152802698042\n",
      "epoch =  0 batch =  927 / 1000 loss_uniform =  1.7199964664771972  loss_variational =  1.8174464982947358\n",
      "epoch =  0 batch =  928 / 1000 loss_uniform =  1.7198983116139621  loss_variational =  1.817284715843612\n",
      "epoch =  0 batch =  929 / 1000 loss_uniform =  1.7197864635639986  loss_variational =  1.8171098034656474\n",
      "epoch =  0 batch =  930 / 1000 loss_uniform =  1.7196648528498983  loss_variational =  1.8169309389206674\n",
      "epoch =  0 batch =  931 / 1000 loss_uniform =  1.7195836359396908  loss_variational =  1.816760071238181\n",
      "epoch =  0 batch =  932 / 1000 loss_uniform =  1.7194791926079036  loss_variational =  1.8165849451087577\n",
      "epoch =  0 batch =  933 / 1000 loss_uniform =  1.7193926958664687  loss_variational =  1.8164096187804164\n",
      "epoch =  0 batch =  934 / 1000 loss_uniform =  1.7193025512664675  loss_variational =  1.8162380316528062\n",
      "epoch =  0 batch =  935 / 1000 loss_uniform =  1.7192049540300416  loss_variational =  1.8160626241867557\n",
      "epoch =  0 batch =  936 / 1000 loss_uniform =  1.7191059240418616  loss_variational =  1.8158908659576354\n",
      "epoch =  0 batch =  937 / 1000 loss_uniform =  1.7190150780764304  loss_variational =  1.815720513001832\n",
      "epoch =  0 batch =  938 / 1000 loss_uniform =  1.7189252351138633  loss_variational =  1.8155440876224658\n",
      "epoch =  0 batch =  939 / 1000 loss_uniform =  1.718832381236286  loss_variational =  1.815401044008704\n",
      "epoch =  0 batch =  940 / 1000 loss_uniform =  1.7187388614137118  loss_variational =  1.8152282674261866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  941 / 1000 loss_uniform =  1.7186386819600294  loss_variational =  1.8150543561017225\n",
      "epoch =  0 batch =  942 / 1000 loss_uniform =  1.7185592655163657  loss_variational =  1.8149134803982552\n",
      "epoch =  0 batch =  943 / 1000 loss_uniform =  1.718456823651383  loss_variational =  1.8147404631273873\n",
      "epoch =  0 batch =  944 / 1000 loss_uniform =  1.7183659301470897  loss_variational =  1.8145704617944818\n",
      "epoch =  0 batch =  945 / 1000 loss_uniform =  1.7182739877196211  loss_variational =  1.81440085885386\n",
      "epoch =  0 batch =  946 / 1000 loss_uniform =  1.7181777991905771  loss_variational =  1.8142459514781237\n",
      "epoch =  0 batch =  947 / 1000 loss_uniform =  1.718089684513579  loss_variational =  1.8140651211693273\n",
      "epoch =  0 batch =  948 / 1000 loss_uniform =  1.7179883028133  loss_variational =  1.8138940515397473\n",
      "epoch =  0 batch =  949 / 1000 loss_uniform =  1.7178986997071755  loss_variational =  1.8137316738968783\n",
      "epoch =  0 batch =  950 / 1000 loss_uniform =  1.7178064135501254  loss_variational =  1.8135886179773433\n",
      "epoch =  0 batch =  951 / 1000 loss_uniform =  1.7177166729444706  loss_variational =  1.8134291436519285\n",
      "epoch =  0 batch =  952 / 1000 loss_uniform =  1.7176224843544114  loss_variational =  1.8132654464795812\n",
      "epoch =  0 batch =  953 / 1000 loss_uniform =  1.7175265380493112  loss_variational =  1.813110409478451\n",
      "epoch =  0 batch =  954 / 1000 loss_uniform =  1.7174453986515785  loss_variational =  1.8129619409953026\n",
      "epoch =  0 batch =  955 / 1000 loss_uniform =  1.7173472464396686  loss_variational =  1.8127855669141442\n",
      "epoch =  0 batch =  956 / 1000 loss_uniform =  1.7172589632507145  loss_variational =  1.8126372684993506\n",
      "epoch =  0 batch =  957 / 1000 loss_uniform =  1.717176272951323  loss_variational =  1.8124604318582902\n",
      "epoch =  0 batch =  958 / 1000 loss_uniform =  1.717096496598954  loss_variational =  1.812292944041075\n",
      "epoch =  0 batch =  959 / 1000 loss_uniform =  1.717003102222995  loss_variational =  1.8121298750448775\n",
      "epoch =  0 batch =  960 / 1000 loss_uniform =  1.7169312529265877  loss_variational =  1.8119722162683807\n",
      "epoch =  0 batch =  961 / 1000 loss_uniform =  1.7168377290531198  loss_variational =  1.811811146701412\n",
      "epoch =  0 batch =  962 / 1000 loss_uniform =  1.7167461122891507  loss_variational =  1.8116456832806438\n",
      "epoch =  0 batch =  963 / 1000 loss_uniform =  1.7166455071786972  loss_variational =  1.811474505243272\n",
      "epoch =  0 batch =  964 / 1000 loss_uniform =  1.716540258084095  loss_variational =  1.8112933498447863\n",
      "epoch =  0 batch =  965 / 1000 loss_uniform =  1.7164400839435  loss_variational =  1.811169372074345\n",
      "epoch =  0 batch =  966 / 1000 loss_uniform =  1.71636269341838  loss_variational =  1.811021321061729\n",
      "epoch =  0 batch =  967 / 1000 loss_uniform =  1.716282337996434  loss_variational =  1.8108494361899141\n",
      "epoch =  0 batch =  968 / 1000 loss_uniform =  1.7162020622698724  loss_variational =  1.8107074783606965\n",
      "epoch =  0 batch =  969 / 1000 loss_uniform =  1.7161008858951372  loss_variational =  1.8105711089322198\n",
      "epoch =  0 batch =  970 / 1000 loss_uniform =  1.7160085055016976  loss_variational =  1.8104166694523136\n",
      "epoch =  0 batch =  971 / 1000 loss_uniform =  1.7159355623469166  loss_variational =  1.8102869791056422\n",
      "epoch =  0 batch =  972 / 1000 loss_uniform =  1.715843349572562  loss_variational =  1.8101242398038324\n",
      "epoch =  0 batch =  973 / 1000 loss_uniform =  1.7157621731615993  loss_variational =  1.8099806242587022\n",
      "epoch =  0 batch =  974 / 1000 loss_uniform =  1.7156846514717505  loss_variational =  1.8098249056011257\n",
      "epoch =  0 batch =  975 / 1000 loss_uniform =  1.7156072965035067  loss_variational =  1.8096639347076418\n",
      "epoch =  0 batch =  976 / 1000 loss_uniform =  1.7155219303047067  loss_variational =  1.8095157997774298\n",
      "epoch =  0 batch =  977 / 1000 loss_uniform =  1.7154417113613565  loss_variational =  1.809362406862429\n",
      "epoch =  0 batch =  978 / 1000 loss_uniform =  1.7153507516184219  loss_variational =  1.8092247731602755\n",
      "epoch =  0 batch =  979 / 1000 loss_uniform =  1.715267237652553  loss_variational =  1.8090738537849764\n",
      "epoch =  0 batch =  980 / 1000 loss_uniform =  1.7151715889268988  loss_variational =  1.8089184574934902\n",
      "epoch =  0 batch =  981 / 1000 loss_uniform =  1.715081774252756  loss_variational =  1.8087737584575847\n",
      "epoch =  0 batch =  982 / 1000 loss_uniform =  1.7150060320823106  loss_variational =  1.8085981319732436\n",
      "epoch =  0 batch =  983 / 1000 loss_uniform =  1.7149224618444119  loss_variational =  1.8084489628596807\n",
      "epoch =  0 batch =  984 / 1000 loss_uniform =  1.714837729325139  loss_variational =  1.8083100841055073\n",
      "epoch =  0 batch =  985 / 1000 loss_uniform =  1.7147578930491718  loss_variational =  1.8081433900116666\n",
      "epoch =  0 batch =  986 / 1000 loss_uniform =  1.714669467832205  loss_variational =  1.8079627521381418\n",
      "epoch =  0 batch =  987 / 1000 loss_uniform =  1.7145779533830694  loss_variational =  1.8078060046276183\n",
      "epoch =  0 batch =  988 / 1000 loss_uniform =  1.7145017340839628  loss_variational =  1.8076562115296664\n",
      "epoch =  0 batch =  989 / 1000 loss_uniform =  1.7144084666206811  loss_variational =  1.8075158401977187\n",
      "epoch =  0 batch =  990 / 1000 loss_uniform =  1.7143180510010378  loss_variational =  1.8073657185140284\n",
      "epoch =  0 batch =  991 / 1000 loss_uniform =  1.7142232865786813  loss_variational =  1.807225395403765\n",
      "epoch =  0 batch =  992 / 1000 loss_uniform =  1.7141305416101404  loss_variational =  1.8070816074407872\n",
      "epoch =  0 batch =  993 / 1000 loss_uniform =  1.7140466729919952  loss_variational =  1.8069257666577268\n",
      "epoch =  0 batch =  994 / 1000 loss_uniform =  1.7139766807527366  loss_variational =  1.8067970057608378\n",
      "epoch =  0 batch =  995 / 1000 loss_uniform =  1.7138877059946103  loss_variational =  1.8066389170124306\n",
      "epoch =  0 batch =  996 / 1000 loss_uniform =  1.7138003309567764  loss_variational =  1.8064722385272445\n",
      "epoch =  0 batch =  997 / 1000 loss_uniform =  1.713712891939291  loss_variational =  1.806319982500947\n",
      "epoch =  0 batch =  998 / 1000 loss_uniform =  1.7136435329555744  loss_variational =  1.8061749009426709\n",
      "epoch =  0 batch =  999 / 1000 loss_uniform =  1.713548973993257  loss_variational =  1.8060124926380927\n",
      "epoch =  0 batch =  1000 / 1000 loss_uniform =  1.713479345798492  loss_variational =  1.8058854516744616\n",
      "epoch =  1 batch =  1 / 1000 loss_uniform =  1.6231192350387573  loss_variational =  1.657047986984253\n",
      "epoch =  1 batch =  2 / 1000 loss_uniform =  1.626738965511322  loss_variational =  1.6573830842971802\n",
      "epoch =  1 batch =  3 / 1000 loss_uniform =  1.625970999399821  loss_variational =  1.6570995648701985\n",
      "epoch =  1 batch =  4 / 1000 loss_uniform =  1.6268190443515778  loss_variational =  1.655504435300827\n",
      "epoch =  1 batch =  5 / 1000 loss_uniform =  1.626789355278015  loss_variational =  1.6525221109390258\n",
      "epoch =  1 batch =  6 / 1000 loss_uniform =  1.6262742280960083  loss_variational =  1.6487257083257039\n",
      "epoch =  1 batch =  7 / 1000 loss_uniform =  1.6251282351357597  loss_variational =  1.6478976692472185\n",
      "epoch =  1 batch =  8 / 1000 loss_uniform =  1.6257601827383041  loss_variational =  1.649348646402359\n",
      "epoch =  1 batch =  9 / 1000 loss_uniform =  1.6260564989513822  loss_variational =  1.6501441796620686\n",
      "epoch =  1 batch =  10 / 1000 loss_uniform =  1.6261291980743409  loss_variational =  1.6496395826339723\n",
      "epoch =  1 batch =  11 / 1000 loss_uniform =  1.6266002980145542  loss_variational =  1.6505181789398193\n",
      "epoch =  1 batch =  12 / 1000 loss_uniform =  1.62714488307635  loss_variational =  1.651629815498988\n",
      "epoch =  1 batch =  13 / 1000 loss_uniform =  1.6278178508465106  loss_variational =  1.6522486118169932\n",
      "epoch =  1 batch =  14 / 1000 loss_uniform =  1.6280333655221122  loss_variational =  1.6533802236829485\n",
      "epoch =  1 batch =  15 / 1000 loss_uniform =  1.6270809014638266  loss_variational =  1.6527273257573445\n",
      "epoch =  1 batch =  16 / 1000 loss_uniform =  1.6271238923072815  loss_variational =  1.6519241034984589\n",
      "epoch =  1 batch =  17 / 1000 loss_uniform =  1.627435424748589  loss_variational =  1.6530510467641495\n",
      "epoch =  1 batch =  18 / 1000 loss_uniform =  1.6276662415928311  loss_variational =  1.6527642144097223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  19 / 1000 loss_uniform =  1.6278203098397506  loss_variational =  1.6528499879335101\n",
      "epoch =  1 batch =  20 / 1000 loss_uniform =  1.628013402223587  loss_variational =  1.653170371055603\n",
      "epoch =  1 batch =  21 / 1000 loss_uniform =  1.6279938277744113  loss_variational =  1.6529998722530546\n",
      "epoch =  1 batch =  22 / 1000 loss_uniform =  1.6284429214217446  loss_variational =  1.6529346975413235\n",
      "epoch =  1 batch =  23 / 1000 loss_uniform =  1.628336621367413  loss_variational =  1.6529978980188784\n",
      "epoch =  1 batch =  24 / 1000 loss_uniform =  1.6287933041652043  loss_variational =  1.6532084792852402\n",
      "epoch =  1 batch =  25 / 1000 loss_uniform =  1.6288789653778075  loss_variational =  1.653622260093689\n",
      "epoch =  1 batch =  26 / 1000 loss_uniform =  1.629077970981598  loss_variational =  1.6538846859565148\n",
      "epoch =  1 batch =  27 / 1000 loss_uniform =  1.629141953256395  loss_variational =  1.6539628594009965\n",
      "epoch =  1 batch =  28 / 1000 loss_uniform =  1.6290137682642256  loss_variational =  1.6545127119336809\n",
      "epoch =  1 batch =  29 / 1000 loss_uniform =  1.6284971154969314  loss_variational =  1.6546778308934178\n",
      "epoch =  1 batch =  30 / 1000 loss_uniform =  1.6284297903378804  loss_variational =  1.654921817779541\n",
      "epoch =  1 batch =  31 / 1000 loss_uniform =  1.6288728098715506  loss_variational =  1.6554731822782947\n",
      "epoch =  1 batch =  32 / 1000 loss_uniform =  1.6291795074939728  loss_variational =  1.6552360728383064\n",
      "epoch =  1 batch =  33 / 1000 loss_uniform =  1.6292163241993298  loss_variational =  1.6551438678394665\n",
      "epoch =  1 batch =  34 / 1000 loss_uniform =  1.6295325756072998  loss_variational =  1.6553281685885262\n",
      "epoch =  1 batch =  35 / 1000 loss_uniform =  1.629393720626831  loss_variational =  1.654877689906529\n",
      "epoch =  1 batch =  36 / 1000 loss_uniform =  1.629707054959403  loss_variational =  1.6550569203164842\n",
      "epoch =  1 batch =  37 / 1000 loss_uniform =  1.6296952254063375  loss_variational =  1.6559805000150525\n",
      "epoch =  1 batch =  38 / 1000 loss_uniform =  1.629674754644695  loss_variational =  1.6559348545576396\n",
      "epoch =  1 batch =  39 / 1000 loss_uniform =  1.6294613373585236  loss_variational =  1.656018886810694\n",
      "epoch =  1 batch =  40 / 1000 loss_uniform =  1.6293292105197907  loss_variational =  1.656434491276741\n",
      "epoch =  1 batch =  41 / 1000 loss_uniform =  1.6290052809366367  loss_variational =  1.6563053480008754\n",
      "epoch =  1 batch =  42 / 1000 loss_uniform =  1.6287412813731603  loss_variational =  1.655890166759491\n",
      "epoch =  1 batch =  43 / 1000 loss_uniform =  1.6288709474164387  loss_variational =  1.6566371806832247\n",
      "epoch =  1 batch =  44 / 1000 loss_uniform =  1.6292906647378749  loss_variational =  1.6562581008130854\n",
      "epoch =  1 batch =  45 / 1000 loss_uniform =  1.629402632183499  loss_variational =  1.6564658217959933\n",
      "epoch =  1 batch =  46 / 1000 loss_uniform =  1.6293637985768525  loss_variational =  1.65668168016102\n",
      "epoch =  1 batch =  47 / 1000 loss_uniform =  1.6293674834231113  loss_variational =  1.656554381898109\n",
      "epoch =  1 batch =  48 / 1000 loss_uniform =  1.6292750164866447  loss_variational =  1.6564806401729584\n",
      "epoch =  1 batch =  49 / 1000 loss_uniform =  1.629448228952836  loss_variational =  1.6565803727325128\n",
      "epoch =  1 batch =  50 / 1000 loss_uniform =  1.6293907809257506  loss_variational =  1.6568033289909363\n",
      "epoch =  1 batch =  51 / 1000 loss_uniform =  1.629342004364612  loss_variational =  1.656844548150605\n",
      "epoch =  1 batch =  52 / 1000 loss_uniform =  1.6293743459077983  loss_variational =  1.6567953389424543\n",
      "epoch =  1 batch =  53 / 1000 loss_uniform =  1.629333514087605  loss_variational =  1.6570118283325772\n",
      "epoch =  1 batch =  54 / 1000 loss_uniform =  1.6294673637107566  loss_variational =  1.6570681112783927\n",
      "epoch =  1 batch =  55 / 1000 loss_uniform =  1.629484714161266  loss_variational =  1.6567637877030805\n",
      "epoch =  1 batch =  56 / 1000 loss_uniform =  1.6296039202383585  loss_variational =  1.6569161925997054\n",
      "epoch =  1 batch =  57 / 1000 loss_uniform =  1.6296949574821873  loss_variational =  1.6568195066953961\n",
      "epoch =  1 batch =  58 / 1000 loss_uniform =  1.6299220981269047  loss_variational =  1.6568395618734688\n",
      "epoch =  1 batch =  59 / 1000 loss_uniform =  1.629927136130252  loss_variational =  1.6568178928504556\n",
      "epoch =  1 batch =  60 / 1000 loss_uniform =  1.629654731353124  loss_variational =  1.657015828291575\n",
      "epoch =  1 batch =  61 / 1000 loss_uniform =  1.629468065793397  loss_variational =  1.6572643733415446\n",
      "epoch =  1 batch =  62 / 1000 loss_uniform =  1.6295255845592869  loss_variational =  1.657556866445849\n",
      "epoch =  1 batch =  63 / 1000 loss_uniform =  1.6293535648830353  loss_variational =  1.6576603442903548\n",
      "epoch =  1 batch =  64 / 1000 loss_uniform =  1.6293481215834618  loss_variational =  1.6577020678669214\n",
      "epoch =  1 batch =  65 / 1000 loss_uniform =  1.6292765268912681  loss_variational =  1.657467537659865\n",
      "epoch =  1 batch =  66 / 1000 loss_uniform =  1.6294121128140073  loss_variational =  1.6574163509137703\n",
      "epoch =  1 batch =  67 / 1000 loss_uniform =  1.6294450581963382  loss_variational =  1.6572606510190822\n",
      "epoch =  1 batch =  68 / 1000 loss_uniform =  1.6295902658911312  loss_variational =  1.657268241924398\n",
      "epoch =  1 batch =  69 / 1000 loss_uniform =  1.6295174636702607  loss_variational =  1.6569381969562476\n",
      "epoch =  1 batch =  70 / 1000 loss_uniform =  1.6295839088303703  loss_variational =  1.6570341518947056\n",
      "epoch =  1 batch =  71 / 1000 loss_uniform =  1.6294739582169224  loss_variational =  1.6568347215652466\n",
      "epoch =  1 batch =  72 / 1000 loss_uniform =  1.6294841435220506  loss_variational =  1.656923633482721\n",
      "epoch =  1 batch =  73 / 1000 loss_uniform =  1.629341439025043  loss_variational =  1.656865417140804\n",
      "epoch =  1 batch =  74 / 1000 loss_uniform =  1.6291672410191718  loss_variational =  1.6569224515476741\n",
      "epoch =  1 batch =  75 / 1000 loss_uniform =  1.6291249815622968  loss_variational =  1.656932471593221\n",
      "epoch =  1 batch =  76 / 1000 loss_uniform =  1.6291337907314303  loss_variational =  1.6569645483242839\n",
      "epoch =  1 batch =  77 / 1000 loss_uniform =  1.6291294159827296  loss_variational =  1.6568564842273663\n",
      "epoch =  1 batch =  78 / 1000 loss_uniform =  1.6292059406256065  loss_variational =  1.6569333550257561\n",
      "epoch =  1 batch =  79 / 1000 loss_uniform =  1.6292095335224006  loss_variational =  1.6570790749561937\n",
      "epoch =  1 batch =  80 / 1000 loss_uniform =  1.6292570382356644  loss_variational =  1.6568406701087952\n",
      "epoch =  1 batch =  81 / 1000 loss_uniform =  1.6292355840588792  loss_variational =  1.656836121170609\n",
      "epoch =  1 batch =  82 / 1000 loss_uniform =  1.6290981842250358  loss_variational =  1.6566256473704082\n",
      "epoch =  1 batch =  83 / 1000 loss_uniform =  1.6290889892233424  loss_variational =  1.656555417072342\n",
      "epoch =  1 batch =  84 / 1000 loss_uniform =  1.6290899756408872  loss_variational =  1.6562310372080122\n",
      "epoch =  1 batch =  85 / 1000 loss_uniform =  1.6290179070304422  loss_variational =  1.6562455345602596\n",
      "epoch =  1 batch =  86 / 1000 loss_uniform =  1.6290920321331468  loss_variational =  1.656428104223207\n",
      "epoch =  1 batch =  87 / 1000 loss_uniform =  1.629136937788163  loss_variational =  1.6564420982338917\n",
      "epoch =  1 batch =  88 / 1000 loss_uniform =  1.6291414892131633  loss_variational =  1.6565626968037\n",
      "epoch =  1 batch =  89 / 1000 loss_uniform =  1.6290711673457972  loss_variational =  1.6565207885892204\n",
      "epoch =  1 batch =  90 / 1000 loss_uniform =  1.6290320065286426  loss_variational =  1.6567389302783542\n",
      "epoch =  1 batch =  91 / 1000 loss_uniform =  1.6290027400949498  loss_variational =  1.656614342888633\n",
      "epoch =  1 batch =  92 / 1000 loss_uniform =  1.6289620373560034  loss_variational =  1.6565224295077117\n",
      "epoch =  1 batch =  93 / 1000 loss_uniform =  1.628983953947662  loss_variational =  1.656567863238755\n",
      "epoch =  1 batch =  94 / 1000 loss_uniform =  1.6290646499775825  loss_variational =  1.656615325745116\n",
      "epoch =  1 batch =  95 / 1000 loss_uniform =  1.6290473185087506  loss_variational =  1.6567694889871698\n",
      "epoch =  1 batch =  96 / 1000 loss_uniform =  1.6291356620689232  loss_variational =  1.6568001608053844\n",
      "epoch =  1 batch =  97 / 1000 loss_uniform =  1.62912294913813  loss_variational =  1.6567781991565351\n",
      "epoch =  1 batch =  98 / 1000 loss_uniform =  1.6291390073542693  loss_variational =  1.6566603074268418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  99 / 1000 loss_uniform =  1.629113298473936  loss_variational =  1.6565155802351055\n",
      "epoch =  1 batch =  100 / 1000 loss_uniform =  1.6291351640224456  loss_variational =  1.6563155877590179\n",
      "epoch =  1 batch =  101 / 1000 loss_uniform =  1.629168196479873  loss_variational =  1.656421954088872\n",
      "epoch =  1 batch =  102 / 1000 loss_uniform =  1.6292017639852037  loss_variational =  1.656356372085272\n",
      "epoch =  1 batch =  103 / 1000 loss_uniform =  1.6291343714427022  loss_variational =  1.656329342462484\n",
      "epoch =  1 batch =  104 / 1000 loss_uniform =  1.6292056017197096  loss_variational =  1.6563335760281637\n",
      "epoch =  1 batch =  105 / 1000 loss_uniform =  1.629287959280468  loss_variational =  1.6562902518681117\n",
      "epoch =  1 batch =  106 / 1000 loss_uniform =  1.6293926463936859  loss_variational =  1.6561358109960016\n",
      "epoch =  1 batch =  107 / 1000 loss_uniform =  1.6294617942560499  loss_variational =  1.6561722532611027\n",
      "epoch =  1 batch =  108 / 1000 loss_uniform =  1.6294383936458163  loss_variational =  1.6561266228004738\n",
      "epoch =  1 batch =  109 / 1000 loss_uniform =  1.629522183619508  loss_variational =  1.6562801107354121\n",
      "epoch =  1 batch =  110 / 1000 loss_uniform =  1.6295987096699802  loss_variational =  1.6565099922093478\n",
      "epoch =  1 batch =  111 / 1000 loss_uniform =  1.6295360552298057  loss_variational =  1.6564260764164969\n",
      "epoch =  1 batch =  112 / 1000 loss_uniform =  1.629502045256751  loss_variational =  1.6563281640410423\n",
      "epoch =  1 batch =  113 / 1000 loss_uniform =  1.6293582072300195  loss_variational =  1.6561692372887535\n",
      "epoch =  1 batch =  114 / 1000 loss_uniform =  1.6293417183976424  loss_variational =  1.6561967050820066\n",
      "epoch =  1 batch =  115 / 1000 loss_uniform =  1.6292976866597715  loss_variational =  1.6562211969624394\n",
      "epoch =  1 batch =  116 / 1000 loss_uniform =  1.6293955496672927  loss_variational =  1.656229011971375\n",
      "epoch =  1 batch =  117 / 1000 loss_uniform =  1.6293482230259821  loss_variational =  1.6563701935303516\n",
      "epoch =  1 batch =  118 / 1000 loss_uniform =  1.6292486716124972  loss_variational =  1.6565043572652138\n",
      "epoch =  1 batch =  119 / 1000 loss_uniform =  1.6291525383957295  loss_variational =  1.6563963960198795\n",
      "epoch =  1 batch =  120 / 1000 loss_uniform =  1.62916197180748  loss_variational =  1.6563155770301818\n",
      "epoch =  1 batch =  121 / 1000 loss_uniform =  1.6290945504322525  loss_variational =  1.656293045390736\n",
      "epoch =  1 batch =  122 / 1000 loss_uniform =  1.6290350566144849  loss_variational =  1.6562336067684362\n",
      "epoch =  1 batch =  123 / 1000 loss_uniform =  1.6290687458301947  loss_variational =  1.6563946376971113\n",
      "epoch =  1 batch =  124 / 1000 loss_uniform =  1.6290271484082746  loss_variational =  1.6563564567796645\n",
      "epoch =  1 batch =  125 / 1000 loss_uniform =  1.6290096321105958  loss_variational =  1.6564065780639647\n",
      "epoch =  1 batch =  126 / 1000 loss_uniform =  1.6290587451722887  loss_variational =  1.6563082384684729\n",
      "epoch =  1 batch =  127 / 1000 loss_uniform =  1.6290282715023972  loss_variational =  1.6561623295461099\n",
      "epoch =  1 batch =  128 / 1000 loss_uniform =  1.6290894774720073  loss_variational =  1.6561015658080578\n",
      "epoch =  1 batch =  129 / 1000 loss_uniform =  1.6290345515391624  loss_variational =  1.656106858290443\n",
      "epoch =  1 batch =  130 / 1000 loss_uniform =  1.6290873197408824  loss_variational =  1.656014648767618\n",
      "epoch =  1 batch =  131 / 1000 loss_uniform =  1.6291267971956094  loss_variational =  1.6559591029436533\n",
      "epoch =  1 batch =  132 / 1000 loss_uniform =  1.6292309146938901  loss_variational =  1.6559310140031758\n",
      "epoch =  1 batch =  133 / 1000 loss_uniform =  1.6292304759635066  loss_variational =  1.6559942405026657\n",
      "epoch =  1 batch =  134 / 1000 loss_uniform =  1.6293066668866285  loss_variational =  1.6561282775295314\n",
      "epoch =  1 batch =  135 / 1000 loss_uniform =  1.6293822164888736  loss_variational =  1.6561523728900485\n",
      "epoch =  1 batch =  136 / 1000 loss_uniform =  1.6293106789098066  loss_variational =  1.6561947009142708\n",
      "epoch =  1 batch =  137 / 1000 loss_uniform =  1.6292677848008428  loss_variational =  1.6561403709606533\n",
      "epoch =  1 batch =  138 / 1000 loss_uniform =  1.6293179444644763  loss_variational =  1.6561566979988762\n",
      "epoch =  1 batch =  139 / 1000 loss_uniform =  1.6293513689109747  loss_variational =  1.6562043737164505\n",
      "epoch =  1 batch =  140 / 1000 loss_uniform =  1.6293998641627176  loss_variational =  1.6561857197965895\n",
      "epoch =  1 batch =  141 / 1000 loss_uniform =  1.6294413619007624  loss_variational =  1.6561464003637327\n",
      "epoch =  1 batch =  142 / 1000 loss_uniform =  1.6295087950330385  loss_variational =  1.6561524448260454\n",
      "epoch =  1 batch =  143 / 1000 loss_uniform =  1.6295039695459645  loss_variational =  1.656147802626336\n",
      "epoch =  1 batch =  144 / 1000 loss_uniform =  1.6294811591506004  loss_variational =  1.6560727987024517\n",
      "epoch =  1 batch =  145 / 1000 loss_uniform =  1.6295076246919302  loss_variational =  1.6558679235392602\n",
      "epoch =  1 batch =  146 / 1000 loss_uniform =  1.62953636336  loss_variational =  1.655815594000359\n",
      "epoch =  1 batch =  147 / 1000 loss_uniform =  1.6295655162966982  loss_variational =  1.655750328180741\n",
      "epoch =  1 batch =  148 / 1000 loss_uniform =  1.6296393259151563  loss_variational =  1.6558156319566673\n",
      "epoch =  1 batch =  149 / 1000 loss_uniform =  1.6296954082962651  loss_variational =  1.6558221722609243\n",
      "epoch =  1 batch =  150 / 1000 loss_uniform =  1.6297326374053955  loss_variational =  1.6558872763315835\n",
      "epoch =  1 batch =  151 / 1000 loss_uniform =  1.6298121198123654  loss_variational =  1.6559367811442998\n",
      "epoch =  1 batch =  152 / 1000 loss_uniform =  1.629802005071389  loss_variational =  1.655877625471667\n",
      "epoch =  1 batch =  153 / 1000 loss_uniform =  1.6298137248731126  loss_variational =  1.6558586608350663\n",
      "epoch =  1 batch =  154 / 1000 loss_uniform =  1.6298636438010574  loss_variational =  1.6558137149005738\n",
      "epoch =  1 batch =  155 / 1000 loss_uniform =  1.6298331760591076  loss_variational =  1.6556417019136487\n",
      "epoch =  1 batch =  156 / 1000 loss_uniform =  1.6298581911967351  loss_variational =  1.6555608442196477\n",
      "epoch =  1 batch =  157 / 1000 loss_uniform =  1.6298109839676291  loss_variational =  1.6555811910872242\n",
      "epoch =  1 batch =  158 / 1000 loss_uniform =  1.6298262439196622  loss_variational =  1.655564769159389\n",
      "epoch =  1 batch =  159 / 1000 loss_uniform =  1.6299229125556707  loss_variational =  1.6555994719079452\n",
      "epoch =  1 batch =  160 / 1000 loss_uniform =  1.6299345083534718  loss_variational =  1.6555959217250344\n",
      "epoch =  1 batch =  161 / 1000 loss_uniform =  1.6299886651661084  loss_variational =  1.6554843091076201\n",
      "epoch =  1 batch =  162 / 1000 loss_uniform =  1.6300318896034618  loss_variational =  1.655449596452124\n",
      "epoch =  1 batch =  163 / 1000 loss_uniform =  1.6300385093396426  loss_variational =  1.655381741699265\n",
      "epoch =  1 batch =  164 / 1000 loss_uniform =  1.6299662669984305  loss_variational =  1.6554148458852997\n",
      "epoch =  1 batch =  165 / 1000 loss_uniform =  1.6299917827952992  loss_variational =  1.655313521442991\n",
      "epoch =  1 batch =  166 / 1000 loss_uniform =  1.6299177839095333  loss_variational =  1.6551717627479365\n",
      "epoch =  1 batch =  167 / 1000 loss_uniform =  1.6299093940300855  loss_variational =  1.6551840747901776\n",
      "epoch =  1 batch =  168 / 1000 loss_uniform =  1.629936729868253  loss_variational =  1.6551728809163682\n",
      "epoch =  1 batch =  169 / 1000 loss_uniform =  1.629910634114192  loss_variational =  1.6551444064935985\n",
      "epoch =  1 batch =  170 / 1000 loss_uniform =  1.6298322761760038  loss_variational =  1.6551302124472222\n",
      "epoch =  1 batch =  171 / 1000 loss_uniform =  1.6298985042070087  loss_variational =  1.6550635977795247\n",
      "epoch =  1 batch =  172 / 1000 loss_uniform =  1.6299254166525463  loss_variational =  1.6550332869208133\n",
      "epoch =  1 batch =  173 / 1000 loss_uniform =  1.6299251855453314  loss_variational =  1.65483222255817\n",
      "epoch =  1 batch =  174 / 1000 loss_uniform =  1.6299599011739094  loss_variational =  1.6548549560294752\n",
      "epoch =  1 batch =  175 / 1000 loss_uniform =  1.6298821408408029  loss_variational =  1.6547966827665053\n",
      "epoch =  1 batch =  176 / 1000 loss_uniform =  1.629937786947597  loss_variational =  1.6549215459010815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  177 / 1000 loss_uniform =  1.629983339606032  loss_variational =  1.654963948632364\n",
      "epoch =  1 batch =  178 / 1000 loss_uniform =  1.629958206348205  loss_variational =  1.6549839678775056\n",
      "epoch =  1 batch =  179 / 1000 loss_uniform =  1.6299071964604894  loss_variational =  1.6549861198031033\n",
      "epoch =  1 batch =  180 / 1000 loss_uniform =  1.6299321631590524  loss_variational =  1.655004576179716\n",
      "epoch =  1 batch =  181 / 1000 loss_uniform =  1.6298844037135003  loss_variational =  1.6549438995551007\n",
      "epoch =  1 batch =  182 / 1000 loss_uniform =  1.6298224670546395  loss_variational =  1.654971116191738\n",
      "epoch =  1 batch =  183 / 1000 loss_uniform =  1.6298347705048941  loss_variational =  1.6550593043937054\n",
      "epoch =  1 batch =  184 / 1000 loss_uniform =  1.629820797106494  loss_variational =  1.6550456194773961\n",
      "epoch =  1 batch =  185 / 1000 loss_uniform =  1.629782440211322  loss_variational =  1.6549670122765203\n",
      "epoch =  1 batch =  186 / 1000 loss_uniform =  1.6297091623788238  loss_variational =  1.6550299967488933\n",
      "epoch =  1 batch =  187 / 1000 loss_uniform =  1.6297197208047551  loss_variational =  1.6550399638752247\n",
      "epoch =  1 batch =  188 / 1000 loss_uniform =  1.6297211196828396  loss_variational =  1.6549702064788085\n",
      "epoch =  1 batch =  189 / 1000 loss_uniform =  1.6297374402404463  loss_variational =  1.6549418180707898\n",
      "epoch =  1 batch =  190 / 1000 loss_uniform =  1.6298128448034588  loss_variational =  1.6548898703173585\n",
      "epoch =  1 batch =  191 / 1000 loss_uniform =  1.6297673186706623  loss_variational =  1.6549141275945132\n",
      "epoch =  1 batch =  192 / 1000 loss_uniform =  1.629765510559082  loss_variational =  1.6549533034364379\n",
      "epoch =  1 batch =  193 / 1000 loss_uniform =  1.6297650948707303  loss_variational =  1.6548401191444593\n",
      "epoch =  1 batch =  194 / 1000 loss_uniform =  1.6297626827181  loss_variational =  1.654784949784426\n",
      "epoch =  1 batch =  195 / 1000 loss_uniform =  1.6297941342378275  loss_variational =  1.6548012262735607\n",
      "epoch =  1 batch =  196 / 1000 loss_uniform =  1.6298382367406572  loss_variational =  1.6548515825855485\n",
      "epoch =  1 batch =  197 / 1000 loss_uniform =  1.6298188418906352  loss_variational =  1.6548610943828135\n",
      "epoch =  1 batch =  198 / 1000 loss_uniform =  1.6298461821344163  loss_variational =  1.6548611985312565\n",
      "epoch =  1 batch =  199 / 1000 loss_uniform =  1.62976214933635  loss_variational =  1.6548933881012036\n",
      "epoch =  1 batch =  200 / 1000 loss_uniform =  1.6297210329771041  loss_variational =  1.6547680085897443\n",
      "epoch =  1 batch =  201 / 1000 loss_uniform =  1.6296736185823506  loss_variational =  1.6548280899797503\n",
      "epoch =  1 batch =  202 / 1000 loss_uniform =  1.6296157258571964  loss_variational =  1.6548949952172758\n",
      "epoch =  1 batch =  203 / 1000 loss_uniform =  1.62956535992364  loss_variational =  1.6548996605896595\n",
      "epoch =  1 batch =  204 / 1000 loss_uniform =  1.629562837820427  loss_variational =  1.6548528449208126\n",
      "epoch =  1 batch =  205 / 1000 loss_uniform =  1.629539222833587  loss_variational =  1.6549343114945945\n",
      "epoch =  1 batch =  206 / 1000 loss_uniform =  1.6295644044876099  loss_variational =  1.6549564090747275\n",
      "epoch =  1 batch =  207 / 1000 loss_uniform =  1.6295676145000735  loss_variational =  1.6549175695520666\n",
      "epoch =  1 batch =  208 / 1000 loss_uniform =  1.6295427198593433  loss_variational =  1.6548379969138363\n",
      "epoch =  1 batch =  209 / 1000 loss_uniform =  1.6295652566343974  loss_variational =  1.6549016094664064\n",
      "epoch =  1 batch =  210 / 1000 loss_uniform =  1.6295467620804196  loss_variational =  1.6548523482822235\n",
      "epoch =  1 batch =  211 / 1000 loss_uniform =  1.629510936578868  loss_variational =  1.654889850819845\n",
      "epoch =  1 batch =  212 / 1000 loss_uniform =  1.6294692018122043  loss_variational =  1.6548128516044254\n",
      "epoch =  1 batch =  213 / 1000 loss_uniform =  1.6294905534932311  loss_variational =  1.654706065643561\n",
      "epoch =  1 batch =  214 / 1000 loss_uniform =  1.6295455354396429  loss_variational =  1.6546389811506892\n",
      "epoch =  1 batch =  215 / 1000 loss_uniform =  1.6295520283455072  loss_variational =  1.6546244443849074\n",
      "epoch =  1 batch =  216 / 1000 loss_uniform =  1.6295587988915268  loss_variational =  1.6546084483464556\n",
      "epoch =  1 batch =  217 / 1000 loss_uniform =  1.6295124797777096  loss_variational =  1.654568227205408\n",
      "epoch =  1 batch =  218 / 1000 loss_uniform =  1.6295156648399634  loss_variational =  1.6546021060112417\n",
      "epoch =  1 batch =  219 / 1000 loss_uniform =  1.6294674846135317  loss_variational =  1.6545855166160894\n",
      "epoch =  1 batch =  220 / 1000 loss_uniform =  1.6294980628923936  loss_variational =  1.6546039039438418\n",
      "epoch =  1 batch =  221 / 1000 loss_uniform =  1.6294735675483807  loss_variational =  1.6544984945884116\n",
      "epoch =  1 batch =  222 / 1000 loss_uniform =  1.6294200731827333  loss_variational =  1.6544033740017863\n",
      "epoch =  1 batch =  223 / 1000 loss_uniform =  1.629397003105403  loss_variational =  1.6543620188674582\n",
      "epoch =  1 batch =  224 / 1000 loss_uniform =  1.629381856748036  loss_variational =  1.65437016370041\n",
      "epoch =  1 batch =  225 / 1000 loss_uniform =  1.6293416865666708  loss_variational =  1.6543585464689463\n",
      "epoch =  1 batch =  226 / 1000 loss_uniform =  1.6293795678467877  loss_variational =  1.65432174226879\n",
      "epoch =  1 batch =  227 / 1000 loss_uniform =  1.6294052359291111  loss_variational =  1.6543463741630182\n",
      "epoch =  1 batch =  228 / 1000 loss_uniform =  1.6293574440897556  loss_variational =  1.6543177517882561\n",
      "epoch =  1 batch =  229 / 1000 loss_uniform =  1.6293875780688623  loss_variational =  1.6543719539475752\n",
      "epoch =  1 batch =  230 / 1000 loss_uniform =  1.6293963981711346  loss_variational =  1.654390712406324\n",
      "epoch =  1 batch =  231 / 1000 loss_uniform =  1.629401810241468  loss_variational =  1.6544121514151104\n",
      "epoch =  1 batch =  232 / 1000 loss_uniform =  1.62940004930414  loss_variational =  1.654463928321312\n",
      "epoch =  1 batch =  233 / 1000 loss_uniform =  1.6294081778997003  loss_variational =  1.6543929699664461\n",
      "epoch =  1 batch =  234 / 1000 loss_uniform =  1.6294443714313018  loss_variational =  1.6543725550684152\n",
      "epoch =  1 batch =  235 / 1000 loss_uniform =  1.6294297948796699  loss_variational =  1.654349298680082\n",
      "epoch =  1 batch =  236 / 1000 loss_uniform =  1.6294870300818298  loss_variational =  1.6544308409852495\n",
      "epoch =  1 batch =  237 / 1000 loss_uniform =  1.629425836514823  loss_variational =  1.654437082729259\n",
      "epoch =  1 batch =  238 / 1000 loss_uniform =  1.6294019713121302  loss_variational =  1.6544131541452485\n",
      "epoch =  1 batch =  239 / 1000 loss_uniform =  1.6294018239655754  loss_variational =  1.654443899956707\n",
      "epoch =  1 batch =  240 / 1000 loss_uniform =  1.629492392639319  loss_variational =  1.6544905980428057\n",
      "epoch =  1 batch =  241 / 1000 loss_uniform =  1.6294075428697579  loss_variational =  1.65445347742421\n",
      "epoch =  1 batch =  242 / 1000 loss_uniform =  1.629379828114155  loss_variational =  1.654473998329856\n",
      "epoch =  1 batch =  243 / 1000 loss_uniform =  1.6293866565688648  loss_variational =  1.6545525602843043\n",
      "epoch =  1 batch =  244 / 1000 loss_uniform =  1.6293778263154577  loss_variational =  1.6544859194364703\n",
      "epoch =  1 batch =  245 / 1000 loss_uniform =  1.6293805088315692  loss_variational =  1.6545698749775788\n",
      "epoch =  1 batch =  246 / 1000 loss_uniform =  1.6293973631975127  loss_variational =  1.6546284071798245\n",
      "epoch =  1 batch =  247 / 1000 loss_uniform =  1.6293682381209091  loss_variational =  1.6545648570002813\n",
      "epoch =  1 batch =  248 / 1000 loss_uniform =  1.6294026716101555  loss_variational =  1.6545087608598892\n",
      "epoch =  1 batch =  249 / 1000 loss_uniform =  1.6293281086956162  loss_variational =  1.6544864924557237\n",
      "epoch =  1 batch =  250 / 1000 loss_uniform =  1.6293308749198914  loss_variational =  1.6545497255325314\n",
      "epoch =  1 batch =  251 / 1000 loss_uniform =  1.6293359500953402  loss_variational =  1.6545551089176616\n",
      "epoch =  1 batch =  252 / 1000 loss_uniform =  1.6293561070684404  loss_variational =  1.6544678532888017\n",
      "epoch =  1 batch =  253 / 1000 loss_uniform =  1.6293338980128171  loss_variational =  1.6544887529531485\n",
      "epoch =  1 batch =  254 / 1000 loss_uniform =  1.6293331952545587  loss_variational =  1.6544237207240005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  255 / 1000 loss_uniform =  1.6294018932417327  loss_variational =  1.6544519073822916\n",
      "epoch =  1 batch =  256 / 1000 loss_uniform =  1.629426009953022  loss_variational =  1.6544656865298746\n",
      "epoch =  1 batch =  257 / 1000 loss_uniform =  1.6293736779736174  loss_variational =  1.6544684385047346\n",
      "epoch =  1 batch =  258 / 1000 loss_uniform =  1.6293517600658327  loss_variational =  1.6544117904448692\n",
      "epoch =  1 batch =  259 / 1000 loss_uniform =  1.6293591734985586  loss_variational =  1.654409821889575\n",
      "epoch =  1 batch =  260 / 1000 loss_uniform =  1.6293446059410388  loss_variational =  1.6544238833280709\n",
      "epoch =  1 batch =  261 / 1000 loss_uniform =  1.6293398763028142  loss_variational =  1.6544518333741987\n",
      "epoch =  1 batch =  262 / 1000 loss_uniform =  1.629299983723473  loss_variational =  1.6544118218749533\n",
      "epoch =  1 batch =  263 / 1000 loss_uniform =  1.6292881820591683  loss_variational =  1.654402312217103\n",
      "epoch =  1 batch =  264 / 1000 loss_uniform =  1.6293165855335467  loss_variational =  1.6543547872341038\n",
      "epoch =  1 batch =  265 / 1000 loss_uniform =  1.629280785794528  loss_variational =  1.6543739885654087\n",
      "epoch =  1 batch =  266 / 1000 loss_uniform =  1.629279327123685  loss_variational =  1.6542976664421252\n",
      "epoch =  1 batch =  267 / 1000 loss_uniform =  1.6293051175856859  loss_variational =  1.6543345897831718\n",
      "epoch =  1 batch =  268 / 1000 loss_uniform =  1.6293384859811013  loss_variational =  1.6543935630748519\n",
      "epoch =  1 batch =  269 / 1000 loss_uniform =  1.6293532303274785  loss_variational =  1.6543561663326276\n",
      "epoch =  1 batch =  270 / 1000 loss_uniform =  1.6294218522531014  loss_variational =  1.6543450364360102\n",
      "epoch =  1 batch =  271 / 1000 loss_uniform =  1.629419868722613  loss_variational =  1.6542745269972459\n",
      "epoch =  1 batch =  272 / 1000 loss_uniform =  1.629452011164497  loss_variational =  1.6543292280505684\n",
      "epoch =  1 batch =  273 / 1000 loss_uniform =  1.6294421630027967  loss_variational =  1.6543376070239166\n",
      "epoch =  1 batch =  274 / 1000 loss_uniform =  1.6294024286478976  loss_variational =  1.654260100674455\n",
      "epoch =  1 batch =  275 / 1000 loss_uniform =  1.6294003404270518  loss_variational =  1.6541912555694578\n",
      "epoch =  1 batch =  276 / 1000 loss_uniform =  1.6293898773366127  loss_variational =  1.6541555083316304\n",
      "epoch =  1 batch =  277 / 1000 loss_uniform =  1.629373160510287  loss_variational =  1.654132440632431\n",
      "epoch =  1 batch =  278 / 1000 loss_uniform =  1.629363906040466  loss_variational =  1.654101343892461\n",
      "epoch =  1 batch =  279 / 1000 loss_uniform =  1.629395146096479  loss_variational =  1.6541027539947124\n",
      "epoch =  1 batch =  280 / 1000 loss_uniform =  1.6294121818883078  loss_variational =  1.6540833979845044\n",
      "epoch =  1 batch =  281 / 1000 loss_uniform =  1.6294487812340896  loss_variational =  1.6540756811026573\n",
      "epoch =  1 batch =  282 / 1000 loss_uniform =  1.6294548536868805  loss_variational =  1.6540621375361229\n",
      "epoch =  1 batch =  283 / 1000 loss_uniform =  1.6294639009468967  loss_variational =  1.6540776352157858\n",
      "epoch =  1 batch =  284 / 1000 loss_uniform =  1.6294862443292644  loss_variational =  1.6541360385820896\n",
      "epoch =  1 batch =  285 / 1000 loss_uniform =  1.6294654657966212  loss_variational =  1.6541309549097425\n",
      "epoch =  1 batch =  286 / 1000 loss_uniform =  1.6294553013114663  loss_variational =  1.654143844034288\n",
      "epoch =  1 batch =  287 / 1000 loss_uniform =  1.6294247746882953  loss_variational =  1.6540763457062349\n",
      "epoch =  1 batch =  288 / 1000 loss_uniform =  1.629427017437087  loss_variational =  1.6540694948699735\n",
      "epoch =  1 batch =  289 / 1000 loss_uniform =  1.629354355656977  loss_variational =  1.65407801210674\n",
      "epoch =  1 batch =  290 / 1000 loss_uniform =  1.6293601467691619  loss_variational =  1.6540206596769131\n",
      "epoch =  1 batch =  291 / 1000 loss_uniform =  1.6293399252023075  loss_variational =  1.653971506557923\n",
      "epoch =  1 batch =  292 / 1000 loss_uniform =  1.629370885352566  loss_variational =  1.6539461959714754\n",
      "epoch =  1 batch =  293 / 1000 loss_uniform =  1.6293985001463125  loss_variational =  1.6540054774528474\n",
      "epoch =  1 batch =  294 / 1000 loss_uniform =  1.6293799763634091  loss_variational =  1.6539522429712772\n",
      "epoch =  1 batch =  295 / 1000 loss_uniform =  1.6294026075783423  loss_variational =  1.6539306042558053\n",
      "epoch =  1 batch =  296 / 1000 loss_uniform =  1.6294132970474862  loss_variational =  1.6538632278506817\n",
      "epoch =  1 batch =  297 / 1000 loss_uniform =  1.6294580461200239  loss_variational =  1.6538906803837525\n",
      "epoch =  1 batch =  298 / 1000 loss_uniform =  1.629445111591544  loss_variational =  1.6538900052941081\n",
      "epoch =  1 batch =  299 / 1000 loss_uniform =  1.6294644213839122  loss_variational =  1.653824482075745\n",
      "epoch =  1 batch =  300 / 1000 loss_uniform =  1.6294892231623335  loss_variational =  1.6537946995099382\n",
      "epoch =  1 batch =  301 / 1000 loss_uniform =  1.6294931929768919  loss_variational =  1.6537500406024461\n",
      "epoch =  1 batch =  302 / 1000 loss_uniform =  1.6294787135345263  loss_variational =  1.6537443446797249\n",
      "epoch =  1 batch =  303 / 1000 loss_uniform =  1.6294537121706676  loss_variational =  1.6537192217981065\n",
      "epoch =  1 batch =  304 / 1000 loss_uniform =  1.6294473476315805  loss_variational =  1.6536979506674563\n",
      "epoch =  1 batch =  305 / 1000 loss_uniform =  1.6294579384756875  loss_variational =  1.6537073967886748\n",
      "epoch =  1 batch =  306 / 1000 loss_uniform =  1.6294674588963882  loss_variational =  1.6537052264400554\n",
      "epoch =  1 batch =  307 / 1000 loss_uniform =  1.6294756622966808  loss_variational =  1.6537365859028568\n",
      "epoch =  1 batch =  308 / 1000 loss_uniform =  1.629493211383944  loss_variational =  1.65377553291135\n",
      "epoch =  1 batch =  309 / 1000 loss_uniform =  1.629517354625715  loss_variational =  1.6538388061677751\n",
      "epoch =  1 batch =  310 / 1000 loss_uniform =  1.629487081496947  loss_variational =  1.6537791379036442\n",
      "epoch =  1 batch =  311 / 1000 loss_uniform =  1.629510574018841  loss_variational =  1.653764276642508\n",
      "epoch =  1 batch =  312 / 1000 loss_uniform =  1.629516542339937  loss_variational =  1.653746063128496\n",
      "epoch =  1 batch =  313 / 1000 loss_uniform =  1.62950887466772  loss_variational =  1.653759488282493\n",
      "epoch =  1 batch =  314 / 1000 loss_uniform =  1.6295109592425605  loss_variational =  1.6537101124502291\n",
      "epoch =  1 batch =  315 / 1000 loss_uniform =  1.6295216034329134  loss_variational =  1.6536839916592552\n",
      "epoch =  1 batch =  316 / 1000 loss_uniform =  1.6295093652568293  loss_variational =  1.6536895527115352\n",
      "epoch =  1 batch =  317 / 1000 loss_uniform =  1.629522202518837  loss_variational =  1.6536959466121925\n",
      "epoch =  1 batch =  318 / 1000 loss_uniform =  1.6294887332046564  loss_variational =  1.6537109182315803\n",
      "epoch =  1 batch =  319 / 1000 loss_uniform =  1.629505462781016  loss_variational =  1.653680954233606\n",
      "epoch =  1 batch =  320 / 1000 loss_uniform =  1.6294713739305742  loss_variational =  1.653700240701437\n",
      "epoch =  1 batch =  321 / 1000 loss_uniform =  1.6295055741461646  loss_variational =  1.653722248344778\n",
      "epoch =  1 batch =  322 / 1000 loss_uniform =  1.6295293721353052  loss_variational =  1.6537002295440768\n",
      "epoch =  1 batch =  323 / 1000 loss_uniform =  1.6295302962371077  loss_variational =  1.6537028373948561\n",
      "epoch =  1 batch =  324 / 1000 loss_uniform =  1.629518037224994  loss_variational =  1.6536891158716178\n",
      "epoch =  1 batch =  325 / 1000 loss_uniform =  1.6294994552318873  loss_variational =  1.65365164573376\n",
      "epoch =  1 batch =  326 / 1000 loss_uniform =  1.62948633410448  loss_variational =  1.6536587948448087\n",
      "epoch =  1 batch =  327 / 1000 loss_uniform =  1.629517776156785  loss_variational =  1.6536746444323012\n",
      "epoch =  1 batch =  328 / 1000 loss_uniform =  1.629525187175449  loss_variational =  1.6536397428774252\n",
      "epoch =  1 batch =  329 / 1000 loss_uniform =  1.629515433746269  loss_variational =  1.6536651237395035\n",
      "epoch =  1 batch =  330 / 1000 loss_uniform =  1.6294679782607346  loss_variational =  1.6536506746754502\n",
      "epoch =  1 batch =  331 / 1000 loss_uniform =  1.6294594934699766  loss_variational =  1.653642372062199\n",
      "epoch =  1 batch =  332 / 1000 loss_uniform =  1.6294697817549655  loss_variational =  1.6535786971988449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  333 / 1000 loss_uniform =  1.6294577397383734  loss_variational =  1.6536214888632834\n",
      "epoch =  1 batch =  334 / 1000 loss_uniform =  1.629475187041803  loss_variational =  1.6536187700882643\n",
      "epoch =  1 batch =  335 / 1000 loss_uniform =  1.6294726122671106  loss_variational =  1.6536121364849716\n",
      "epoch =  1 batch =  336 / 1000 loss_uniform =  1.6294883737961459  loss_variational =  1.6536008027337847\n",
      "epoch =  1 batch =  337 / 1000 loss_uniform =  1.6295248238198488  loss_variational =  1.6536014688474843\n",
      "epoch =  1 batch =  338 / 1000 loss_uniform =  1.6294850460171  loss_variational =  1.6535276650677067\n",
      "epoch =  1 batch =  339 / 1000 loss_uniform =  1.6294826803657516  loss_variational =  1.6535806961819135\n",
      "epoch =  1 batch =  340 / 1000 loss_uniform =  1.6294774458688854  loss_variational =  1.6535287888611063\n",
      "epoch =  1 batch =  341 / 1000 loss_uniform =  1.629498542928277  loss_variational =  1.6535185425162664\n",
      "epoch =  1 batch =  342 / 1000 loss_uniform =  1.6295138032812828  loss_variational =  1.653483581821821\n",
      "epoch =  1 batch =  343 / 1000 loss_uniform =  1.6295298473480497  loss_variational =  1.6534910365374373\n",
      "epoch =  1 batch =  344 / 1000 loss_uniform =  1.6295106681280365  loss_variational =  1.6534713808187218\n",
      "epoch =  1 batch =  345 / 1000 loss_uniform =  1.6295073916946639  loss_variational =  1.6534773709117503\n",
      "epoch =  1 batch =  346 / 1000 loss_uniform =  1.629528338854024  loss_variational =  1.653445420926706\n",
      "epoch =  1 batch =  347 / 1000 loss_uniform =  1.6295167369182935  loss_variational =  1.6534603507786731\n",
      "epoch =  1 batch =  348 / 1000 loss_uniform =  1.6295510414002963  loss_variational =  1.6534762300294021\n",
      "epoch =  1 batch =  349 / 1000 loss_uniform =  1.6295002070402353  loss_variational =  1.6534415766981065\n",
      "epoch =  1 batch =  350 / 1000 loss_uniform =  1.6294969810758324  loss_variational =  1.6534097511427743\n",
      "epoch =  1 batch =  351 / 1000 loss_uniform =  1.629510557549632  loss_variational =  1.6534111051477938\n",
      "epoch =  1 batch =  352 / 1000 loss_uniform =  1.6295763098380789  loss_variational =  1.653433670713143\n",
      "epoch =  1 batch =  353 / 1000 loss_uniform =  1.629588657668225  loss_variational =  1.6533929362850892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f902630ee707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss_uniform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss_variational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer_uniform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 10000\n",
    "n_batches = m.ceil(x_data.shape[0]/batch_size)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    permutation = torch.randperm(x_data.shape[0], device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss_uniform = 0\n",
    "    cum_loss_variational = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, x_data.shape[0]-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        batch_x = x_data[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer_uniform.zero_grad()\n",
    "        optimizer_variational.zero_grad()\n",
    "\n",
    "        loss_uniform = -flow_uniform.log_prob(inputs=batch_x).mean()\n",
    "        loss_variational = -flow_variational.log_prob(inputs=batch_x).mean()\n",
    "\n",
    "        loss_uniform.backward()\n",
    "        loss_variational.backward()\n",
    "\n",
    "        optimizer_uniform.step()\n",
    "        optimizer_variational.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss_uniform = (cum_loss_uniform*batch + loss_uniform.item())/(batch+1)\n",
    "        cum_loss_variational = (cum_loss_variational*batch + loss_variational.item())/(batch+1)\n",
    "\n",
    "        print(\"epoch = \", epoch, \"batch = \",batch+1, \"/\", n_batches, \"loss_uniform = \", cum_loss_uniform, \" loss_variational = \", cum_loss_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sample = 100000\n",
    "with torch.no_grad():\n",
    "    x_uniform = flow_uniform.sample(n_sample).cpu().numpy()\n",
    "    x_variational = flow_variational.sample(n_sample).cpu().numpy()\n",
    "x_data_plot = x_data.cpu()[:n_sample,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.5, drop_indices.shape[0]+0.5, drop_indices.shape[0]+2)\n",
    "plt.hist(np.sum(x_data_plot == 0, axis=1), histtype='stepfilled', edgecolor=\"black\", facecolor=\"lightgray\", bins = bins)\n",
    "plt.hist(np.sum(x_uniform == 0, axis=1), edgecolor=\"red\", histtype=\"step\", bins = bins)\n",
    "plt.hist(np.sum(x_variational == 0, axis=1), edgecolor=\"green\", histtype=\"step\", bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, drop_indices.shape[0], 20)\n",
    "plt.hist(np.sum(x_data_plot, axis=1), histtype='stepfilled', edgecolor=\"black\", facecolor=\"lightgray\", bins = bins)\n",
    "plt.hist(np.sum(x_uniform, axis=1), edgecolor=\"red\", histtype=\"step\", bins = bins)\n",
    "plt.hist(np.sum(x_variational, axis=1), edgecolor=\"green\", histtype=\"step\", bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 20)\n",
    "plt.hist(x_data_plot[:,2], histtype='stepfilled', edgecolor=\"black\", facecolor=\"lightgray\", bins = bins)\n",
    "plt.hist(x_uniform[:,2], edgecolor=\"red\", histtype=\"step\", bins = bins)\n",
    "plt.hist(x_variational[:,2], edgecolor=\"green\", histtype=\"step\", bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
