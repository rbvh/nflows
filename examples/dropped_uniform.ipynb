{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.4 64-bit",
   "display_name": "Python 3.8.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.transforms.dropout import UniformStochasticDropout\n",
    "from nflows.transforms.dropout import VariationalStochasticDropout\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works with any size x\n",
    "def p(x, n_probs):\n",
    "    sums = torch.sum(x, axis=1)\n",
    "    probs = torch.cos(torch.ger(sums, torch.arange(1, n_probs+1, dtype=torch.float32)))**2\n",
    "    norm = torch.sum(probs, axis=1)\n",
    "\n",
    "    for i in range(n_probs):\n",
    "        probs[:,i] /= norm\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n, drop_indices):\n",
    "    n_probs = torch.max(drop_indices) + 1\n",
    "    x = torch.rand(n, drop_indices.shape[0])\n",
    "    probs = p(x, n_probs)\n",
    "\n",
    "    # Pick a prob\n",
    "    probs_cumsum = torch.cumsum(probs, axis=1)\n",
    "\n",
    "    # Tensor with bools that are true when r passes the cumprob\n",
    "    larger_than_cumprob = torch.rand(n,1) < probs_cumsum\n",
    "    # Do the arange trick to find first nonzero\n",
    "    # This is the HIGHEST LABEL FROM DROP_INDICES THAT IS KEPT\n",
    "    selected_index = torch.argmax(larger_than_cumprob*torch.arange(n_probs, 0, -1), axis=1)\n",
    "\n",
    "    '''\n",
    "    print(\"The index of the selected probability\")\n",
    "    print(\"This is also the highest label in drop_indices that is kept\")\n",
    "    print(selected_index)\n",
    "    ''' \n",
    "    \n",
    "    # Find the index of the first true\n",
    "    drop_mask = drop_indices > selected_index[:,None]\n",
    "    x[drop_mask] = 0\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indices = torch.tensor([0,0,1,1,1,2,3,3,4])\n",
    "n_data = int(1e6)\n",
    "x_data = generate(n_data, drop_indices).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "drop_indices.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "base_dist_uniform = BoxUniform(torch.zeros(drop_indices.shape[0]), torch.ones(drop_indices.shape[0]))\n",
    "#base_dist_variational = BoxUniform(drop_indices.shape[0], drop_indices.shape[0])\n",
    "\n",
    "transforms_uniform = []\n",
    "#transforms_variational = []\n",
    "\n",
    "transforms_uniform.append(UniformStochasticDropout(drop_indices))\n",
    "#transforms_variational.append(VariationalStochasticDropout(drop_indices))\n",
    "\n",
    "for _ in range(num_layers):\n",
    "    transforms_uniform.append(RandomPermutation(features=drop_indices.shape[0]))\n",
    "    transforms_uniform.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=drop_indices.shape[0], \n",
    "        hidden_features=25,\n",
    "        num_bins=10,\n",
    "        num_blocks=4,\n",
    "    ))\n",
    "\n",
    "    #transforms_variational.append(RandomPermutation(features=drop_indices.shape[0]))\n",
    "    #transforms_variational.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "    #    features=drop_indices.shape[0], \n",
    "    #    hidden_features=25,\n",
    "    #    num_bins=10,\n",
    "    #    num_blocks=4,\n",
    "    #))\n",
    "\n",
    "transform_uniform = CompositeTransform(transforms_uniform)\n",
    "#transform_variational = CompositeTransform(transforms_variational)\n",
    "\n",
    "flow_uniform = Flow(transform_uniform, base_dist_uniform).to(device)\n",
    "#flow_variational = Flow(transform_variational, base_dist_variational).to(device)\n",
    "\n",
    "optimizer_uniform = optim.Adam(flow_uniform.parameters())\n",
    "#optimizer_variational = optim.Adam(flow_variational.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "uniform =  1.7655362319069496\n",
      "epoch =  0 batch =  708 / 1000 loss_uniform =  1.7653532401990075\n",
      "epoch =  0 batch =  709 / 1000 loss_uniform =  1.7651719502232468\n",
      "epoch =  0 batch =  710 / 1000 loss_uniform =  1.7650157156124915\n",
      "epoch =  0 batch =  711 / 1000 loss_uniform =  1.7648237995625207\n",
      "epoch =  0 batch =  712 / 1000 loss_uniform =  1.7646351592259455\n",
      "epoch =  0 batch =  713 / 1000 loss_uniform =  1.7644597338760712\n",
      "epoch =  0 batch =  714 / 1000 loss_uniform =  1.7642669632655226\n",
      "epoch =  0 batch =  715 / 1000 loss_uniform =  1.7640994090300333\n",
      "epoch =  0 batch =  716 / 1000 loss_uniform =  1.7639266527231838\n",
      "epoch =  0 batch =  717 / 1000 loss_uniform =  1.7637540145232913\n",
      "epoch =  0 batch =  718 / 1000 loss_uniform =  1.7635827881380037\n",
      "epoch =  0 batch =  719 / 1000 loss_uniform =  1.7634065749748022\n",
      "epoch =  0 batch =  720 / 1000 loss_uniform =  1.7632252130243506\n",
      "epoch =  0 batch =  721 / 1000 loss_uniform =  1.763056726958318\n",
      "epoch =  0 batch =  722 / 1000 loss_uniform =  1.7628919361700965\n",
      "epoch =  0 batch =  723 / 1000 loss_uniform =  1.762701681870477\n",
      "epoch =  0 batch =  724 / 1000 loss_uniform =  1.7625168530651212\n",
      "epoch =  0 batch =  725 / 1000 loss_uniform =  1.7623582959997237\n",
      "epoch =  0 batch =  726 / 1000 loss_uniform =  1.7622146099066924\n",
      "epoch =  0 batch =  727 / 1000 loss_uniform =  1.7620323994792633\n",
      "epoch =  0 batch =  728 / 1000 loss_uniform =  1.7618682931412701\n",
      "epoch =  0 batch =  729 / 1000 loss_uniform =  1.7616859883764964\n",
      "epoch =  0 batch =  730 / 1000 loss_uniform =  1.761536882348256\n",
      "epoch =  0 batch =  731 / 1000 loss_uniform =  1.7613698222894831\n",
      "epoch =  0 batch =  732 / 1000 loss_uniform =  1.7611862723944611\n",
      "epoch =  0 batch =  733 / 1000 loss_uniform =  1.7610162895015278\n",
      "epoch =  0 batch =  734 / 1000 loss_uniform =  1.7608611713638092\n",
      "epoch =  0 batch =  735 / 1000 loss_uniform =  1.7606872599141121\n",
      "epoch =  0 batch =  736 / 1000 loss_uniform =  1.7605359653091943\n",
      "epoch =  0 batch =  737 / 1000 loss_uniform =  1.7603781849267195\n",
      "epoch =  0 batch =  738 / 1000 loss_uniform =  1.760213226806826\n",
      "epoch =  0 batch =  739 / 1000 loss_uniform =  1.760054810282664\n",
      "epoch =  0 batch =  740 / 1000 loss_uniform =  1.7598932635139768\n",
      "epoch =  0 batch =  741 / 1000 loss_uniform =  1.759717692569521\n",
      "epoch =  0 batch =  742 / 1000 loss_uniform =  1.759545859461524\n",
      "epoch =  0 batch =  743 / 1000 loss_uniform =  1.7593867993771943\n",
      "epoch =  0 batch =  744 / 1000 loss_uniform =  1.759207674252089\n",
      "epoch =  0 batch =  745 / 1000 loss_uniform =  1.7590440638113336\n",
      "epoch =  0 batch =  746 / 1000 loss_uniform =  1.758883985213875\n",
      "epoch =  0 batch =  747 / 1000 loss_uniform =  1.7587202086825282\n",
      "epoch =  0 batch =  748 / 1000 loss_uniform =  1.7585724434431855\n",
      "epoch =  0 batch =  749 / 1000 loss_uniform =  1.7584278055122278\n",
      "epoch =  0 batch =  750 / 1000 loss_uniform =  1.758266040960947\n",
      "epoch =  0 batch =  751 / 1000 loss_uniform =  1.7580875234502287\n",
      "epoch =  0 batch =  752 / 1000 loss_uniform =  1.7579224198422527\n",
      "epoch =  0 batch =  753 / 1000 loss_uniform =  1.7577719835646117\n",
      "epoch =  0 batch =  754 / 1000 loss_uniform =  1.7576180334432683\n",
      "epoch =  0 batch =  755 / 1000 loss_uniform =  1.7574828512621237\n",
      "epoch =  0 batch =  756 / 1000 loss_uniform =  1.7573271598765452\n",
      "epoch =  0 batch =  757 / 1000 loss_uniform =  1.7571645981411947\n",
      "epoch =  0 batch =  758 / 1000 loss_uniform =  1.7570064857326895\n",
      "epoch =  0 batch =  759 / 1000 loss_uniform =  1.756868780837228\n",
      "epoch =  0 batch =  760 / 1000 loss_uniform =  1.7566985843997247\n",
      "epoch =  0 batch =  761 / 1000 loss_uniform =  1.7565442989439588\n",
      "epoch =  0 batch =  762 / 1000 loss_uniform =  1.756381938463746\n",
      "epoch =  0 batch =  763 / 1000 loss_uniform =  1.7562046583795603\n",
      "epoch =  0 batch =  764 / 1000 loss_uniform =  1.7560334898414407\n",
      "epoch =  0 batch =  765 / 1000 loss_uniform =  1.7558714752882907\n",
      "epoch =  0 batch =  766 / 1000 loss_uniform =  1.7557304711628203\n",
      "epoch =  0 batch =  767 / 1000 loss_uniform =  1.7555781609076404\n",
      "epoch =  0 batch =  768 / 1000 loss_uniform =  1.7554198368452483\n",
      "epoch =  0 batch =  769 / 1000 loss_uniform =  1.7552515144310934\n",
      "epoch =  0 batch =  770 / 1000 loss_uniform =  1.7550967694877024\n",
      "epoch =  0 batch =  771 / 1000 loss_uniform =  1.7549364099861269\n",
      "epoch =  0 batch =  772 / 1000 loss_uniform =  1.754785008226651\n",
      "epoch =  0 batch =  773 / 1000 loss_uniform =  1.7546420367229796\n",
      "epoch =  0 batch =  774 / 1000 loss_uniform =  1.754477037169828\n",
      "epoch =  0 batch =  775 / 1000 loss_uniform =  1.7543138207158728\n",
      "epoch =  0 batch =  776 / 1000 loss_uniform =  1.7541491873178279\n",
      "epoch =  0 batch =  777 / 1000 loss_uniform =  1.753985377198787\n",
      "epoch =  0 batch =  778 / 1000 loss_uniform =  1.753832080523581\n",
      "epoch =  0 batch =  779 / 1000 loss_uniform =  1.7536574543976196\n",
      "epoch =  0 batch =  780 / 1000 loss_uniform =  1.7535061014004236\n",
      "epoch =  0 batch =  781 / 1000 loss_uniform =  1.7533880108907793\n",
      "epoch =  0 batch =  782 / 1000 loss_uniform =  1.753234003815809\n",
      "epoch =  0 batch =  783 / 1000 loss_uniform =  1.753082822261337\n",
      "epoch =  0 batch =  784 / 1000 loss_uniform =  1.7529277605365727\n",
      "epoch =  0 batch =  785 / 1000 loss_uniform =  1.7527856843486707\n",
      "epoch =  0 batch =  786 / 1000 loss_uniform =  1.752621843311319\n",
      "epoch =  0 batch =  787 / 1000 loss_uniform =  1.7524733549454912\n",
      "epoch =  0 batch =  788 / 1000 loss_uniform =  1.75232546765187\n",
      "epoch =  0 batch =  789 / 1000 loss_uniform =  1.752188435978762\n",
      "epoch =  0 batch =  790 / 1000 loss_uniform =  1.7520353431943092\n",
      "epoch =  0 batch =  791 / 1000 loss_uniform =  1.751877507578708\n",
      "epoch =  0 batch =  792 / 1000 loss_uniform =  1.7517338538109648\n",
      "epoch =  0 batch =  793 / 1000 loss_uniform =  1.7515832944896448\n",
      "epoch =  0 batch =  794 / 1000 loss_uniform =  1.7514378333872447\n",
      "epoch =  0 batch =  795 / 1000 loss_uniform =  1.7512922793814216\n",
      "epoch =  0 batch =  796 / 1000 loss_uniform =  1.7511363902583188\n",
      "epoch =  0 batch =  797 / 1000 loss_uniform =  1.7509949367348487\n",
      "epoch =  0 batch =  798 / 1000 loss_uniform =  1.750863255265362\n",
      "epoch =  0 batch =  799 / 1000 loss_uniform =  1.750716784719531\n",
      "epoch =  0 batch =  800 / 1000 loss_uniform =  1.7505792595446104\n",
      "epoch =  0 batch =  801 / 1000 loss_uniform =  1.750442090998874\n",
      "epoch =  0 batch =  802 / 1000 loss_uniform =  1.750296332889661\n",
      "epoch =  0 batch =  803 / 1000 loss_uniform =  1.7501561463547222\n",
      "epoch =  0 batch =  804 / 1000 loss_uniform =  1.7500130574205022\n",
      "epoch =  0 batch =  805 / 1000 loss_uniform =  1.7498639670958425\n",
      "epoch =  0 batch =  806 / 1000 loss_uniform =  1.7497253224216673\n",
      "epoch =  0 batch =  807 / 1000 loss_uniform =  1.7495751339559065\n",
      "epoch =  0 batch =  808 / 1000 loss_uniform =  1.749434347199921\n",
      "epoch =  0 batch =  809 / 1000 loss_uniform =  1.749296831848889\n",
      "epoch =  0 batch =  810 / 1000 loss_uniform =  1.7491452170007018\n",
      "epoch =  0 batch =  811 / 1000 loss_uniform =  1.749007574873993\n",
      "epoch =  0 batch =  812 / 1000 loss_uniform =  1.7488640050582693\n",
      "epoch =  0 batch =  813 / 1000 loss_uniform =  1.7486988297247794\n",
      "epoch =  0 batch =  814 / 1000 loss_uniform =  1.7485668199361097\n",
      "epoch =  0 batch =  815 / 1000 loss_uniform =  1.7484376661616594\n",
      "epoch =  0 batch =  816 / 1000 loss_uniform =  1.748305847247441\n",
      "epoch =  0 batch =  817 / 1000 loss_uniform =  1.7481727522764818\n",
      "epoch =  0 batch =  818 / 1000 loss_uniform =  1.7480159212441193\n",
      "epoch =  0 batch =  819 / 1000 loss_uniform =  1.747878749728639\n",
      "epoch =  0 batch =  820 / 1000 loss_uniform =  1.7477321982383722\n",
      "epoch =  0 batch =  821 / 1000 loss_uniform =  1.7475929014865716\n",
      "epoch =  0 batch =  822 / 1000 loss_uniform =  1.7474509152762785\n",
      "epoch =  0 batch =  823 / 1000 loss_uniform =  1.747311538798261\n",
      "epoch =  0 batch =  824 / 1000 loss_uniform =  1.747197418536954\n",
      "epoch =  0 batch =  825 / 1000 loss_uniform =  1.7470842128811455\n",
      "epoch =  0 batch =  826 / 1000 loss_uniform =  1.746953050103083\n",
      "epoch =  0 batch =  827 / 1000 loss_uniform =  1.7468228167172926\n",
      "epoch =  0 batch =  828 / 1000 loss_uniform =  1.7466762140753183\n",
      "epoch =  0 batch =  829 / 1000 loss_uniform =  1.746537933591191\n",
      "epoch =  0 batch =  830 / 1000 loss_uniform =  1.7464138138725092\n",
      "epoch =  0 batch =  831 / 1000 loss_uniform =  1.746284207282083\n",
      "epoch =  0 batch =  832 / 1000 loss_uniform =  1.7461622873177889\n",
      "epoch =  0 batch =  833 / 1000 loss_uniform =  1.7460383993952495\n",
      "epoch =  0 batch =  834 / 1000 loss_uniform =  1.7459096947162267\n",
      "epoch =  0 batch =  835 / 1000 loss_uniform =  1.7457802993808673\n",
      "epoch =  0 batch =  836 / 1000 loss_uniform =  1.7456601483114593\n",
      "epoch =  0 batch =  837 / 1000 loss_uniform =  1.7455148256807766\n",
      "epoch =  0 batch =  838 / 1000 loss_uniform =  1.7453942132451363\n",
      "epoch =  0 batch =  839 / 1000 loss_uniform =  1.7452615789349792\n",
      "epoch =  0 batch =  840 / 1000 loss_uniform =  1.7451282007353641\n",
      "epoch =  0 batch =  841 / 1000 loss_uniform =  1.7449964946855683\n",
      "epoch =  0 batch =  842 / 1000 loss_uniform =  1.7448841027579223\n",
      "epoch =  0 batch =  843 / 1000 loss_uniform =  1.7447517497966576\n",
      "epoch =  0 batch =  844 / 1000 loss_uniform =  1.7446160734547254\n",
      "epoch =  0 batch =  845 / 1000 loss_uniform =  1.7444943731353122\n",
      "epoch =  0 batch =  846 / 1000 loss_uniform =  1.7443538799917158\n",
      "epoch =  0 batch =  847 / 1000 loss_uniform =  1.7442071820656546\n",
      "epoch =  0 batch =  848 / 1000 loss_uniform =  1.7440882744091857\n",
      "epoch =  0 batch =  849 / 1000 loss_uniform =  1.7439519303145476\n",
      "epoch =  0 batch =  850 / 1000 loss_uniform =  1.7438321866708637\n",
      "epoch =  0 batch =  851 / 1000 loss_uniform =  1.7437141029871164\n",
      "epoch =  0 batch =  852 / 1000 loss_uniform =  1.743583631207685\n",
      "epoch =  0 batch =  853 / 1000 loss_uniform =  1.743438367267845\n",
      "epoch =  0 batch =  854 / 1000 loss_uniform =  1.7433000086900496\n",
      "epoch =  0 batch =  855 / 1000 loss_uniform =  1.7431674661692118\n",
      "epoch =  0 batch =  856 / 1000 loss_uniform =  1.7430394516091474\n",
      "epoch =  0 batch =  857 / 1000 loss_uniform =  1.7429152295914938\n",
      "epoch =  0 batch =  858 / 1000 loss_uniform =  1.7427762855182989\n",
      "epoch =  0 batch =  859 / 1000 loss_uniform =  1.7426499707041014\n",
      "epoch =  0 batch =  860 / 1000 loss_uniform =  1.7425326444381886\n",
      "epoch =  0 batch =  861 / 1000 loss_uniform =  1.742412060118441\n",
      "epoch =  0 batch =  862 / 1000 loss_uniform =  1.7422822524389363\n",
      "epoch =  0 batch =  863 / 1000 loss_uniform =  1.742158950687421\n",
      "epoch =  0 batch =  864 / 1000 loss_uniform =  1.7420337320201922\n",
      "epoch =  0 batch =  865 / 1000 loss_uniform =  1.7419080593682432\n",
      "epoch =  0 batch =  866 / 1000 loss_uniform =  1.74179532704122\n",
      "epoch =  0 batch =  867 / 1000 loss_uniform =  1.7416730742416024\n",
      "epoch =  0 batch =  868 / 1000 loss_uniform =  1.741550079688498\n",
      "epoch =  0 batch =  869 / 1000 loss_uniform =  1.7414381276340283\n",
      "epoch =  0 batch =  870 / 1000 loss_uniform =  1.7412949031796943\n",
      "epoch =  0 batch =  871 / 1000 loss_uniform =  1.7411763101439794\n",
      "epoch =  0 batch =  872 / 1000 loss_uniform =  1.7410576585509356\n",
      "epoch =  0 batch =  873 / 1000 loss_uniform =  1.740939463400212\n",
      "epoch =  0 batch =  874 / 1000 loss_uniform =  1.7408151417902455\n",
      "epoch =  0 batch =  875 / 1000 loss_uniform =  1.740697464397975\n",
      "epoch =  0 batch =  876 / 1000 loss_uniform =  1.7405851962359524\n",
      "epoch =  0 batch =  877 / 1000 loss_uniform =  1.7404658419240426\n",
      "epoch =  0 batch =  878 / 1000 loss_uniform =  1.7403494882692232\n",
      "epoch =  0 batch =  879 / 1000 loss_uniform =  1.7402355909618767\n",
      "epoch =  0 batch =  880 / 1000 loss_uniform =  1.740101280537518\n",
      "epoch =  0 batch =  881 / 1000 loss_uniform =  1.7399783729830336\n",
      "epoch =  0 batch =  882 / 1000 loss_uniform =  1.73986081849961\n",
      "epoch =  0 batch =  883 / 1000 loss_uniform =  1.7397483052645772\n",
      "epoch =  0 batch =  884 / 1000 loss_uniform =  1.7396204015787904\n",
      "epoch =  0 batch =  885 / 1000 loss_uniform =  1.7395138662413683\n",
      "epoch =  0 batch =  886 / 1000 loss_uniform =  1.7393976308691308\n",
      "epoch =  0 batch =  887 / 1000 loss_uniform =  1.7392837709611804\n",
      "epoch =  0 batch =  888 / 1000 loss_uniform =  1.7391821448061913\n",
      "epoch =  0 batch =  889 / 1000 loss_uniform =  1.7390801433234966\n",
      "epoch =  0 batch =  890 / 1000 loss_uniform =  1.73896216930968\n",
      "epoch =  0 batch =  891 / 1000 loss_uniform =  1.7388394252218375\n",
      "epoch =  0 batch =  892 / 1000 loss_uniform =  1.7387306455004905\n",
      "epoch =  0 batch =  893 / 1000 loss_uniform =  1.7386081948926435\n",
      "epoch =  0 batch =  894 / 1000 loss_uniform =  1.7384875352750684\n",
      "epoch =  0 batch =  895 / 1000 loss_uniform =  1.7383685750002296\n",
      "epoch =  0 batch =  896 / 1000 loss_uniform =  1.73824953553932\n",
      "epoch =  0 batch =  897 / 1000 loss_uniform =  1.7381402941186022\n",
      "epoch =  0 batch =  898 / 1000 loss_uniform =  1.7380430162085716\n",
      "epoch =  0 batch =  899 / 1000 loss_uniform =  1.7379389428455911\n",
      "epoch =  0 batch =  900 / 1000 loss_uniform =  1.737830537822511\n",
      "epoch =  0 batch =  901 / 1000 loss_uniform =  1.7377057566362264\n",
      "epoch =  0 batch =  902 / 1000 loss_uniform =  1.7375795576894886\n",
      "epoch =  0 batch =  903 / 1000 loss_uniform =  1.7374687013964052\n",
      "epoch =  0 batch =  904 / 1000 loss_uniform =  1.7373532830877636\n",
      "epoch =  0 batch =  905 / 1000 loss_uniform =  1.7372362875806688\n",
      "epoch =  0 batch =  906 / 1000 loss_uniform =  1.7371431749651232\n",
      "epoch =  0 batch =  907 / 1000 loss_uniform =  1.737021192300411\n",
      "epoch =  0 batch =  908 / 1000 loss_uniform =  1.7369053487210542\n",
      "epoch =  0 batch =  909 / 1000 loss_uniform =  1.7367994356470136\n",
      "epoch =  0 batch =  910 / 1000 loss_uniform =  1.7366715690591827\n",
      "epoch =  0 batch =  911 / 1000 loss_uniform =  1.7365650513038673\n",
      "epoch =  0 batch =  912 / 1000 loss_uniform =  1.736461338243986\n",
      "epoch =  0 batch =  913 / 1000 loss_uniform =  1.7363453935036126\n",
      "epoch =  0 batch =  914 / 1000 loss_uniform =  1.7362258778620074\n",
      "epoch =  0 batch =  915 / 1000 loss_uniform =  1.7361196394175122\n",
      "epoch =  0 batch =  916 / 1000 loss_uniform =  1.7360143229430414\n",
      "epoch =  0 batch =  917 / 1000 loss_uniform =  1.7359354441402517\n",
      "epoch =  0 batch =  918 / 1000 loss_uniform =  1.7358319229549828\n",
      "epoch =  0 batch =  919 / 1000 loss_uniform =  1.7357193449506039\n",
      "epoch =  0 batch =  920 / 1000 loss_uniform =  1.7356075981388916\n",
      "epoch =  0 batch =  921 / 1000 loss_uniform =  1.735497580159629\n",
      "epoch =  0 batch =  922 / 1000 loss_uniform =  1.7354054947478648\n",
      "epoch =  0 batch =  923 / 1000 loss_uniform =  1.7352993142178614\n",
      "epoch =  0 batch =  924 / 1000 loss_uniform =  1.7351798557099838\n",
      "epoch =  0 batch =  925 / 1000 loss_uniform =  1.735070940868274\n",
      "epoch =  0 batch =  926 / 1000 loss_uniform =  1.734959188084365\n",
      "epoch =  0 batch =  927 / 1000 loss_uniform =  1.7348417110556276\n",
      "epoch =  0 batch =  928 / 1000 loss_uniform =  1.7347366279312244\n",
      "epoch =  0 batch =  929 / 1000 loss_uniform =  1.734616323872454\n",
      "epoch =  0 batch =  930 / 1000 loss_uniform =  1.734494224286848\n",
      "epoch =  0 batch =  931 / 1000 loss_uniform =  1.7343790075320558\n",
      "epoch =  0 batch =  932 / 1000 loss_uniform =  1.7342637058491355\n",
      "epoch =  0 batch =  933 / 1000 loss_uniform =  1.7341661513298905\n",
      "epoch =  0 batch =  934 / 1000 loss_uniform =  1.7340479708841061\n",
      "epoch =  0 batch =  935 / 1000 loss_uniform =  1.7339464479589202\n",
      "epoch =  0 batch =  936 / 1000 loss_uniform =  1.7338295566220563\n",
      "epoch =  0 batch =  937 / 1000 loss_uniform =  1.7337103201714494\n",
      "epoch =  0 batch =  938 / 1000 loss_uniform =  1.7335983270775275\n",
      "epoch =  0 batch =  939 / 1000 loss_uniform =  1.7334807256794074\n",
      "epoch =  0 batch =  940 / 1000 loss_uniform =  1.7333810245737111\n",
      "epoch =  0 batch =  941 / 1000 loss_uniform =  1.7332783855109863\n",
      "epoch =  0 batch =  942 / 1000 loss_uniform =  1.733169452273415\n",
      "epoch =  0 batch =  943 / 1000 loss_uniform =  1.7330469095315049\n",
      "epoch =  0 batch =  944 / 1000 loss_uniform =  1.7329424944216918\n",
      "epoch =  0 batch =  945 / 1000 loss_uniform =  1.732842760615878\n",
      "epoch =  0 batch =  946 / 1000 loss_uniform =  1.7327348042996182\n",
      "epoch =  0 batch =  947 / 1000 loss_uniform =  1.7326290373313762\n",
      "epoch =  0 batch =  948 / 1000 loss_uniform =  1.7325459530081926\n",
      "epoch =  0 batch =  949 / 1000 loss_uniform =  1.7324374412962704\n",
      "epoch =  0 batch =  950 / 1000 loss_uniform =  1.7323204015430647\n",
      "epoch =  0 batch =  951 / 1000 loss_uniform =  1.732214353939461\n",
      "epoch =  0 batch =  952 / 1000 loss_uniform =  1.7321060095765004\n",
      "epoch =  0 batch =  953 / 1000 loss_uniform =  1.7319969217774747\n",
      "epoch =  0 batch =  954 / 1000 loss_uniform =  1.7318898295706417\n",
      "epoch =  0 batch =  955 / 1000 loss_uniform =  1.7317893768480306\n",
      "epoch =  0 batch =  956 / 1000 loss_uniform =  1.7316848535916791\n",
      "epoch =  0 batch =  957 / 1000 loss_uniform =  1.7315754434531754\n",
      "epoch =  0 batch =  958 / 1000 loss_uniform =  1.7314609352631454\n",
      "epoch =  0 batch =  959 / 1000 loss_uniform =  1.7313664068892298\n",
      "epoch =  0 batch =  960 / 1000 loss_uniform =  1.7312789101153607\n",
      "epoch =  0 batch =  961 / 1000 loss_uniform =  1.7311857958614014\n",
      "epoch =  0 batch =  962 / 1000 loss_uniform =  1.7310761794478873\n",
      "epoch =  0 batch =  963 / 1000 loss_uniform =  1.7309631496698805\n",
      "epoch =  0 batch =  964 / 1000 loss_uniform =  1.7308724391509878\n",
      "epoch =  0 batch =  965 / 1000 loss_uniform =  1.7307696432647306\n",
      "epoch =  0 batch =  966 / 1000 loss_uniform =  1.7306716648194602\n",
      "epoch =  0 batch =  967 / 1000 loss_uniform =  1.7305669367868128\n",
      "epoch =  0 batch =  968 / 1000 loss_uniform =  1.7304648014385833\n",
      "epoch =  0 batch =  969 / 1000 loss_uniform =  1.7303576247979977\n",
      "epoch =  0 batch =  970 / 1000 loss_uniform =  1.7302617758819732\n",
      "epoch =  0 batch =  971 / 1000 loss_uniform =  1.730155150873162\n",
      "epoch =  0 batch =  972 / 1000 loss_uniform =  1.7300582826137538\n",
      "epoch =  0 batch =  973 / 1000 loss_uniform =  1.7299538392569762\n",
      "epoch =  0 batch =  974 / 1000 loss_uniform =  1.729843160577378\n",
      "epoch =  0 batch =  975 / 1000 loss_uniform =  1.729754752256931\n",
      "epoch =  0 batch =  976 / 1000 loss_uniform =  1.7296647814209338\n",
      "epoch =  0 batch =  977 / 1000 loss_uniform =  1.7295665082082285\n",
      "epoch =  0 batch =  978 / 1000 loss_uniform =  1.7294830820068012\n",
      "epoch =  0 batch =  979 / 1000 loss_uniform =  1.7294022219904348\n",
      "epoch =  0 batch =  980 / 1000 loss_uniform =  1.7293161431137392\n",
      "epoch =  0 batch =  981 / 1000 loss_uniform =  1.7292285938875387\n",
      "epoch =  0 batch =  982 / 1000 loss_uniform =  1.729129362251996\n",
      "epoch =  0 batch =  983 / 1000 loss_uniform =  1.72903982426361\n",
      "epoch =  0 batch =  984 / 1000 loss_uniform =  1.7289338171239785\n",
      "epoch =  0 batch =  985 / 1000 loss_uniform =  1.7288357968257764\n",
      "epoch =  0 batch =  986 / 1000 loss_uniform =  1.7287468501568803\n",
      "epoch =  0 batch =  987 / 1000 loss_uniform =  1.7286522900562997\n",
      "epoch =  0 batch =  988 / 1000 loss_uniform =  1.7285573335311668\n",
      "epoch =  0 batch =  989 / 1000 loss_uniform =  1.728466983632202\n",
      "epoch =  0 batch =  990 / 1000 loss_uniform =  1.728371984669656\n",
      "epoch =  0 batch =  991 / 1000 loss_uniform =  1.7282752474670329\n",
      "epoch =  0 batch =  992 / 1000 loss_uniform =  1.7281934765558085\n",
      "epoch =  0 batch =  993 / 1000 loss_uniform =  1.7280926265025063\n",
      "epoch =  0 batch =  994 / 1000 loss_uniform =  1.727994034467808\n",
      "epoch =  0 batch =  995 / 1000 loss_uniform =  1.7278974495940467\n",
      "epoch =  0 batch =  996 / 1000 loss_uniform =  1.7278041188496658\n",
      "epoch =  0 batch =  997 / 1000 loss_uniform =  1.727705040929788\n",
      "epoch =  0 batch =  998 / 1000 loss_uniform =  1.7276078605938527\n",
      "epoch =  0 batch =  999 / 1000 loss_uniform =  1.7275076346831753\n",
      "epoch =  0 batch =  1000 / 1000 loss_uniform =  1.7274232519865031\n",
      "epoch =  1 batch =  1 / 1000 loss_uniform =  1.6389187574386597\n",
      "epoch =  1 batch =  2 / 1000 loss_uniform =  1.6391562223434448\n",
      "epoch =  1 batch =  3 / 1000 loss_uniform =  1.6392999092737834\n",
      "epoch =  1 batch =  4 / 1000 loss_uniform =  1.6391767263412476\n",
      "epoch =  1 batch =  5 / 1000 loss_uniform =  1.6366412878036498\n",
      "epoch =  1 batch =  6 / 1000 loss_uniform =  1.632887860139211\n",
      "epoch =  1 batch =  7 / 1000 loss_uniform =  1.6317205258778162\n",
      "epoch =  1 batch =  8 / 1000 loss_uniform =  1.6340092867612839\n",
      "epoch =  1 batch =  9 / 1000 loss_uniform =  1.6350455549028184\n",
      "epoch =  1 batch =  10 / 1000 loss_uniform =  1.6348016858100891\n",
      "epoch =  1 batch =  11 / 1000 loss_uniform =  1.6336508447473699\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5cfc40c757b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#loss_variational = -flow_variational.log_prob(inputs=batch_x).mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss_uniform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#loss_variational.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 1000\n",
    "n_batches = m.ceil(x_data.shape[0]/batch_size)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    permutation = torch.randperm(x_data.shape[0], device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss_uniform = 0\n",
    "    #cum_loss_variational = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, x_data.shape[0]-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        batch_x = x_data[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer_uniform.zero_grad()\n",
    "        #optimizer_variational.zero_grad()\n",
    "\n",
    "        loss_uniform = -flow_uniform.log_prob(inputs=batch_x).mean()\n",
    "        #loss_variational = -flow_variational.log_prob(inputs=batch_x).mean()\n",
    "\n",
    "        loss_uniform.backward()\n",
    "        #loss_variational.backward()\n",
    "\n",
    "        optimizer_uniform.step()\n",
    "        #optimizer_variational.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss_uniform = (cum_loss_uniform*batch + loss_uniform.item())/(batch+1)\n",
    "        #cum_loss_variational = (cum_loss_variational*batch + loss_variational.item())/(batch+1)\n",
    "\n",
    "        print(\"epoch = \", epoch, \"batch = \",batch+1, \"/\", n_batches, \"loss_uniform = \", cum_loss_uniform)#, \" loss_variational = \", cum_loss_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "with torch.no_grad():\n",
    "    x_uniform = flow_uniform.sample(n_sample).cpu()\n",
    "    #x_variational = flow_variational.sample(n_sample).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-22d52798fe88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'stepfilled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"black\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lightgray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(np.count_nonzero(x_data.numpy(), axis=1), np.linspace(-0.5,4.5,6), histtype='stepfilled', edgecolor=\"black\", facecolor=\"lightgray\", density=True)\n",
    "plt.hist(np.count_nonzero(x_flow.numpy(), axis=1), np.linspace(-0.5,4.5,6), edgecolor=\"red\", histtype=\"step\", density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_random = torch.rand(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "p() missing 1 required positional argument: 'n_probs'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ab4e3ad264a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: p() missing 1 required positional argument: 'n_probs'"
     ]
    }
   ],
   "source": [
    "p(x_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ac66c5402be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-201f9714ef89>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprobs_cumsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mprobs_cumsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = StochasticDropout(torch.tensor([1,2,3,4]), hidden_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleAttributeError",
     "evalue": "'StochasticDropout' object has no attribute 'inverse'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-df89582992a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    772\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'StochasticDropout' object has no attribute 'inverse'"
     ]
    }
   ],
   "source": [
    "a = test.inverse(torch.rand(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}