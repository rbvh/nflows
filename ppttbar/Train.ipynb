{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.splines.rational_quadratic import rational_quadratic_spline\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math as m\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard writer\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg run 14\n",
    "n_RQS_knots = 10   # Number of knots in RQS transform\n",
    "n_made_layers = 3  # Number of layers in every made network\n",
    "n_made_units = 500 # Number of units in every layer of the made network\n",
    "n_flow_layers = 12 # Number of layers in the flow\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 800\n",
    "adam_lr = 0.001   # Learning rate for the ADAM optimizer (default: 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_testing = int(3.6820486488184496*1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = torch.tensor(np.genfromtxt(\"neg_training_samples.csv\",\n",
    "                    delimiter=','), dtype=torch.float32, device=device)\n",
    "testing_samples = torch.tensor(np.genfromtxt(\"neg_testing_samples.csv\",\n",
    "                    delimiter=',')[:n_testing], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_weights = np.genfromtxt(\"neg_training_weights.csv\", delimiter=',')\n",
    "testing_weights = np.genfromtxt(\"neg_testing_weights.csv\", delimiter=',')[:n_testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_weights = torch.tensor(np.sign(training_weights), dtype=torch.float32, device=device)\n",
    "testing_weights = torch.tensor(np.sign(testing_weights), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dim = training_samples.shape[1] # Dimensionality of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dist = BoxUniform(torch.zeros(event_dim), torch.ones(event_dim))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(n_flow_layers):\n",
    "    transforms.append(RandomPermutation(features=event_dim))\n",
    "    transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=event_dim, \n",
    "        hidden_features=n_made_units,\n",
    "        num_bins=n_RQS_knots,\n",
    "        num_blocks=n_made_layers-1,\n",
    "        tails=\"constrained\",\n",
    "        use_residual_blocks=False\n",
    "    ))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "flow = Flow(transform, base_dist).to(device)\n",
    "optimizer = optim.Adam(flow.parameters(), lr=adam_lr)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[350, 425, 500, 575, 650, 725, 800], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  1 / 3596 loss =  6.753967761993408\n",
      "epoch =  0 batch =  26 / 3596 loss =  -6.534637190544834\n",
      "epoch =  0 batch =  51 / 3596 loss =  -10.456426861604639\n",
      "epoch =  0 batch =  76 / 3596 loss =  -12.033402792962367\n",
      "epoch =  0 batch =  101 / 3596 loss =  -13.069429122759859\n",
      "epoch =  0 batch =  126 / 3596 loss =  -13.73941470626446\n",
      "epoch =  0 batch =  151 / 3596 loss =  -14.215411261340838\n",
      "epoch =  0 batch =  176 / 3596 loss =  -14.542447311740199\n",
      "epoch =  0 batch =  201 / 3596 loss =  -14.78892212433379\n",
      "epoch =  0 batch =  226 / 3596 loss =  -15.01673978997345\n",
      "epoch =  0 batch =  251 / 3596 loss =  -15.225528534264322\n",
      "epoch =  0 batch =  276 / 3596 loss =  -15.443562203194892\n",
      "epoch =  0 batch =  301 / 3596 loss =  -15.60108390090325\n",
      "epoch =  0 batch =  326 / 3596 loss =  -15.740978670689318\n",
      "epoch =  0 batch =  351 / 3596 loss =  -15.865404593352324\n",
      "epoch =  0 batch =  376 / 3596 loss =  -15.984581216585209\n",
      "epoch =  0 batch =  401 / 3596 loss =  -16.077922578213613\n",
      "epoch =  0 batch =  426 / 3596 loss =  -16.139440717595374\n",
      "epoch =  0 batch =  451 / 3596 loss =  -16.211282452869934\n",
      "epoch =  0 batch =  476 / 3596 loss =  -16.267444756641215\n",
      "epoch =  0 batch =  501 / 3596 loss =  -16.319828099870488\n",
      "epoch =  0 batch =  526 / 3596 loss =  -16.36031164034156\n",
      "epoch =  0 batch =  551 / 3596 loss =  -16.40084184604123\n",
      "epoch =  0 batch =  576 / 3596 loss =  -16.445573735393655\n",
      "epoch =  0 batch =  601 / 3596 loss =  -16.496058920884956\n",
      "epoch =  0 batch =  626 / 3596 loss =  -16.544183071268325\n",
      "epoch =  0 batch =  651 / 3596 loss =  -16.59245732580579\n",
      "epoch =  0 batch =  676 / 3596 loss =  -16.635502267722625\n",
      "epoch =  0 batch =  701 / 3596 loss =  -16.68586258867098\n",
      "epoch =  0 batch =  726 / 3596 loss =  -16.720401746700695\n",
      "epoch =  0 batch =  751 / 3596 loss =  -16.766412240871013\n",
      "epoch =  0 batch =  776 / 3596 loss =  -16.792272025647303\n",
      "epoch =  0 batch =  801 / 3596 loss =  -16.832729185886063\n",
      "epoch =  0 batch =  826 / 3596 loss =  -16.84888460895287\n",
      "epoch =  0 batch =  851 / 3596 loss =  -16.885471483957378\n",
      "epoch =  0 batch =  876 / 3596 loss =  -16.915003808006894\n",
      "epoch =  0 batch =  901 / 3596 loss =  -16.931220368878066\n",
      "epoch =  0 batch =  926 / 3596 loss =  -16.957813862224413\n",
      "epoch =  0 batch =  951 / 3596 loss =  -16.990083217013677\n",
      "epoch =  0 batch =  976 / 3596 loss =  -17.020747872546583\n",
      "epoch =  0 batch =  1001 / 3596 loss =  -17.04215134906914\n",
      "epoch =  0 batch =  1026 / 3596 loss =  -17.070616381809284\n",
      "epoch =  0 batch =  1051 / 3596 loss =  -17.09820106017671\n",
      "epoch =  0 batch =  1076 / 3596 loss =  -17.12289862463866\n",
      "epoch =  0 batch =  1101 / 3596 loss =  -17.148380457884624\n",
      "epoch =  0 batch =  1126 / 3596 loss =  -17.178945886851217\n",
      "epoch =  0 batch =  1151 / 3596 loss =  -17.205990976831178\n",
      "epoch =  0 batch =  1176 / 3596 loss =  -17.235143104292515\n",
      "epoch =  0 batch =  1201 / 3596 loss =  -17.25345290363839\n",
      "epoch =  0 batch =  1226 / 3596 loss =  -17.269898419974883\n",
      "epoch =  0 batch =  1251 / 3596 loss =  -17.298111711203635\n",
      "epoch =  0 batch =  1276 / 3596 loss =  -17.32142925478785\n",
      "epoch =  0 batch =  1301 / 3596 loss =  -17.349534206181108\n",
      "epoch =  0 batch =  1326 / 3596 loss =  -17.37454894146014\n",
      "epoch =  0 batch =  1351 / 3596 loss =  -17.402461561528078\n",
      "epoch =  0 batch =  1376 / 3596 loss =  -17.435588407581974\n",
      "epoch =  0 batch =  1401 / 3596 loss =  -17.46222793699893\n",
      "epoch =  0 batch =  1426 / 3596 loss =  -17.490115016502873\n",
      "epoch =  0 batch =  1451 / 3596 loss =  -17.519557029370834\n",
      "epoch =  0 batch =  1476 / 3596 loss =  -17.528604278005215\n",
      "epoch =  0 batch =  1501 / 3596 loss =  -17.554860400895908\n",
      "epoch =  0 batch =  1526 / 3596 loss =  -17.579431545621578\n",
      "epoch =  0 batch =  1551 / 3596 loss =  -17.601038583485238\n",
      "epoch =  0 batch =  1576 / 3596 loss =  -17.622381768186973\n",
      "epoch =  0 batch =  1601 / 3596 loss =  -17.641056551563665\n",
      "epoch =  0 batch =  1626 / 3596 loss =  -17.656366798648673\n",
      "epoch =  0 batch =  1651 / 3596 loss =  -17.67379349344907\n",
      "epoch =  0 batch =  1676 / 3596 loss =  -17.698661836004206\n",
      "epoch =  0 batch =  1701 / 3596 loss =  -17.72378745008652\n",
      "epoch =  0 batch =  1726 / 3596 loss =  -17.747758276296526\n",
      "epoch =  0 batch =  1751 / 3596 loss =  -17.770380212888668\n",
      "epoch =  0 batch =  1776 / 3596 loss =  -17.792479991856204\n",
      "epoch =  0 batch =  1801 / 3596 loss =  -17.816449470824256\n",
      "epoch =  0 batch =  1826 / 3596 loss =  -17.839667088306246\n",
      "epoch =  0 batch =  1851 / 3596 loss =  -17.86186581075007\n",
      "epoch =  0 batch =  1876 / 3596 loss =  -17.882426903392485\n",
      "epoch =  0 batch =  1901 / 3596 loss =  -17.89951570677145\n",
      "epoch =  0 batch =  1926 / 3596 loss =  -17.918499094870256\n",
      "epoch =  0 batch =  1951 / 3596 loss =  -17.93344126373095\n",
      "epoch =  0 batch =  1976 / 3596 loss =  -17.95514694008004\n",
      "epoch =  0 batch =  2001 / 3596 loss =  -17.971997861988264\n",
      "epoch =  0 batch =  2026 / 3596 loss =  -17.991860261624584\n",
      "epoch =  0 batch =  2051 / 3596 loss =  -18.014415855302882\n",
      "epoch =  0 batch =  2076 / 3596 loss =  -18.03312542805761\n",
      "epoch =  0 batch =  2101 / 3596 loss =  -18.049425444629993\n",
      "epoch =  0 batch =  2126 / 3596 loss =  -18.065124842721136\n",
      "epoch =  0 batch =  2151 / 3596 loss =  -18.082175804102068\n",
      "epoch =  0 batch =  2176 / 3596 loss =  -18.095200919006917\n",
      "epoch =  0 batch =  2201 / 3596 loss =  -18.112869430766672\n",
      "epoch =  0 batch =  2226 / 3596 loss =  -18.127825985440893\n",
      "epoch =  0 batch =  2251 / 3596 loss =  -18.147996610938275\n",
      "epoch =  0 batch =  2276 / 3596 loss =  -18.164348360899062\n",
      "epoch =  0 batch =  2301 / 3596 loss =  -18.17988139632661\n",
      "epoch =  0 batch =  2326 / 3596 loss =  -18.197544326640593\n",
      "epoch =  0 batch =  2351 / 3596 loss =  -18.212421120260508\n",
      "epoch =  0 batch =  2376 / 3596 loss =  -18.229360174207397\n",
      "epoch =  0 batch =  2401 / 3596 loss =  -18.246322158333086\n",
      "epoch =  0 batch =  2426 / 3596 loss =  -18.263054181754864\n",
      "epoch =  0 batch =  2451 / 3596 loss =  -18.273044144127546\n",
      "epoch =  0 batch =  2476 / 3596 loss =  -18.287405293628954\n",
      "epoch =  0 batch =  2501 / 3596 loss =  -18.301588753954046\n",
      "epoch =  0 batch =  2526 / 3596 loss =  -18.31646171031241\n",
      "epoch =  0 batch =  2551 / 3596 loss =  -18.330645921937634\n",
      "epoch =  0 batch =  2576 / 3596 loss =  -18.343704428692966\n",
      "epoch =  0 batch =  2601 / 3596 loss =  -18.360930344874017\n",
      "epoch =  0 batch =  2626 / 3596 loss =  -18.374176798169888\n",
      "epoch =  0 batch =  2651 / 3596 loss =  -18.386200164100813\n",
      "epoch =  0 batch =  2676 / 3596 loss =  -18.406541013181133\n",
      "epoch =  0 batch =  2701 / 3596 loss =  -18.41907256389963\n",
      "epoch =  0 batch =  2726 / 3596 loss =  -18.432130077490292\n",
      "epoch =  0 batch =  2751 / 3596 loss =  -18.444136934649425\n",
      "epoch =  0 batch =  2776 / 3596 loss =  -18.457298995402258\n",
      "epoch =  0 batch =  2801 / 3596 loss =  -18.472869321439237\n",
      "epoch =  0 batch =  2826 / 3596 loss =  -18.483975368580232\n",
      "epoch =  0 batch =  2851 / 3596 loss =  -18.493592176264926\n",
      "epoch =  0 batch =  2876 / 3596 loss =  -18.50818565521667\n",
      "epoch =  0 batch =  2901 / 3596 loss =  -18.521889834811454\n",
      "epoch =  0 batch =  2926 / 3596 loss =  -18.53284742660889\n",
      "epoch =  0 batch =  2951 / 3596 loss =  -18.542870060347873\n",
      "epoch =  0 batch =  2976 / 3596 loss =  -18.55506574078735\n",
      "epoch =  0 batch =  3001 / 3596 loss =  -18.566797543714276\n",
      "epoch =  0 batch =  3026 / 3596 loss =  -18.579401302997724\n",
      "epoch =  0 batch =  3051 / 3596 loss =  -18.59415026248518\n",
      "epoch =  0 batch =  3076 / 3596 loss =  -18.60622559905033\n",
      "epoch =  0 batch =  3101 / 3596 loss =  -18.61891158382706\n",
      "epoch =  0 batch =  3126 / 3596 loss =  -18.633440631485218\n",
      "epoch =  0 batch =  3151 / 3596 loss =  -18.648518638857308\n",
      "epoch =  0 batch =  3176 / 3596 loss =  -18.661651554244102\n",
      "epoch =  0 batch =  3201 / 3596 loss =  -18.673471880389425\n",
      "epoch =  0 batch =  3226 / 3596 loss =  -18.682698381632772\n",
      "epoch =  0 batch =  3251 / 3596 loss =  -18.69205161730773\n"
     ]
    }
   ],
   "source": [
    "data_size = training_samples.shape[0]\n",
    "n_batches = m.ceil(data_size/batch_size)\n",
    "\n",
    "data_size_validation = testing_samples.shape[0]\n",
    "n_batches_validate = m.ceil(data_size_validation/batch_size)\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    scheduler.step()\n",
    "    \n",
    "    permutation = torch.randperm(data_size, device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, data_size-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        samples_batch = training_samples[indices]\n",
    "        weights_batch = training_weights[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer.zero_grad()\n",
    "        loss = -(flow.log_prob(inputs=samples_batch)*weights_batch).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss = (cum_loss*batch + loss.item())/(batch+1)\n",
    "\n",
    "        if batch%25 == 0:\n",
    "            print(\"epoch = \", epoch, \"batch = \",batch+1, \"/\", n_batches, \"loss = \", cum_loss)\n",
    "    \n",
    "    # Compute validation loss\n",
    "    validation_loss = 0\n",
    "    for batch in range(n_batches_validate):\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end = min( (batch+1)*batch_size, data_size_validation-1 )\n",
    "        samples_batch = testing_samples[batch_begin:batch_end]\n",
    "        weights_batch = testing_weights[batch_begin:batch_end]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            validation_loss = (validation_loss*batch - (flow.log_prob(samples_batch)*weights_batch).mean())/(batch+1)\n",
    "    \n",
    "    print(\"Validation loss = \", validation_loss)\n",
    "    \n",
    "    writer.add_scalar(\"Loss_train\", cum_loss, epoch)\n",
    "    writer.add_scalar(\"Loss_test\", validation_loss, epoch)\n",
    "    \n",
    "    if validation_loss < best_loss:\n",
    "        torch.save(flow, \"flow_model.pt\")\n",
    "        best_loss = validation_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
